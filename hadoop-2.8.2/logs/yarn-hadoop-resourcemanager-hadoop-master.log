2017-11-12 12:06:12,931 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.252.131
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/etc/hadoop:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-11-12 12:06:12,939 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-11-12 12:06:13,115 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2017-11-12 12:06:13,161 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2017-11-12 12:06:13,206 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2017-11-12 12:06:13,338 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2017-11-12 12:06:13,552 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2017-11-12 12:06:13,597 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2017-11-12 12:06:13,606 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2017-11-12 12:06:13,655 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2017-11-12 12:06:13,657 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2017-11-12 12:06:13,657 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2017-11-12 12:06:13,680 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2017-11-12 12:06:13,681 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2017-11-12 12:06:13,682 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2017-11-12 12:06:13,683 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2017-11-12 12:06:13,722 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-11-12 12:06:13,774 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-11-12 12:06:13,774 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2017-11-12 12:06:13,784 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2017-11-12 12:06:13,790 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2017-11-12 12:06:13,792 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2017-11-12 12:06:13,798 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2017-11-12 12:06:13,800 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-11-12 12:06:13,806 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2017-11-12 12:06:13,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2017-11-12 12:06:13,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2017-11-12 12:06:13,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2017-11-12 12:06:13,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2017-11-12 12:06:13,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2017-11-12 12:06:13,865 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2017-11-12 12:06:13,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2017-11-12 12:06:13,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2017-11-12 12:06:13,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-11-12 12:06:13,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-11-12 12:06:13,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2017-11-12 12:06:13,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2017-11-12 12:06:13,874 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2017-11-12 12:06:13,884 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2017-11-12 12:06:13,884 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2017-11-12 12:06:13,891 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-11-12 12:06:13,898 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2017-11-12 12:06:13,898 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2017-11-12 12:06:13,899 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2017-11-12 12:06:13,899 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 12:06:13,899 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2017-11-12 12:06:13,899 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-11-12 12:06:13,900 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-11-12 12:06:13,900 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 12:06:13,900 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2017-11-12 12:06:13,900 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-11-12 12:06:13,901 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2017-11-12 12:06:13,997 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 12:06:14,065 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2017-11-12 12:06:14,544 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2017-11-12 12:06:14,545 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 12:06:14,572 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2017-11-12 12:06:14,658 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 12:06:14,672 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2017-11-12 12:06:14,682 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2017-11-12 12:06:14,682 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 12:06:14,683 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2017-11-12 12:06:14,973 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 12:06:14,974 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2017-11-12 12:06:14,981 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2017-11-12 12:06:14,981 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 12:06:14,981 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2017-11-12 12:06:15,047 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2017-11-12 12:06:15,174 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-11-12 12:06:15,188 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-11-12 12:06:15,202 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2017-11-12 12:06:15,228 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-11-12 12:06:15,231 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2017-11-12 12:06:15,231 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2017-11-12 12:06:15,231 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2017-11-12 12:06:15,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2017-11-12 12:06:15,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-11-12 12:06:15,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-11-12 12:06:15,239 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2017-11-12 12:06:15,239 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-11-12 12:06:15,832 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-11-12 12:06:15,836 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2017-11-12 12:06:15,836 INFO org.mortbay.log: jetty-6.1.26
2017-11-12 12:06:15,865 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2017-11-12 12:06:16,420 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 12:06:16,478 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-11-12 12:06:16,478 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 12:06:18,428 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-11-12 12:06:18,428 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2017-11-12 12:06:18,479 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 12:06:18,483 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2017-11-12 12:06:18,493 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2017-11-12 12:06:18,495 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 12:06:18,497 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2017-11-12 12:17:21,034 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2017-11-12 12:18:06,773 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01(cmPort: 41792 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01:41792
2017-11-12 12:18:06,778 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01:41792 Node Transitioned from NEW to RUNNING
2017-11-12 12:18:06,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01:41792 clusterResource: <memory:8192, vCores:8>
2017-11-12 12:18:08,781 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03(cmPort: 34047 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03:34047
2017-11-12 12:18:08,781 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03:34047 Node Transitioned from NEW to RUNNING
2017-11-12 12:18:08,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03:34047 clusterResource: <memory:16384, vCores:16>
2017-11-12 12:18:08,846 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02(cmPort: 35444 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02:35444
2017-11-12 12:18:08,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02:35444 Node Transitioned from NEW to RUNNING
2017-11-12 12:18:08,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02:35444 clusterResource: <memory:24576, vCores:24>
2017-11-12 12:41:09,673 INFO org.apache.hadoop.yarn.util.AdHocLogDumper: Dumping adhoc logs for org.apache.hadoop.yarn.server.resourcemanager.scheduler to /opt/hadoop/logs/yarn-capacity-scheduler-debug.log for 60000 milliseconds
2017-11-12 12:42:16,457 INFO org.apache.hadoop.yarn.util.AdHocLogDumper: Done dumping adhoc logs for org.apache.hadoop.yarn.server.resourcemanager.scheduler
2017-11-12 14:18:21,135 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2017-11-12 14:18:21,146 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-11-12 14:18:21,149 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-11-12 14:18:21,155 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2017-11-12 14:18:21,163 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:18:21,165 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2017-11-12 14:18:21,169 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2017-11-12 14:18:21,174 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2017-11-12 14:18:21,176 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:18:21,177 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2017-11-12 14:18:21,178 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2017-11-12 14:18:21,178 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2017-11-12 14:18:21,184 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2017-11-12 14:18:21,184 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:18:21,185 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2017-11-12 14:18:21,193 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2017-11-12 14:18:21,193 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:18:21,194 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2017-11-12 14:18:21,195 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2017-11-12 14:18:21,197 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-11-12 14:18:21,199 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-11-12 14:18:21,199 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2017-11-12 14:18:21,200 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-11-12 14:18:21,200 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2017-11-12 14:18:21,208 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-11-12 14:18:21,209 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2017-11-12 14:18:21,209 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2017-11-12 14:18:21,209 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-11-12 14:18:21,210 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2017-11-12 14:18:21,211 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.252.131
************************************************************/
2017-11-12 14:20:47,237 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.252.131
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/etc/hadoop:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-11-12 14:20:47,242 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-11-12 14:20:47,435 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2017-11-12 14:20:47,487 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2017-11-12 14:20:47,548 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2017-11-12 14:20:47,758 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2017-11-12 14:20:47,880 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2017-11-12 14:20:47,893 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2017-11-12 14:20:47,896 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2017-11-12 14:20:47,915 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2017-11-12 14:20:47,917 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2017-11-12 14:20:47,917 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2017-11-12 14:20:47,929 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2017-11-12 14:20:47,930 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2017-11-12 14:20:47,930 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2017-11-12 14:20:47,931 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2017-11-12 14:20:47,961 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-11-12 14:20:48,012 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-11-12 14:20:48,012 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2017-11-12 14:20:48,021 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2017-11-12 14:20:48,026 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2017-11-12 14:20:48,028 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2017-11-12 14:20:48,034 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2017-11-12 14:20:48,035 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-11-12 14:20:48,041 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2017-11-12 14:20:48,122 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2017-11-12 14:20:48,122 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2017-11-12 14:20:48,134 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2017-11-12 14:20:48,135 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2017-11-12 14:20:48,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2017-11-12 14:20:48,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2017-11-12 14:20:48,151 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2017-11-12 14:20:48,151 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2017-11-12 14:20:48,152 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-11-12 14:20:48,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-11-12 14:20:48,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2017-11-12 14:20:48,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2017-11-12 14:20:48,158 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2017-11-12 14:20:48,172 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2017-11-12 14:20:48,173 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2017-11-12 14:20:48,183 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-11-12 14:20:48,195 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2017-11-12 14:20:48,195 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2017-11-12 14:20:48,195 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2017-11-12 14:20:48,195 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 14:20:48,196 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2017-11-12 14:20:48,196 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-11-12 14:20:48,198 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-11-12 14:20:48,198 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 14:20:48,198 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2017-11-12 14:20:48,198 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-11-12 14:20:48,201 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2017-11-12 14:20:48,244 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 14:20:48,262 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2017-11-12 14:20:48,507 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2017-11-12 14:20:48,508 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 14:20:48,508 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2017-11-12 14:20:48,524 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 14:20:48,528 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2017-11-12 14:20:48,539 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2017-11-12 14:20:48,540 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 14:20:48,540 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2017-11-12 14:20:48,697 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 14:20:48,699 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2017-11-12 14:20:48,707 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2017-11-12 14:20:48,708 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 14:20:48,709 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2017-11-12 14:20:48,728 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2017-11-12 14:20:48,854 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-11-12 14:20:48,876 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-11-12 14:20:48,893 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2017-11-12 14:20:48,915 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-11-12 14:20:48,921 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2017-11-12 14:20:48,921 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2017-11-12 14:20:48,921 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2017-11-12 14:20:48,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2017-11-12 14:20:48,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-11-12 14:20:48,922 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-11-12 14:20:48,926 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2017-11-12 14:20:48,926 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-11-12 14:20:49,540 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-11-12 14:20:49,543 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2017-11-12 14:20:49,543 INFO org.mortbay.log: jetty-6.1.26
2017-11-12 14:20:49,569 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2017-11-12 14:20:49,796 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 14:20:49,799 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-11-12 14:20:49,799 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-11-12 14:20:51,902 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-11-12 14:20:51,902 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2017-11-12 14:20:51,962 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-11-12 14:20:51,971 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2017-11-12 14:20:52,006 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2017-11-12 14:20:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-11-12 14:20:52,007 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2017-11-12 14:20:54,764 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03(cmPort: 38486 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03:38486
2017-11-12 14:20:54,764 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01(cmPort: 42958 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01:42958
2017-11-12 14:20:54,764 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02(cmPort: 35574 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02:35574
2017-11-12 14:20:54,769 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01:42958 Node Transitioned from NEW to RUNNING
2017-11-12 14:20:54,773 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02:35574 Node Transitioned from NEW to RUNNING
2017-11-12 14:20:54,773 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03:38486 Node Transitioned from NEW to RUNNING
2017-11-12 14:20:54,780 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01:42958 clusterResource: <memory:8192, vCores:8>
2017-11-12 14:20:54,781 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02:35574 clusterResource: <memory:16384, vCores:16>
2017-11-12 14:20:54,781 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03:38486 clusterResource: <memory:24576, vCores:24>
2017-11-12 14:21:48,207 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2017-11-12 14:21:48,215 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-11-12 14:21:48,217 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-11-12 14:21:48,318 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2017-11-12 14:21:48,319 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2017-11-12 14:21:48,320 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2017-11-12 14:21:48,321 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:21:48,323 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2017-11-12 14:21:48,324 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2017-11-12 14:21:48,326 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:21:48,327 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2017-11-12 14:21:48,328 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2017-11-12 14:21:48,332 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2017-11-12 14:21:48,332 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2017-11-12 14:21:48,334 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2017-11-12 14:21:48,334 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2017-11-12 14:21:48,334 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:21:48,335 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-11-12 14:21:48,335 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2017-11-12 14:21:48,340 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-11-12 14:21:48,340 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2017-11-12 14:21:48,340 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-11-12 14:21:48,341 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-11-12 14:21:48,341 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2017-11-12 14:21:48,341 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-11-12 14:21:48,344 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2017-11-12 14:21:48,345 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2017-11-12 14:21:48,345 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-11-12 14:21:48,345 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2017-11-12 14:21:48,345 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.252.131
************************************************************/
2017-12-25 11:42:11,071 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-12-25 11:42:11,082 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-25 11:42:11,430 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2017-12-25 11:42:11,529 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2017-12-25 11:42:11,612 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2017-12-25 11:42:11,990 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2017-12-25 11:42:12,558 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2017-12-25 11:42:12,567 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2017-12-25 11:42:12,576 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2017-12-25 11:42:12,678 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2017-12-25 11:42:12,682 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2017-12-25 11:42:12,683 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2017-12-25 11:42:12,747 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2017-12-25 11:42:12,749 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2017-12-25 11:42:12,751 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2017-12-25 11:42:12,753 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2017-12-25 11:42:12,909 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-25 11:42:13,046 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-12-25 11:42:13,046 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2017-12-25 11:42:13,074 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2017-12-25 11:42:13,121 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2017-12-25 11:42:13,125 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2017-12-25 11:42:13,136 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2017-12-25 11:42:13,139 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-12-25 11:42:13,168 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2017-12-25 11:42:13,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2017-12-25 11:42:13,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2017-12-25 11:42:13,454 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2017-12-25 11:42:13,454 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2017-12-25 11:42:13,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2017-12-25 11:42:13,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2017-12-25 11:42:13,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2017-12-25 11:42:13,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 11:42:13,492 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 11:42:13,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 11:42:13,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2017-12-25 11:42:13,511 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2017-12-25 11:42:13,540 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2017-12-25 11:42:13,620 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2017-12-25 11:42:13,620 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2017-12-25 11:42:13,668 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-12-25 11:42:13,705 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2017-12-25 11:42:13,705 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2017-12-25 11:42:13,705 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2017-12-25 11:42:13,706 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 11:42:13,706 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2017-12-25 11:42:13,706 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-25 11:42:13,709 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-25 11:42:13,709 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 11:42:13,709 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2017-12-25 11:42:13,709 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-25 11:42:13,715 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2017-12-25 11:42:13,819 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 11:42:13,865 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2017-12-25 11:42:14,251 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2017-12-25 11:42:14,257 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 11:42:14,259 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2017-12-25 11:42:14,346 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 11:42:14,361 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2017-12-25 11:42:14,388 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2017-12-25 11:42:14,408 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 11:42:14,410 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2017-12-25 11:42:14,809 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 11:42:14,831 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2017-12-25 11:42:14,856 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2017-12-25 11:42:14,868 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 11:42:14,878 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2017-12-25 11:42:15,049 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2017-12-25 11:42:15,290 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-25 11:42:15,335 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-12-25 11:42:15,353 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2017-12-25 11:42:15,400 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-25 11:42:15,404 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2017-12-25 11:42:15,404 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2017-12-25 11:42:15,404 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2017-12-25 11:42:15,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2017-12-25 11:42:15,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-25 11:42:15,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-25 11:42:15,410 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2017-12-25 11:42:15,410 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-12-25 11:42:16,687 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-12-25 11:42:16,692 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2017-12-25 11:42:16,692 INFO org.mortbay.log: jetty-6.1.26
2017-12-25 11:42:16,784 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2017-12-25 11:42:17,412 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 11:42:17,416 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-25 11:42:17,422 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 11:42:21,031 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-25 11:42:21,032 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2017-12-25 11:42:21,228 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 11:42:21,261 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2017-12-25 11:42:21,269 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2017-12-25 11:42:21,306 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 11:42:21,322 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2017-12-25 11:42:24,852 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 39001 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:39001
2017-12-25 11:42:24,855 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 45044 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:45044
2017-12-25 11:42:24,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:39001 Node Transitioned from NEW to RUNNING
2017-12-25 11:42:24,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:45044 Node Transitioned from NEW to RUNNING
2017-12-25 11:42:24,877 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:39001 clusterResource: <memory:8192, vCores:8>
2017-12-25 11:42:24,878 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:45044 clusterResource: <memory:16384, vCores:16>
2017-12-25 11:52:57,441 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2017-12-25 12:12:13,906 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2017-12-25 12:12:13,925 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-25 12:12:13,928 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-25 12:12:14,034 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2017-12-25 12:12:14,059 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2017-12-25 12:12:14,068 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:12:14,072 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2017-12-25 12:12:14,081 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2017-12-25 12:12:14,086 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:12:14,086 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2017-12-25 12:12:14,087 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2017-12-25 12:12:14,087 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2017-12-25 12:12:14,089 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2017-12-25 12:12:14,089 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2017-12-25 12:12:14,095 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:12:14,096 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2017-12-25 12:12:14,097 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2017-12-25 12:12:14,097 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:12:14,096 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2017-12-25 12:12:14,102 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-25 12:12:14,103 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-25 12:12:14,103 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-25 12:12:14,103 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-25 12:12:14,104 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2017-12-25 12:12:14,104 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2017-12-25 12:12:14,109 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2017-12-25 12:12:14,109 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2017-12-25 12:12:14,110 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-25 12:12:14,110 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2017-12-25 12:12:14,111 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2017-12-25 12:24:05,839 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-12-25 12:24:05,850 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-25 12:24:06,253 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2017-12-25 12:24:06,371 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2017-12-25 12:24:06,487 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2017-12-25 12:24:06,905 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2017-12-25 12:24:07,453 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2017-12-25 12:24:07,461 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2017-12-25 12:24:07,472 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2017-12-25 12:24:07,582 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2017-12-25 12:24:07,608 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2017-12-25 12:24:07,609 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2017-12-25 12:24:07,675 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2017-12-25 12:24:07,681 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2017-12-25 12:24:07,683 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2017-12-25 12:24:07,685 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2017-12-25 12:24:07,784 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-25 12:24:07,944 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-12-25 12:24:07,945 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2017-12-25 12:24:08,000 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2017-12-25 12:24:08,101 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2017-12-25 12:24:08,104 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2017-12-25 12:24:08,137 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2017-12-25 12:24:08,140 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-12-25 12:24:08,156 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2017-12-25 12:24:08,514 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2017-12-25 12:24:08,514 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2017-12-25 12:24:08,532 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2017-12-25 12:24:08,533 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2017-12-25 12:24:08,587 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2017-12-25 12:24:08,587 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2017-12-25 12:24:08,590 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2017-12-25 12:24:08,590 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 12:24:08,591 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 12:24:08,592 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 12:24:08,592 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2017-12-25 12:24:08,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2017-12-25 12:24:08,636 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2017-12-25 12:24:08,664 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2017-12-25 12:24:08,664 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2017-12-25 12:24:08,853 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-12-25 12:24:08,855 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2017-12-25 12:24:08,856 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2017-12-25 12:24:08,856 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2017-12-25 12:24:08,856 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 12:24:08,857 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2017-12-25 12:24:08,858 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-25 12:24:08,863 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-25 12:24:08,863 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 12:24:08,863 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2017-12-25 12:24:08,863 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-25 12:24:08,869 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2017-12-25 12:24:08,952 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 12:24:08,990 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2017-12-25 12:24:09,456 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2017-12-25 12:24:09,462 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 12:24:09,468 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2017-12-25 12:24:09,832 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 12:24:09,851 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2017-12-25 12:24:09,883 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2017-12-25 12:24:09,886 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 12:24:09,890 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2017-12-25 12:24:10,231 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 12:24:10,249 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2017-12-25 12:24:10,267 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2017-12-25 12:24:10,299 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 12:24:10,308 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2017-12-25 12:24:10,744 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2017-12-25 12:24:11,140 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-25 12:24:11,177 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-12-25 12:24:11,205 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2017-12-25 12:24:11,271 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-25 12:24:11,276 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2017-12-25 12:24:11,276 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2017-12-25 12:24:11,276 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2017-12-25 12:24:11,277 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2017-12-25 12:24:11,277 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-25 12:24:11,278 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-25 12:24:11,283 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2017-12-25 12:24:11,283 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-12-25 12:24:12,481 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-12-25 12:24:12,484 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2017-12-25 12:24:12,484 INFO org.mortbay.log: jetty-6.1.26
2017-12-25 12:24:12,558 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2017-12-25 12:24:12,997 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 12:24:13,000 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-25 12:24:13,002 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 12:24:16,581 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-25 12:24:16,582 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2017-12-25 12:24:16,855 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 12:24:16,857 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2017-12-25 12:24:16,864 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2017-12-25 12:24:16,921 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 12:24:16,941 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2017-12-25 12:24:20,120 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 40017 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:40017
2017-12-25 12:24:20,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:40017 Node Transitioned from NEW to RUNNING
2017-12-25 12:24:20,156 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:40017 clusterResource: <memory:8192, vCores:8>
2017-12-25 12:24:20,225 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 44567 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:44567
2017-12-25 12:24:20,226 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:44567 Node Transitioned from NEW to RUNNING
2017-12-25 12:24:20,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:44567 clusterResource: <memory:16384, vCores:16>
2017-12-25 12:26:34,214 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2017-12-25 12:26:44,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514172248677_0001' is submitted without priority hence considering default queue/cluster priority: 0
2017-12-25 12:26:44,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514172248677_0001 for the user: hadoop
2017-12-25 12:26:44,809 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2017-12-25 12:26:44,866 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2017-12-25 12:26:44,867 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514172248677_0001
2017-12-25 12:26:44,869 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514172248677_0001
2017-12-25 12:26:44,877 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from NEW to NEW_SAVING on event=START
2017-12-25 12:26:44,877 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514172248677_0001
2017-12-25 12:26:44,878 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2017-12-25 12:26:44,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514172248677_0001 user: hadoop leaf-queue of parent: root #applications: 1
2017-12-25 12:26:44,882 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514172248677_0001 from user: hadoop, in queue: default
2017-12-25 12:26:44,897 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2017-12-25 12:26:44,933 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514172248677_0001_000001
2017-12-25 12:26:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from NEW to SUBMITTED
2017-12-25 12:26:44,968 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514172248677_0001 from user: hadoop activated in queue: default
2017-12-25 12:26:44,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514172248677_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2017-12-25 12:26:44,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514172248677_0001_000001 to scheduler from user hadoop in queue default
2017-12-25 12:26:44,972 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from SUBMITTED to SCHEDULED
2017-12-25 12:26:45,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2017-12-25 12:26:45,133 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514172248677_0001	CONTAINERID=container_1514172248677_0001_01_000001
2017-12-25 12:26:45,135 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514172248677_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:44567, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2017-12-25 12:26:45,135 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514172248677_0001_000001 container=container_1514172248677_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@16e4d429 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2017-12-25 12:26:45,137 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2017-12-25 12:26:45,137 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2017-12-25 12:26:45,169 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:44567 for container : container_1514172248677_0001_01_000001
2017-12-25 12:26:45,183 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2017-12-25 12:26:45,184 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514172248677_0001_000001
2017-12-25 12:26:45,184 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514172248677_0001 AttemptId: appattempt_1514172248677_0001_000001 MasterContainer: Container: [ContainerId: container_1514172248677_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:44567, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:44567 }, ]
2017-12-25 12:26:45,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2017-12-25 12:26:45,200 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2017-12-25 12:26:45,203 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514172248677_0001_000001
2017-12-25 12:26:45,271 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514172248677_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:44567, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:44567 }, ] for AM appattempt_1514172248677_0001_000001
2017-12-25 12:26:45,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514172248677_0001_000001
2017-12-25 12:26:45,276 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514172248677_0001_000001
2017-12-25 12:26:45,764 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514172248677_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:44567, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:44567 }, ] for AM appattempt_1514172248677_0001_000001
2017-12-25 12:26:45,764 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from ALLOCATED to LAUNCHED
2017-12-25 12:26:46,123 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2017-12-25 12:26:54,874 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514172248677_0001_000001 (auth:SIMPLE)
2017-12-25 12:26:54,886 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514172248677_0001_000001
2017-12-25 12:26:54,887 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514172248677_0001	APPATTEMPTID=appattempt_1514172248677_0001_000001
2017-12-25 12:26:54,887 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from LAUNCHED to RUNNING
2017-12-25 12:26:54,887 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2017-12-25 12:26:55,418 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2017-12-25 12:26:55,418 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514172248677_0001	CONTAINERID=container_1514172248677_0001_01_000002
2017-12-25 12:26:55,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514172248677_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:40017, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2017-12-25 12:26:55,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514172248677_0001_000001 container=container_1514172248677_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@16e4d429 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2017-12-25 12:26:55,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2017-12-25 12:26:55,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2017-12-25 12:26:55,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2017-12-25 12:26:55,671 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514172248677_0001	CONTAINERID=container_1514172248677_0001_01_000003
2017-12-25 12:26:55,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514172248677_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:44567, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2017-12-25 12:26:55,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514172248677_0001_000001 container=container_1514172248677_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@16e4d429 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2017-12-25 12:26:55,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2017-12-25 12:26:55,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2017-12-25 12:26:55,716 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:40017 for container : container_1514172248677_0001_01_000002
2017-12-25 12:26:55,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2017-12-25 12:26:55,722 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:44567 for container : container_1514172248677_0001_01_000003
2017-12-25 12:26:55,724 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2017-12-25 12:26:56,708 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2017-12-25 12:26:58,195 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2017-12-25 12:26:58,853 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514172248677_0001
2017-12-25 12:27:44,627 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514172248677_0001_000001 with final state: FINISHING, and exit status: -1000
2017-12-25 12:27:44,628 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from RUNNING to FINAL_SAVING
2017-12-25 12:27:44,628 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514172248677_0001 with final state: FINISHING
2017-12-25 12:27:44,629 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2017-12-25 12:27:44,629 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514172248677_0001
2017-12-25 12:27:44,629 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from FINAL_SAVING to FINISHING
2017-12-25 12:27:44,629 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2017-12-25 12:27:44,739 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514172248677_0001 unregistered successfully. 
2017-12-25 12:27:44,957 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2017-12-25 12:27:44,957 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514172248677_0001	CONTAINERID=container_1514172248677_0001_01_000003
2017-12-25 12:27:44,960 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514172248677_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:44567, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2017-12-25 12:27:44,965 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2017-12-25 12:27:44,966 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514172248677_0001	CONTAINERID=container_1514172248677_0001_01_000002
2017-12-25 12:27:44,966 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514172248677_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:40017, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2017-12-25 12:27:45,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514172248677_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2017-12-25 12:27:45,242 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514172248677_0001_000001
2017-12-25 12:27:45,242 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514172248677_0001	CONTAINERID=container_1514172248677_0001_01_000001
2017-12-25 12:27:45,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514172248677_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:44567, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2017-12-25 12:27:45,243 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514172248677_0001_000001
2017-12-25 12:27:45,244 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514172248677_0001_000001 State change from FINISHING to FINISHED
2017-12-25 12:27:45,246 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514172248677_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2017-12-25 12:27:45,246 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514172248677_0001_000001 is done. finalState=FINISHED
2017-12-25 12:27:45,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514172248677_0001 requests cleared
2017-12-25 12:27:45,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514172248677_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2017-12-25 12:27:45,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514172248677_0001 user: hadoop leaf-queue of parent: root #applications: 0
2017-12-25 12:27:45,250 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514172248677_0001_000001
2017-12-25 12:27:45,257 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514172248677_0001
2017-12-25 12:27:45,262 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514172248677_0001,name=Spark shell,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514172248677_0001/,appMasterHost=192.168.28.132,startTime=1514172404809,finishTime=1514172464628,finalStatus=SUCCEEDED,memorySeconds=263963,vcoreSeconds=158,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2017-12-25 12:27:47,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514172248677_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2017-12-25 12:27:47,278 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514172248677_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2017-12-25 12:34:38,351 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2017-12-25 12:43:52,430 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker02.local:44567 has shutdown, hence unregistering the node.
2017-12-25 12:43:52,430 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker01.local:40017 has shutdown, hence unregistering the node.
2017-12-25 12:43:52,434 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker02.local:44567 as it is now SHUTDOWN
2017-12-25 12:43:52,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:44567 Node Transitioned from RUNNING to SHUTDOWN
2017-12-25 12:43:52,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker01.local:40017 as it is now SHUTDOWN
2017-12-25 12:43:52,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:40017 Node Transitioned from RUNNING to SHUTDOWN
2017-12-25 12:43:52,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker02.local:44567 clusterResource: <memory:8192, vCores:8>
2017-12-25 12:43:52,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker01.local:40017 clusterResource: <memory:0, vCores:0>
2017-12-25 12:44:32,970 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2017-12-25 12:44:33,053 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-25 12:44:33,060 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-25 12:44:33,075 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2017-12-25 12:44:33,145 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2017-12-25 12:44:33,152 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2017-12-25 12:44:33,161 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:44:33,171 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2017-12-25 12:44:33,171 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2017-12-25 12:44:33,185 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:44:33,185 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2017-12-25 12:44:33,187 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2017-12-25 12:44:33,192 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2017-12-25 12:44:33,196 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:44:33,217 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2017-12-25 12:44:33,220 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2017-12-25 12:44:33,220 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2017-12-25 12:44:33,220 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2017-12-25 12:44:33,220 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 12:44:33,223 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-25 12:44:33,223 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-25 12:44:33,224 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2017-12-25 12:44:33,224 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-25 12:44:33,224 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-25 12:44:33,231 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2017-12-25 12:44:33,233 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2017-12-25 12:44:33,233 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2017-12-25 12:44:33,234 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-25 12:44:33,235 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2017-12-25 12:44:33,235 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2017-12-25 20:39:01,707 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-12-25 20:39:01,729 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-25 20:39:02,361 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2017-12-25 20:39:02,680 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2017-12-25 20:39:03,008 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2017-12-25 20:39:03,577 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2017-12-25 20:39:04,582 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2017-12-25 20:39:04,596 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2017-12-25 20:39:04,662 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2017-12-25 20:39:05,083 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2017-12-25 20:39:05,089 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2017-12-25 20:39:05,089 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2017-12-25 20:39:05,246 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2017-12-25 20:39:05,248 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2017-12-25 20:39:05,296 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2017-12-25 20:39:05,298 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2017-12-25 20:39:05,550 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-25 20:39:05,896 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-12-25 20:39:05,896 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2017-12-25 20:39:05,928 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2017-12-25 20:39:06,022 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2017-12-25 20:39:06,026 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2017-12-25 20:39:06,039 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2017-12-25 20:39:06,042 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-12-25 20:39:06,187 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2017-12-25 20:39:06,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2017-12-25 20:39:06,790 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2017-12-25 20:39:06,926 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2017-12-25 20:39:06,927 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2017-12-25 20:39:06,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2017-12-25 20:39:06,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2017-12-25 20:39:06,957 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2017-12-25 20:39:06,957 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 20:39:06,958 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 20:39:06,959 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-25 20:39:06,959 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2017-12-25 20:39:07,046 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2017-12-25 20:39:07,069 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2017-12-25 20:39:07,088 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2017-12-25 20:39:07,088 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2017-12-25 20:39:07,126 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-12-25 20:39:07,254 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2017-12-25 20:39:07,254 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2017-12-25 20:39:07,254 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2017-12-25 20:39:07,255 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 20:39:07,256 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2017-12-25 20:39:07,256 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-25 20:39:07,297 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2017-12-25 20:39:07,305 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-25 20:39:07,306 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 20:39:07,306 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2017-12-25 20:39:07,306 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-25 20:39:07,397 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 20:39:07,453 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2017-12-25 20:39:08,100 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2017-12-25 20:39:08,103 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 20:39:08,140 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2017-12-25 20:39:08,316 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 20:39:08,329 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2017-12-25 20:39:08,347 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2017-12-25 20:39:08,378 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 20:39:08,457 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2017-12-25 20:39:09,105 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 20:39:09,142 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2017-12-25 20:39:09,152 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2017-12-25 20:39:09,157 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2017-12-25 20:39:09,169 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 20:39:09,677 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2017-12-25 20:39:10,019 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-25 20:39:10,076 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-12-25 20:39:10,094 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2017-12-25 20:39:10,138 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-25 20:39:10,143 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2017-12-25 20:39:10,143 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2017-12-25 20:39:10,143 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2017-12-25 20:39:10,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2017-12-25 20:39:10,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-25 20:39:10,144 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-25 20:39:10,150 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2017-12-25 20:39:10,150 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-12-25 20:39:11,202 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-12-25 20:39:11,224 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2017-12-25 20:39:11,224 INFO org.mortbay.log: jetty-6.1.26
2017-12-25 20:39:11,295 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2017-12-25 20:39:11,822 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 20:39:11,824 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-25 20:39:11,826 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-25 20:39:15,160 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-25 20:39:15,160 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2017-12-25 20:39:15,266 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-25 20:39:15,273 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2017-12-25 20:39:15,278 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2017-12-25 20:39:15,280 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-25 20:39:15,288 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2017-12-25 20:39:20,013 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 43111 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:43111
2017-12-25 20:39:20,057 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:43111 Node Transitioned from NEW to RUNNING
2017-12-25 20:39:20,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:43111 clusterResource: <memory:8192, vCores:8>
2017-12-25 20:39:20,504 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 38671 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:38671
2017-12-25 20:39:20,504 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:38671 Node Transitioned from NEW to RUNNING
2017-12-25 20:39:20,505 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:38671 clusterResource: <memory:16384, vCores:16>
2017-12-25 20:39:55,444 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2017-12-25 20:40:14,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514201947090_0001' is submitted without priority hence considering default queue/cluster priority: 0
2017-12-25 20:40:14,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514201947090_0001 for the user: hadoop
2017-12-25 20:40:14,789 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2017-12-25 20:40:14,802 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2017-12-25 20:40:14,803 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514201947090_0001
2017-12-25 20:40:14,814 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514201947090_0001
2017-12-25 20:40:14,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from NEW to NEW_SAVING on event=START
2017-12-25 20:40:14,831 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514201947090_0001
2017-12-25 20:40:14,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2017-12-25 20:40:14,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514201947090_0001 user: hadoop leaf-queue of parent: root #applications: 1
2017-12-25 20:40:14,837 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514201947090_0001 from user: hadoop, in queue: default
2017-12-25 20:40:14,932 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2017-12-25 20:40:14,972 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514201947090_0001_000001
2017-12-25 20:40:14,974 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from NEW to SUBMITTED
2017-12-25 20:40:15,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514201947090_0001 from user: hadoop activated in queue: default
2017-12-25 20:40:15,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514201947090_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2017-12-25 20:40:15,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514201947090_0001_000001 to scheduler from user hadoop in queue default
2017-12-25 20:40:15,018 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from SUBMITTED to SCHEDULED
2017-12-25 20:40:15,233 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2017-12-25 20:40:15,233 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514201947090_0001	CONTAINERID=container_1514201947090_0001_01_000001
2017-12-25 20:40:15,234 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514201947090_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:43111, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2017-12-25 20:40:15,234 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514201947090_0001_000001 container=container_1514201947090_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@c9c1688 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2017-12-25 20:40:15,259 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:43111 for container : container_1514201947090_0001_01_000001
2017-12-25 20:40:15,276 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2017-12-25 20:40:15,278 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514201947090_0001_000001
2017-12-25 20:40:15,279 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514201947090_0001 AttemptId: appattempt_1514201947090_0001_000001 MasterContainer: Container: [ContainerId: container_1514201947090_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:43111, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:43111 }, ]
2017-12-25 20:40:15,279 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2017-12-25 20:40:15,280 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2017-12-25 20:40:15,291 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2017-12-25 20:40:15,296 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2017-12-25 20:40:15,301 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514201947090_0001_000001
2017-12-25 20:40:15,380 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514201947090_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:43111, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:43111 }, ] for AM appattempt_1514201947090_0001_000001
2017-12-25 20:40:15,380 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514201947090_0001_000001
2017-12-25 20:40:15,385 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514201947090_0001_000001
2017-12-25 20:40:15,981 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514201947090_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:43111, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:43111 }, ] for AM appattempt_1514201947090_0001_000001
2017-12-25 20:40:15,981 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from ALLOCATED to LAUNCHED
2017-12-25 20:40:16,360 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2017-12-25 20:40:28,546 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514201947090_0001_000001 (auth:SIMPLE)
2017-12-25 20:40:28,562 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514201947090_0001_000001
2017-12-25 20:40:28,587 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from LAUNCHED to RUNNING
2017-12-25 20:40:28,587 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2017-12-25 20:40:28,577 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514201947090_0001	APPATTEMPTID=appattempt_1514201947090_0001_000001
2017-12-25 20:40:29,649 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2017-12-25 20:40:29,650 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514201947090_0001	CONTAINERID=container_1514201947090_0001_01_000002
2017-12-25 20:40:29,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514201947090_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:38671, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2017-12-25 20:40:29,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514201947090_0001_000001 container=container_1514201947090_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@c9c1688 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2017-12-25 20:40:29,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2017-12-25 20:40:29,651 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2017-12-25 20:40:29,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2017-12-25 20:40:29,723 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514201947090_0001	CONTAINERID=container_1514201947090_0001_01_000003
2017-12-25 20:40:29,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514201947090_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:43111, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2017-12-25 20:40:29,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514201947090_0001_000001 container=container_1514201947090_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@c9c1688 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2017-12-25 20:40:29,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2017-12-25 20:40:29,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2017-12-25 20:40:30,359 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:38671 for container : container_1514201947090_0001_01_000002
2017-12-25 20:40:30,367 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2017-12-25 20:40:30,368 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:43111 for container : container_1514201947090_0001_01_000003
2017-12-25 20:40:30,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2017-12-25 20:40:33,423 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2017-12-25 20:40:33,612 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514201947090_0001
2017-12-25 20:40:35,627 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2017-12-25 20:49:22,060 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2017-12-25 21:08:36,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514201947090_0001_000001 with final state: FINISHING, and exit status: -1000
2017-12-25 21:08:36,149 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from RUNNING to FINAL_SAVING
2017-12-25 21:08:36,149 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514201947090_0001 with final state: FINISHING
2017-12-25 21:08:36,149 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2017-12-25 21:08:36,150 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from FINAL_SAVING to FINISHING
2017-12-25 21:08:36,150 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514201947090_0001
2017-12-25 21:08:36,150 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2017-12-25 21:08:36,183 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2017-12-25 21:08:36,184 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514201947090_0001	CONTAINERID=container_1514201947090_0001_01_000003
2017-12-25 21:08:36,185 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514201947090_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:43111, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2017-12-25 21:08:36,257 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514201947090_0001 unregistered successfully. 
2017-12-25 21:08:36,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2017-12-25 21:08:36,760 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514201947090_0001_000001
2017-12-25 21:08:36,760 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514201947090_0001	CONTAINERID=container_1514201947090_0001_01_000001
2017-12-25 21:08:36,761 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514201947090_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:43111, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2017-12-25 21:08:36,761 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514201947090_0001_000001
2017-12-25 21:08:36,762 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514201947090_0001_000001 State change from FINISHING to FINISHED
2017-12-25 21:08:36,763 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514201947090_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2017-12-25 21:08:36,764 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514201947090_0001_000001 is done. finalState=FINISHED
2017-12-25 21:08:36,764 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514201947090_0001
2017-12-25 21:08:36,767 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514201947090_0001_000001
2017-12-25 21:08:36,770 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514201947090_0001_01_000002 Container Transitioned from RUNNING to KILLED
2017-12-25 21:08:36,770 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514201947090_0001	CONTAINERID=container_1514201947090_0001_01_000002
2017-12-25 21:08:36,771 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514201947090_0001 requests cleared
2017-12-25 21:08:36,772 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514201947090_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2017-12-25 21:08:36,772 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514201947090_0001 user: hadoop leaf-queue of parent: root #applications: 0
2017-12-25 21:08:36,773 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514201947090_0001,name=Spark shell,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514201947090_0001/,appMasterHost=192.168.28.131,startTime=1514202014789,finishTime=1514203716149,finalStatus=SUCCEEDED,memorySeconds=5196234,vcoreSeconds=3387,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2017-12-25 21:08:37,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514201947090_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2017-12-25 21:08:37,234 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514201947090_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:38671, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2017-12-25 21:08:38,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514201947090_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2017-12-25 21:08:38,774 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514201947090_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2017-12-25 21:09:03,850 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker01.local:43111 has shutdown, hence unregistering the node.
2017-12-25 21:09:03,855 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker01.local:43111 as it is now SHUTDOWN
2017-12-25 21:09:03,855 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:43111 Node Transitioned from RUNNING to SHUTDOWN
2017-12-25 21:09:03,856 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker01.local:43111 clusterResource: <memory:8192, vCores:8>
2017-12-25 21:09:03,862 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker02.local:38671 has shutdown, hence unregistering the node.
2017-12-25 21:09:03,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker02.local:38671 as it is now SHUTDOWN
2017-12-25 21:09:03,866 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:38671 Node Transitioned from RUNNING to SHUTDOWN
2017-12-25 21:09:03,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker02.local:38671 clusterResource: <memory:0, vCores:0>
2017-12-25 21:09:27,891 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2017-12-25 21:09:28,058 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-25 21:09:28,064 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-25 21:09:28,188 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2017-12-25 21:09:28,210 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 21:09:28,211 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2017-12-25 21:09:28,211 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2017-12-25 21:09:28,217 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2017-12-25 21:09:28,217 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2017-12-25 21:09:28,218 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2017-12-25 21:09:28,219 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2017-12-25 21:09:28,249 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 21:09:28,250 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2017-12-25 21:09:28,254 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 21:09:28,254 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2017-12-25 21:09:28,276 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-25 21:09:28,277 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2017-12-25 21:09:28,279 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2017-12-25 21:09:28,279 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2017-12-25 21:09:28,282 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-25 21:09:28,283 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-25 21:09:28,283 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-25 21:09:28,283 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2017-12-25 21:09:28,285 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2017-12-25 21:09:28,285 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-25 21:09:28,287 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2017-12-25 21:09:28,287 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2017-12-25 21:09:28,288 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-25 21:09:28,288 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2017-12-25 21:09:28,289 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2017-12-26 22:11:12,481 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2017-12-26 22:11:12,493 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-26 22:11:16,474 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2017-12-26 22:11:16,585 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2017-12-26 22:11:16,690 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2017-12-26 22:11:17,197 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2017-12-26 22:11:17,800 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2017-12-26 22:11:17,809 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2017-12-26 22:11:17,819 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2017-12-26 22:11:17,949 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2017-12-26 22:11:17,984 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2017-12-26 22:11:17,984 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2017-12-26 22:11:18,040 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2017-12-26 22:11:18,042 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2017-12-26 22:11:18,044 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2017-12-26 22:11:18,046 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2017-12-26 22:11:18,195 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-26 22:11:18,369 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2017-12-26 22:11:18,369 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2017-12-26 22:11:18,412 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2017-12-26 22:11:18,438 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2017-12-26 22:11:18,442 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2017-12-26 22:11:18,455 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2017-12-26 22:11:18,459 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2017-12-26 22:11:18,494 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2017-12-26 22:11:18,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2017-12-26 22:11:18,687 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2017-12-26 22:11:18,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2017-12-26 22:11:18,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2017-12-26 22:11:18,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2017-12-26 22:11:18,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2017-12-26 22:11:18,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2017-12-26 22:11:18,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2017-12-26 22:11:18,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-26 22:11:18,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2017-12-26 22:11:18,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2017-12-26 22:11:18,753 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2017-12-26 22:11:18,763 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2017-12-26 22:11:18,787 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2017-12-26 22:11:18,788 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2017-12-26 22:11:18,827 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2017-12-26 22:11:18,845 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2017-12-26 22:11:18,846 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2017-12-26 22:11:18,850 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2017-12-26 22:11:18,851 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-26 22:11:18,852 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2017-12-26 22:11:18,853 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-26 22:11:18,857 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-26 22:11:18,857 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-26 22:11:18,857 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2017-12-26 22:11:18,857 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2017-12-26 22:11:18,863 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2017-12-26 22:11:18,995 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-26 22:11:19,052 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2017-12-26 22:11:19,713 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2017-12-26 22:11:19,715 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-26 22:11:19,721 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2017-12-26 22:11:19,896 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-26 22:11:19,922 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2017-12-26 22:11:19,948 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2017-12-26 22:11:19,951 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-26 22:11:19,952 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2017-12-26 22:11:20,301 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-26 22:11:20,304 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2017-12-26 22:11:20,362 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2017-12-26 22:11:20,362 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-26 22:11:20,363 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2017-12-26 22:11:20,417 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2017-12-26 22:11:20,673 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-26 22:11:20,705 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-12-26 22:11:20,724 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2017-12-26 22:11:20,747 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-26 22:11:20,762 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2017-12-26 22:11:20,763 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2017-12-26 22:11:20,763 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2017-12-26 22:11:20,764 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2017-12-26 22:11:20,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-26 22:11:20,765 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-26 22:11:20,773 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2017-12-26 22:11:20,773 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-12-26 22:11:22,193 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-12-26 22:11:22,197 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2017-12-26 22:11:22,197 INFO org.mortbay.log: jetty-6.1.26
2017-12-26 22:11:22,359 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2017-12-26 22:11:23,199 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-26 22:11:23,224 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2017-12-26 22:11:23,278 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2017-12-26 22:11:26,838 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-26 22:11:26,842 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2017-12-26 22:11:26,992 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2017-12-26 22:11:27,003 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2017-12-26 22:11:27,008 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2017-12-26 22:11:27,014 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-26 22:11:27,015 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2017-12-26 22:11:32,379 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 36399 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:36399
2017-12-26 22:11:32,383 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 42901 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:42901
2017-12-26 22:11:32,396 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:36399 Node Transitioned from NEW to RUNNING
2017-12-26 22:11:32,397 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:42901 Node Transitioned from NEW to RUNNING
2017-12-26 22:11:32,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:36399 clusterResource: <memory:8192, vCores:8>
2017-12-26 22:11:32,473 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:42901 clusterResource: <memory:16384, vCores:16>
2017-12-26 22:21:39,802 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2017-12-26 22:44:52,816 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2017-12-26 22:44:52,842 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-26 22:44:52,846 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2017-12-26 22:44:52,953 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2017-12-26 22:44:52,972 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2017-12-26 22:44:52,978 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-26 22:44:52,979 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2017-12-26 22:44:52,991 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2017-12-26 22:44:52,996 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-26 22:44:52,997 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2017-12-26 22:44:52,997 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2017-12-26 22:44:52,998 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2017-12-26 22:44:53,008 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2017-12-26 22:44:53,010 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-26 22:44:53,010 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2017-12-26 22:44:53,027 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2017-12-26 22:44:53,028 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2017-12-26 22:44:53,030 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-26 22:44:53,031 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2017-12-26 22:44:53,031 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-26 22:44:53,031 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2017-12-26 22:44:53,031 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2017-12-26 22:44:53,032 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-12-26 22:44:53,033 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2017-12-26 22:44:53,034 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2017-12-26 22:44:53,038 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2017-12-26 22:44:53,039 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2017-12-26 22:44:53,039 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2017-12-26 22:44:53,040 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2017-12-26 22:44:53,040 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-03 13:16:42,289 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-03 13:16:42,306 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-03 13:16:42,760 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-03 13:16:42,913 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-03 13:16:43,092 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-03 13:16:43,533 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-03 13:16:44,146 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-03 13:16:44,160 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-03 13:16:44,183 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-03 13:16:44,371 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-03 13:16:44,388 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-03 13:16:44,388 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-03 13:16:44,447 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-03 13:16:44,450 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-03 13:16:44,452 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-03 13:16:44,454 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-03 13:16:44,607 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-03 13:16:44,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-03 13:16:44,824 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-03 13:16:44,848 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-03 13:16:44,877 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-03 13:16:44,892 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-03 13:16:44,932 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-03 13:16:44,936 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-03 13:16:44,991 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-03 13:16:45,260 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-03 13:16:45,260 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-03 13:16:45,274 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-03 13:16:45,274 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-03 13:16:45,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-03 13:16:45,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-03 13:16:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-03 13:16:45,335 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-03 13:16:45,459 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-03 13:16:45,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-03 13:16:45,460 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-03 13:16:45,462 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-03 13:16:45,466 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-03 13:16:45,483 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-03 13:16:45,484 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-03 13:16:45,510 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-03 13:16:45,580 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-03 13:16:45,581 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-03 13:16:45,581 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-03 13:16:45,581 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 13:16:45,583 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-03 13:16:45,583 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-03 13:16:45,597 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-03 13:16:45,597 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 13:16:45,597 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-03 13:16:45,597 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-03 13:16:45,609 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-03 13:16:45,716 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 13:16:45,781 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-03 13:16:46,337 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-03 13:16:46,339 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 13:16:46,430 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-03 13:16:46,579 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 13:16:46,607 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-03 13:16:46,666 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-03 13:16:46,679 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 13:16:46,689 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-03 13:16:47,352 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 13:16:47,365 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-03 13:16:47,371 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-03 13:16:47,386 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 13:16:47,386 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-03 13:16:47,867 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-03 13:16:48,302 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-03 13:16:48,348 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-03 13:16:48,378 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-03 13:16:48,392 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-03 13:16:48,397 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-03 13:16:48,398 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-03 13:16:48,398 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-03 13:16:48,399 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-03 13:16:48,399 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-03 13:16:48,399 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-03 13:16:48,409 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-03 13:16:48,409 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-03 13:16:49,697 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-03 13:16:49,701 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-03 13:16:49,701 INFO org.mortbay.log: jetty-6.1.26
2018-01-03 13:16:49,894 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-03 13:16:50,340 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 13:16:50,349 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-03 13:16:50,350 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 13:16:55,110 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-03 13:16:55,110 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-03 13:16:55,262 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 13:16:55,263 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-03 13:16:55,346 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-03 13:16:55,347 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 13:16:55,360 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-03 13:16:58,971 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 34223 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:34223
2018-01-03 13:16:58,984 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:34223 Node Transitioned from NEW to RUNNING
2018-01-03 13:16:59,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:34223 clusterResource: <memory:8192, vCores:8>
2018-01-03 13:17:00,255 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 33765 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:33765
2018-01-03 13:17:00,256 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:33765 Node Transitioned from NEW to RUNNING
2018-01-03 13:17:00,257 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:33765 clusterResource: <memory:16384, vCores:16>
2018-01-03 13:27:28,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-03 13:52:31,210 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-03 13:52:44,157 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514953005485_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 13:52:44,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514953005485_0001 for the user: hadoop
2018-01-03 13:52:44,191 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 13:52:44,202 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-03 13:52:44,202 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514953005485_0001
2018-01-03 13:52:44,211 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514953005485_0001
2018-01-03 13:52:44,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from NEW to NEW_SAVING on event=START
2018-01-03 13:52:44,242 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514953005485_0001
2018-01-03 13:52:44,244 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 13:52:44,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514953005485_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 13:52:44,256 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514953005485_0001 from user: hadoop, in queue: default
2018-01-03 13:52:44,338 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 13:52:44,394 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514953005485_0001_000001
2018-01-03 13:52:44,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from NEW to SUBMITTED
2018-01-03 13:52:44,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514953005485_0001 from user: hadoop activated in queue: default
2018-01-03 13:52:44,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514953005485_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 13:52:44,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514953005485_0001_000001 to scheduler from user hadoop in queue default
2018-01-03 13:52:44,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 13:52:44,928 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:52:44,929 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0001	CONTAINERID=container_1514953005485_0001_01_000001
2018-01-03 13:52:44,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:34223, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 13:52:44,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0001_000001 container=container_1514953005485_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@2249a8e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:52:44,966 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:34223 for container : container_1514953005485_0001_01_000001
2018-01-03 13:52:44,985 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:52:44,987 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514953005485_0001_000001
2018-01-03 13:52:44,987 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514953005485_0001 AttemptId: appattempt_1514953005485_0001_000001 MasterContainer: Container: [ContainerId: container_1514953005485_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:34223, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:34223 }, ]
2018-01-03 13:52:44,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 13:52:44,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 13:52:45,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 13:52:45,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 13:52:45,022 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514953005485_0001_000001
2018-01-03 13:52:45,116 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514953005485_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:34223, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:34223 }, ] for AM appattempt_1514953005485_0001_000001
2018-01-03 13:52:45,116 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514953005485_0001_000001
2018-01-03 13:52:45,122 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514953005485_0001_000001
2018-01-03 13:52:45,797 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514953005485_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:34223, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:34223 }, ] for AM appattempt_1514953005485_0001_000001
2018-01-03 13:52:45,798 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 13:52:46,068 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 13:53:00,551 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514953005485_0001_000001 (auth:SIMPLE)
2018-01-03 13:53:00,569 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514953005485_0001_000001
2018-01-03 13:53:00,570 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514953005485_0001	APPATTEMPTID=appattempt_1514953005485_0001_000001
2018-01-03 13:53:00,570 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from LAUNCHED to RUNNING
2018-01-03 13:53:00,570 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 13:53:01,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:53:01,274 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0001	CONTAINERID=container_1514953005485_0001_01_000002
2018-01-03 13:53:01,274 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:34223, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 13:53:01,274 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0001_000001 container=container_1514953005485_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@2249a8e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:53:01,283 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 13:53:01,283 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 13:53:01,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:53:01,284 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0001	CONTAINERID=container_1514953005485_0001_01_000003
2018-01-03 13:53:01,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:33765, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 13:53:01,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0001_000001 container=container_1514953005485_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@2249a8e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:53:01,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 13:53:01,284 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 13:53:01,518 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:34223 for container : container_1514953005485_0001_01_000002
2018-01-03 13:53:01,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:53:01,522 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:33765 for container : container_1514953005485_0001_01_000003
2018-01-03 13:53:01,524 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:53:02,576 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 13:53:03,244 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 13:53:04,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514953005485_0001
2018-01-03 13:53:58,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-03 13:53:58,243 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0001	CONTAINERID=container_1514953005485_0001_01_000003
2018-01-03 13:53:58,245 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514953005485_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:33765, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 13:53:58,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514953005485_0001_000001 with final state: FINISHING, and exit status: -1000
2018-01-03 13:53:58,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 13:53:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514953005485_0001 with final state: FINISHING
2018-01-03 13:53:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-03 13:53:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514953005485_0001
2018-01-03 13:53:58,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from FINAL_SAVING to FINISHING
2018-01-03 13:53:58,328 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-03 13:53:58,480 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514953005485_0001 unregistered successfully. 
2018-01-03 13:53:58,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-03 13:53:58,815 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0001	CONTAINERID=container_1514953005485_0001_01_000002
2018-01-03 13:53:58,815 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514953005485_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:34223, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-03 13:53:59,271 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 13:53:59,271 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514953005485_0001_000001
2018-01-03 13:53:59,271 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0001	CONTAINERID=container_1514953005485_0001_01_000001
2018-01-03 13:53:59,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514953005485_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:34223, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 13:53:59,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514953005485_0001_000001
2018-01-03 13:53:59,273 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0001_000001 State change from FINISHING to FINISHED
2018-01-03 13:53:59,275 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-03 13:53:59,275 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514953005485_0001_000001 is done. finalState=FINISHED
2018-01-03 13:53:59,277 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514953005485_0001
2018-01-03 13:53:59,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514953005485_0001 requests cleared
2018-01-03 13:53:59,277 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514953005485_0001_000001
2018-01-03 13:53:59,279 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514953005485_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 13:53:59,279 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514953005485_0001 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 13:53:59,289 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514953005485_0001,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514953005485_0001/,appMasterHost=192.168.28.132,startTime=1514955164191,finishTime=1514955238327,finalStatus=SUCCEEDED,memorySeconds=310622,vcoreSeconds=187,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 13:54:01,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514953005485_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 13:54:01,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514953005485_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 13:54:57,667 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2018-01-03 13:55:08,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514953005485_0002' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 13:55:08,305 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514953005485_0002 for the user: hadoop
2018-01-03 13:55:08,305 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 13:55:08,306 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user hadoop
2018-01-03 13:55:08,306 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514953005485_0002
2018-01-03 13:55:08,306 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514953005485_0002
2018-01-03 13:55:08,307 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0002 State change from NEW to NEW_SAVING on event=START
2018-01-03 13:55:08,307 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514953005485_0002
2018-01-03 13:55:08,308 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 13:55:08,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514953005485_0002 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 13:55:08,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514953005485_0002 from user: hadoop, in queue: default
2018-01-03 13:55:08,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 13:55:08,310 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514953005485_0002_000001
2018-01-03 13:55:08,310 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from NEW to SUBMITTED
2018-01-03 13:55:08,310 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514953005485_0002 from user: hadoop activated in queue: default
2018-01-03 13:55:08,311 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514953005485_0002 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 13:55:08,311 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514953005485_0002_000001 to scheduler from user hadoop in queue default
2018-01-03 13:55:08,312 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 13:55:08,824 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:55:08,824 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000001
2018-01-03 13:55:08,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:33765, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 13:55:08,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0002_000001 container=container_1514953005485_0002_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@5b6309e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:55:08,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 13:55:08,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 13:55:08,826 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:33765 for container : container_1514953005485_0002_01_000001
2018-01-03 13:55:08,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:55:08,829 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514953005485_0002_000001
2018-01-03 13:55:08,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514953005485_0002 AttemptId: appattempt_1514953005485_0002_000001 MasterContainer: Container: [ContainerId: container_1514953005485_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:33765, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:33765 }, ]
2018-01-03 13:55:08,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 13:55:08,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 13:55:08,830 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514953005485_0002_000001
2018-01-03 13:55:08,837 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514953005485_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:33765, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:33765 }, ] for AM appattempt_1514953005485_0002_000001
2018-01-03 13:55:08,837 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514953005485_0002_000001
2018-01-03 13:55:08,837 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514953005485_0002_000001
2018-01-03 13:55:08,864 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514953005485_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:33765, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:33765 }, ] for AM appattempt_1514953005485_0002_000001
2018-01-03 13:55:08,864 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 13:55:09,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 13:55:18,674 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514953005485_0002_000001 (auth:SIMPLE)
2018-01-03 13:55:18,694 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514953005485_0002_000001
2018-01-03 13:55:18,695 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514953005485_0002	APPATTEMPTID=appattempt_1514953005485_0002_000001
2018-01-03 13:55:18,695 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from LAUNCHED to RUNNING
2018-01-03 13:55:18,695 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 13:55:18,919 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:55:18,919 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000002
2018-01-03 13:55:18,919 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:33765, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 13:55:18,919 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0002_000001 container=container_1514953005485_0002_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@5b6309e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:55:18,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 13:55:18,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 13:55:18,947 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:33765 for container : container_1514953005485_0002_01_000002
2018-01-03 13:55:18,954 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:55:19,005 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:55:19,005 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000003
2018-01-03 13:55:19,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:34223, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 13:55:19,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0002_000001 container=container_1514953005485_0002_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@5b6309e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:55:19,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 13:55:19,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 13:55:19,234 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:34223 for container : container_1514953005485_0002_01_000003
2018-01-03 13:55:19,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:55:19,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 13:55:19,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-03 13:55:19,831 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000004
2018-01-03 13:55:19,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514953005485_0002_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:33765, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-03 13:55:19,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514953005485_0002_000001 container=container_1514953005485_0002_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@5b6309e6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 13:55:19,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-03 13:55:19,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 13:55:20,159 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 13:55:22,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514953005485_0002
2018-01-03 13:55:22,063 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 13:55:24,924 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-03 13:55:24,924 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000004
2018-01-03 13:55:24,944 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514953005485_0002_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:33765, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-03 14:00:38,512 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker01.local:33765 has shutdown, hence unregistering the node.
2018-01-03 14:00:38,512 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker02.local:34223 has shutdown, hence unregistering the node.
2018-01-03 14:00:38,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker01.local:33765 as it is now SHUTDOWN
2018-01-03 14:00:38,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:33765 Node Transitioned from RUNNING to SHUTDOWN
2018-01-03 14:00:38,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker02.local:34223 as it is now SHUTDOWN
2018-01-03 14:00:38,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:34223 Node Transitioned from RUNNING to SHUTDOWN
2018-01-03 14:00:38,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000001 Container Transitioned from RUNNING to KILLED
2018-01-03 14:00:38,519 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000001
2018-01-03 14:00:38,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514953005485_0002_000001 with final state: FAILED, and exit status: -100
2018-01-03 14:00:38,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000002 Container Transitioned from RUNNING to KILLED
2018-01-03 14:00:38,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 14:00:38,521 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000002
2018-01-03 14:00:38,523 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514953005485_0002_000001
2018-01-03 14:00:38,523 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514953005485_0002_000001
2018-01-03 14:00:38,523 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000001 State change from FINAL_SAVING to FAILED
2018-01-03 14:00:38,523 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 0. The max attempts is 2
2018-01-03 14:00:38,524 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514953005485_0002 State change from RUNNING to ACCEPTED on event=ATTEMPT_FAILED
2018-01-03 14:00:38,524 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514953005485_0002_000002
2018-01-03 14:00:38,524 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker01.local:33765 clusterResource: <memory:8192, vCores:8>
2018-01-03 14:00:38,524 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000002 State change from NEW to SUBMITTED
2018-01-03 14:00:38,525 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514953005485_0002_01_000003 Container Transitioned from RUNNING to KILLED
2018-01-03 14:00:38,525 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514953005485_0002	CONTAINERID=container_1514953005485_0002_01_000003
2018-01-03 14:00:38,525 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514953005485_0002_000001
2018-01-03 14:00:38,525 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker02.local:34223 clusterResource: <memory:0, vCores:0>
2018-01-03 14:00:38,525 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514953005485_0002_000001 is done. finalState=FAILED
2018-01-03 14:00:38,528 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514953005485_0002 requests cleared
2018-01-03 14:00:38,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514953005485_0002 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:00:38,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Skipping activateApplications for appattempt_1514953005485_0002_000002 since cluster resource is <memory:0, vCores:0>
2018-01-03 14:00:38,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514953005485_0002 user: hadoop, leaf-queue: default #user-pending-applications: 1 #user-active-applications: 0 #queue-pending-applications: 1 #queue-active-applications: 0
2018-01-03 14:00:38,530 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514953005485_0002_000002 to scheduler from user hadoop in queue default
2018-01-03 14:00:38,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514953005485_0002_000002 State change from SUBMITTED to SCHEDULED
2018-01-03 14:00:54,147 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-03 14:00:54,156 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-03 14:00:54,159 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-03 14:00:54,263 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-03 14:00:54,293 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-03 14:00:54,294 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-03 14:00:54,294 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 14:00:54,306 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-03 14:00:54,307 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-03 14:00:54,308 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 14:00:54,309 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-03 14:00:54,309 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-03 14:00:54,327 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-03 14:00:54,328 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-03 14:00:54,330 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 14:00:54,337 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-03 14:00:54,337 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-03 14:00:54,341 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-03 14:00:54,339 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 14:00:54,342 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-03 14:00:54,343 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-03 14:00:54,345 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-03 14:00:54,347 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-03 14:00:54,349 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-03 14:00:54,349 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-03 14:00:54,350 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-03 14:00:54,351 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-03 14:00:54,351 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-03 14:00:54,352 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-03 14:00:54,352 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-03 14:03:21,349 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-03 14:03:21,363 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-03 14:03:21,981 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-03 14:03:22,289 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-03 14:03:22,523 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-03 14:03:23,230 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-03 14:03:24,097 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-03 14:03:24,135 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-03 14:03:24,162 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-03 14:03:24,481 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-03 14:03:24,487 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-03 14:03:24,487 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-03 14:03:24,723 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-03 14:03:24,725 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-03 14:03:24,727 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-03 14:03:24,729 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-03 14:03:24,826 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-03 14:03:25,134 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-03 14:03:25,134 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-03 14:03:25,175 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-03 14:03:25,303 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-03 14:03:25,307 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-03 14:03:25,317 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-03 14:03:25,320 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-03 14:03:25,447 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-03 14:03:25,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-03 14:03:25,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-03 14:03:25,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-03 14:03:25,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-03 14:03:25,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-03 14:03:25,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-03 14:03:25,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-03 14:03:25,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-03 14:03:25,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-03 14:03:25,879 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-03 14:03:25,879 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-03 14:03:25,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-03 14:03:25,888 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-03 14:03:25,907 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-03 14:03:25,907 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-03 14:03:25,937 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-03 14:03:25,980 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-03 14:03:25,980 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-03 14:03:25,986 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-03 14:03:26,014 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 14:03:26,016 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-03 14:03:26,016 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-03 14:03:26,019 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-03 14:03:26,019 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 14:03:26,020 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-03 14:03:26,020 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-03 14:03:26,025 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-03 14:03:26,158 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 14:03:26,225 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-03 14:03:26,928 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-03 14:03:26,938 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-03 14:03:26,935 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 14:03:27,107 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 14:03:27,160 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-03 14:03:27,344 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-03 14:03:27,345 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 14:03:27,346 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-03 14:03:27,744 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 14:03:27,759 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-03 14:03:27,783 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-03 14:03:27,807 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 14:03:27,812 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-03 14:03:28,274 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-03 14:03:28,660 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-03 14:03:28,736 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-03 14:03:28,752 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-03 14:03:28,783 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-03 14:03:28,789 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-03 14:03:28,789 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-03 14:03:28,789 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-03 14:03:28,790 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-03 14:03:28,802 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-03 14:03:28,802 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-03 14:03:28,808 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-03 14:03:28,809 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-03 14:03:30,860 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8032, call Call#371 Retry#0 org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getApplicationReport from 192.168.28.132:55494
org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException: Application with id 'application_1514953005485_0002' doesn't exist in RM.
	at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getApplicationReport(ClientRMService.java:359)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.getApplicationReport(ApplicationClientProtocolPBServiceImpl.java:214)
	at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:497)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:847)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:790)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2486)
2018-01-03 14:03:31,505 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-03 14:03:31,509 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-03 14:03:31,510 INFO org.mortbay.log: jetty-6.1.26
2018-01-03 14:03:31,594 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-03 14:03:32,595 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 14:03:32,606 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-03 14:03:32,624 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-03 14:03:37,366 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-03 14:03:37,367 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-03 14:03:37,888 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-03 14:03:37,914 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-03 14:03:37,921 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-03 14:03:37,946 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-03 14:03:37,980 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-03 14:03:43,937 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 45394 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:45394
2018-01-03 14:03:43,937 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 41166 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:41166
2018-01-03 14:03:44,036 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:45394 Node Transitioned from NEW to RUNNING
2018-01-03 14:03:44,036 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:41166 Node Transitioned from NEW to RUNNING
2018-01-03 14:03:44,065 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:45394 clusterResource: <memory:8192, vCores:8>
2018-01-03 14:03:44,066 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:41166 clusterResource: <memory:16384, vCores:16>
2018-01-03 14:04:19,917 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-03 14:04:32,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 14:04:32,839 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0001 for the user: hadoop
2018-01-03 14:04:32,866 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 14:04:32,875 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-03 14:04:32,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0001
2018-01-03 14:04:32,878 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0001
2018-01-03 14:04:32,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from NEW to NEW_SAVING on event=START
2018-01-03 14:04:32,888 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0001
2018-01-03 14:04:32,947 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 14:04:32,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 14:04:32,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0001 from user: hadoop, in queue: default
2018-01-03 14:04:32,983 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 14:04:33,030 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0001_000001
2018-01-03 14:04:33,031 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from NEW to SUBMITTED
2018-01-03 14:04:33,057 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0001 from user: hadoop activated in queue: default
2018-01-03 14:04:33,058 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:04:33,058 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0001_000001 to scheduler from user hadoop in queue default
2018-01-03 14:04:33,061 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 14:04:33,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:04:33,598 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000001
2018-01-03 14:04:33,600 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:04:33,602 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0001_000001 container=container_1514955805909_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1a5abddb clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:04:33,605 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:04:33,607 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:04:33,665 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0001_01_000001
2018-01-03 14:04:33,680 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:04:33,683 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0001_000001
2018-01-03 14:04:33,683 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0001 AttemptId: appattempt_1514955805909_0001_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 14:04:33,694 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:04:33,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:04:33,704 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0001_000001
2018-01-03 14:04:33,785 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0001_000001
2018-01-03 14:04:33,786 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0001_000001
2018-01-03 14:04:33,793 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0001_000001
2018-01-03 14:04:34,284 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0001_000001
2018-01-03 14:04:34,284 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 14:04:34,569 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:04:44,611 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514955805909_0001_000001 (auth:SIMPLE)
2018-01-03 14:04:44,628 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514955805909_0001_000001
2018-01-03 14:04:44,630 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514955805909_0001	APPATTEMPTID=appattempt_1514955805909_0001_000001
2018-01-03 14:04:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from LAUNCHED to RUNNING
2018-01-03 14:04:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 14:04:45,511 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:04:45,511 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000002
2018-01-03 14:04:45,511 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 14:04:45,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0001_000001 container=container_1514955805909_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1a5abddb clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:04:45,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 14:04:45,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 14:04:45,587 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0001_01_000002
2018-01-03 14:04:45,588 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:04:45,842 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:04:45,843 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000003
2018-01-03 14:04:45,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 14:04:45,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0001_000001 container=container_1514955805909_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1a5abddb clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:04:45,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 14:04:45,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 14:04:46,479 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0001_01_000003
2018-01-03 14:04:52,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:04:52,624 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:04:52,629 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:04:52,629 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000004
2018-01-03 14:04:52,629 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-03 14:04:52,629 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0001_000001 container=container_1514955805909_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1a5abddb clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:04:52,629 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-03 14:04:52,630 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 14:04:53,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:04:55,690 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0001
2018-01-03 14:04:55,785 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:04:59,460 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-03 14:04:59,460 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000004
2018-01-03 14:04:59,558 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-03 14:07:57,970 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:07:57,971 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000003
2018-01-03 14:07:57,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-03 14:07:57,971 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0001_000001 with final state: FINISHING, and exit status: -1000
2018-01-03 14:07:57,972 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 14:07:57,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0001 with final state: FINISHING
2018-01-03 14:07:57,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-03 14:07:57,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from FINAL_SAVING to FINISHING
2018-01-03 14:07:57,973 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0001
2018-01-03 14:07:57,974 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-03 14:07:58,082 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514955805909_0001 unregistered successfully. 
2018-01-03 14:07:58,696 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:07:58,696 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000001
2018-01-03 14:07:58,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:07:58,699 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0001_000001
2018-01-03 14:07:58,702 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0001_000001
2018-01-03 14:07:58,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0001_000001 State change from FINISHING to FINISHED
2018-01-03 14:07:58,707 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-03 14:07:58,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0001_000001 is done. finalState=FINISHED
2018-01-03 14:07:58,707 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0001_01_000002 Container Transitioned from RUNNING to KILLED
2018-01-03 14:07:58,707 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0001	CONTAINERID=container_1514955805909_0001_01_000002
2018-01-03 14:07:58,708 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514955805909_0001
2018-01-03 14:07:58,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0001 requests cleared
2018-01-03 14:07:58,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:07:58,718 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0001 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 14:07:58,725 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0001,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514955805909_0001/,appMasterHost=192.168.28.131,startTime=1514955872866,finishTime=1514956077973,finalStatus=SUCCEEDED,memorySeconds=1013158,vcoreSeconds=596,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 14:07:58,726 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Container container_1514955805909_0001_01_000002 already scheduled for cleanup, no further processing
2018-01-03 14:07:58,726 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Container container_1514955805909_0001_01_000002 was running but not reported from hadoop-worker02.local:45394
2018-01-03 14:07:58,719 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514955805909_0001_000001
2018-01-03 14:07:58,739 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:07:58,741 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:07:59,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:08:00,703 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:08:23,965 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2018-01-03 14:08:35,076 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0002' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 14:08:35,076 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0002 for the user: hadoop
2018-01-03 14:08:35,076 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 14:08:35,077 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0002
2018-01-03 14:08:35,077 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from NEW to NEW_SAVING on event=START
2018-01-03 14:08:35,083 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0002
2018-01-03 14:08:35,083 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 14:08:35,083 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user hadoop
2018-01-03 14:08:35,083 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0002
2018-01-03 14:08:35,083 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0002 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 14:08:35,083 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0002 from user: hadoop, in queue: default
2018-01-03 14:08:35,084 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 14:08:35,084 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0002_000001
2018-01-03 14:08:35,084 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from NEW to SUBMITTED
2018-01-03 14:08:35,085 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0002 from user: hadoop activated in queue: default
2018-01-03 14:08:35,085 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0002 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:08:35,085 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0002_000001 to scheduler from user hadoop in queue default
2018-01-03 14:08:35,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 14:08:35,882 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:08:35,882 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0002	CONTAINERID=container_1514955805909_0002_01_000001
2018-01-03 14:08:35,882 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:08:35,882 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0002_000001 container=container_1514955805909_0002_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@55ab0444 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:08:35,884 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0002_01_000001
2018-01-03 14:08:35,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:08:35,891 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0002_000001
2018-01-03 14:08:35,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:08:35,892 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0002 AttemptId: appattempt_1514955805909_0002_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0002_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 14:08:35,892 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:08:35,892 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:08:35,892 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:08:35,893 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0002_000001
2018-01-03 14:08:35,903 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0002_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0002_000001
2018-01-03 14:08:35,903 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0002_000001
2018-01-03 14:08:35,903 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0002_000001
2018-01-03 14:08:35,943 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0002_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0002_000001
2018-01-03 14:08:35,943 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 14:08:36,892 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:08:48,566 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514955805909_0002_000001 (auth:SIMPLE)
2018-01-03 14:08:48,583 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514955805909_0002_000001
2018-01-03 14:08:48,583 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514955805909_0002	APPATTEMPTID=appattempt_1514955805909_0002_000001
2018-01-03 14:08:48,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from LAUNCHED to RUNNING
2018-01-03 14:08:48,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 14:08:49,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:08:49,016 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0002	CONTAINERID=container_1514955805909_0002_01_000002
2018-01-03 14:08:49,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 14:08:49,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0002_000001 container=container_1514955805909_0002_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@55ab0444 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:08:49,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 14:08:49,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 14:08:49,045 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0002_01_000002
2018-01-03 14:08:49,051 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:08:49,720 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:08:49,721 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0002	CONTAINERID=container_1514955805909_0002_01_000003
2018-01-03 14:08:49,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 14:08:49,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0002_000001 container=container_1514955805909_0002_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@55ab0444 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:08:49,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 14:08:49,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 14:08:49,995 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:08:50,455 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0002_01_000003
2018-01-03 14:08:50,458 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:08:50,645 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:08:53,212 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0002
2018-01-03 14:09:43,588 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:09:43,588 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0002	CONTAINERID=container_1514955805909_0002_01_000003
2018-01-03 14:09:43,603 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:09:44,033 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0002_000001 with final state: FINISHING, and exit status: -1000
2018-01-03 14:09:44,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 14:09:44,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0002 with final state: FINISHING
2018-01-03 14:09:44,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-03 14:09:44,034 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0002
2018-01-03 14:09:44,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from FINAL_SAVING to FINISHING
2018-01-03 14:09:44,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-03 14:09:44,358 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514955805909_0002 unregistered successfully. 
2018-01-03 14:09:44,603 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:09:44,606 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0002	CONTAINERID=container_1514955805909_0002_01_000002
2018-01-03 14:09:44,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-03 14:09:44,933 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:09:44,933 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0002_000001
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0002	CONTAINERID=container_1514955805909_0002_01_000001
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0002_000001
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0002_000001 State change from FINISHING to FINISHED
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514955805909_0002
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0002_000001 is done. finalState=FINISHED
2018-01-03 14:09:44,934 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0002,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514955805909_0002/,appMasterHost=192.168.28.132,startTime=1514956115076,finishTime=1514956184034,finalStatus=SUCCEEDED,memorySeconds=294872,vcoreSeconds=177,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 14:09:44,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0002 requests cleared
2018-01-03 14:09:44,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0002 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:09:44,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0002 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 14:09:44,943 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514955805909_0002_000001
2018-01-03 14:09:46,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0002_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:09:46,950 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0002_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:10:04,007 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2018-01-03 14:10:18,063 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0003' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 14:10:18,064 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0003 for the user: hadoop
2018-01-03 14:10:18,064 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 3 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 14:10:18,064 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user hadoop
2018-01-03 14:10:18,064 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0003
2018-01-03 14:10:18,064 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0003
2018-01-03 14:10:18,064 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from NEW to NEW_SAVING on event=START
2018-01-03 14:10:18,065 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0003
2018-01-03 14:10:18,065 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 14:10:18,065 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0003 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 14:10:18,065 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0003 from user: hadoop, in queue: default
2018-01-03 14:10:18,072 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 14:10:18,073 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0003_000001
2018-01-03 14:10:18,073 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from NEW to SUBMITTED
2018-01-03 14:10:18,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0003 from user: hadoop activated in queue: default
2018-01-03 14:10:18,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0003 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:10:18,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0003_000001 to scheduler from user hadoop in queue default
2018-01-03 14:10:18,081 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 14:10:18,373 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:10:18,374 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000001
2018-01-03 14:10:18,374 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:10:18,375 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:10:18,413 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0003_01_000001
2018-01-03 14:10:18,416 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:10:18,417 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0003_000001
2018-01-03 14:10:18,417 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0003 AttemptId: appattempt_1514955805909_0003_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0003_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 14:10:18,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:10:18,418 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:10:18,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:10:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:10:18,421 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0003_000001
2018-01-03 14:10:18,428 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0003_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0003_000001
2018-01-03 14:10:18,428 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0003_000001
2018-01-03 14:10:18,429 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0003_000001
2018-01-03 14:10:18,489 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0003_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0003_000001
2018-01-03 14:10:18,489 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 14:10:19,486 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:10:30,728 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514955805909_0003_000001 (auth:SIMPLE)
2018-01-03 14:10:30,741 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514955805909_0003_000001
2018-01-03 14:10:30,741 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514955805909_0003	APPATTEMPTID=appattempt_1514955805909_0003_000001
2018-01-03 14:10:30,742 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from LAUNCHED to RUNNING
2018-01-03 14:10:30,742 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 14:10:31,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:10:31,843 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000002
2018-01-03 14:10:31,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 14:10:31,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:10:31,843 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 14:10:31,844 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 14:10:31,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:10:31,896 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000003
2018-01-03 14:10:31,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 14:10:31,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:10:31,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 14:10:31,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 14:10:32,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0003_01_000002
2018-01-03 14:10:32,540 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:10:32,542 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0003_01_000003
2018-01-03 14:10:32,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:10:32,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:10:33,020 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:10:35,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0003
2018-01-03 14:14:00,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-03 14:14:23,485 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000003 Container Transitioned from RUNNING to RELEASED
2018-01-03 14:14:23,487 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000003
2018-01-03 14:14:24,350 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:14:24,350 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000004
2018-01-03 14:14:24,350 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 2 containers, <memory:4096, vCores:2> used and <memory:4096, vCores:6> available after allocation
2018-01-03 14:14:24,350 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:14:24,351 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 14:14:24,351 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 14:14:24,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0003_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:14:24,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-03 14:14:25,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:14:28,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0003
2018-01-03 14:17:33,705 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-03 14:17:33,705 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000004
2018-01-03 14:17:33,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:17:33,943 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000005 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:17:33,943 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000005
2018-01-03 14:17:33,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000005 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-03 14:17:33,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000005 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:17:33,944 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 14:17:33,944 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 14:17:34,132 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:17:34,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000006 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:17:34,328 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000006
2018-01-03 14:17:34,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000006 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 14:17:34,328 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000006 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:17:34,329 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-03 14:17:34,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 14:17:34,575 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000006 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:17:34,982 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000005 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 14:17:34,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000007 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:17:34,988 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000007
2018-01-03 14:17:34,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0003_01_000007 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 4 containers, <memory:7168, vCores:4> used and <memory:1024, vCores:4> available after allocation
2018-01-03 14:17:34,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0003_000001 container=container_1514955805909_0003_01_000007 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3490a94f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:17:34,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:9216, vCores:5>, usedCapacity=0.5625, absoluteUsedCapacity=0.5625, numApps=1, numContainers=5
2018-01-03 14:17:34,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.5625 absoluteUsedCapacity=0.5625 used=<memory:9216, vCores:5> cluster=<memory:16384, vCores:16>
2018-01-03 14:17:37,592 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0003
2018-01-03 14:17:37,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000007 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:17:40,657 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000007 Container Transitioned from ACQUIRED to RELEASED
2018-01-03 14:17:40,657 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000007
2018-01-03 14:17:40,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000007 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available, release resources=true
2018-01-03 14:19:42,086 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0003_000001 with final state: FINISHING, and exit status: -1000
2018-01-03 14:19:42,086 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 14:19:42,086 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0003 with final state: FINISHING
2018-01-03 14:19:42,086 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-03 14:19:42,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from FINAL_SAVING to FINISHING
2018-01-03 14:19:42,087 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0003
2018-01-03 14:19:42,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-03 14:19:42,188 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514955805909_0003 unregistered successfully. 
2018-01-03 14:19:42,367 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000005 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:19:42,367 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000005
2018-01-03 14:19:42,368 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000005 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000001
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0003_000001
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0003_000001
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0003_000001 State change from FINISHING to FINISHED
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-03 14:19:42,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0003 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0003_000001 is done. finalState=FINISHED
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514955805909_0003
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000006 Container Transitioned from ACQUIRED to KILLED
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000006
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000006 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0003,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514955805909_0003/,appMasterHost=192.168.28.132,startTime=1514956218064,finishTime=1514956782086,finalStatus=SUCCEEDED,memorySeconds=3105531,vcoreSeconds=1795,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 14:19:42,677 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0003_01_000002 Container Transitioned from RUNNING to KILLED
2018-01-03 14:19:42,678 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0003	CONTAINERID=container_1514955805909_0003_01_000002
2018-01-03 14:19:42,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0003 requests cleared
2018-01-03 14:19:42,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0003 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:19:42,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0003 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 14:19:42,680 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514955805909_0003_000001
2018-01-03 14:19:42,687 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:19:42,966 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0003_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:19:42,966 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0003_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:19:43,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0003_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:19:43,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0003_01_000005 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 14:19:52,696 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:02,747 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:05,817 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2018-01-03 14:20:12,779 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:15,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0004' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 14:20:15,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0004 for the user: hadoop
2018-01-03 14:20:15,985 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 4 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 14:20:15,985 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user hadoop
2018-01-03 14:20:15,985 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0004
2018-01-03 14:20:15,985 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0004
2018-01-03 14:20:15,985 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0004 State change from NEW to NEW_SAVING on event=START
2018-01-03 14:20:15,985 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0004
2018-01-03 14:20:15,986 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 14:20:15,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0004 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 14:20:15,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0004 from user: hadoop, in queue: default
2018-01-03 14:20:15,986 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 14:20:15,987 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0004_000001
2018-01-03 14:20:15,987 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000001 State change from NEW to SUBMITTED
2018-01-03 14:20:15,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0004 from user: hadoop activated in queue: default
2018-01-03 14:20:15,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0004 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:20:15,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0004_000001 to scheduler from user hadoop in queue default
2018-01-03 14:20:15,994 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 14:20:16,307 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:20:16,307 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0004	CONTAINERID=container_1514955805909_0004_01_000001
2018-01-03 14:20:16,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0004_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:20:16,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0004_000001 container=container_1514955805909_0004_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@7c8f36f3 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:20:16,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:20:16,309 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0004_01_000001
2018-01-03 14:20:16,310 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:20:16,312 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:20:16,312 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0004_000001
2018-01-03 14:20:16,312 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0004 AttemptId: appattempt_1514955805909_0004_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0004_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 14:20:16,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:20:16,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:20:16,314 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0004_000001
2018-01-03 14:20:16,317 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0004_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0004_000001
2018-01-03 14:20:16,317 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0004_000001
2018-01-03 14:20:16,317 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0004_000001
2018-01-03 14:20:16,319 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:22,787 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:26,323 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:38,387 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:41,922 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:48,391 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:51,930 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:20:58,394 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:01,964 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:08,404 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:11,969 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:18,408 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:21,973 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:28,414 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:31,979 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:43,515 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:47,084 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:53,519 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:21:57,097 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:03,523 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:07,105 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:13,526 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:17,112 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:23,530 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:27,118 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:33,536 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:37,150 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:48,161 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:52,778 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:58,168 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:22:58,171 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error cleaning master 
java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
2018-01-03 14:23:02,783 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:23:12,789 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:23:22,794 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:23:32,799 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:23:32,801 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0004_000001. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker01.local:41166 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 14:23:32,803 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0004_000001 with final state: FAILED, and exit status: -1000
2018-01-03 14:23:32,804 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000001 State change from ALLOCATED to FINAL_SAVING
2018-01-03 14:23:32,805 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0004_000001
2018-01-03 14:23:32,805 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0004_000001
2018-01-03 14:23:32,806 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000001 State change from FINAL_SAVING to FAILED
2018-01-03 14:23:32,806 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2018-01-03 14:23:32,807 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0004_000002
2018-01-03 14:23:32,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0004_000001 is done. finalState=FAILED
2018-01-03 14:23:32,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000002 State change from NEW to SUBMITTED
2018-01-03 14:23:32,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0004_01_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 14:23:32,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0004	CONTAINERID=container_1514955805909_0004_01_000001
2018-01-03 14:23:32,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0004_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:23:32,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0004 requests cleared
2018-01-03 14:23:32,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0004 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:23:32,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0004 from user: hadoop activated in queue: default
2018-01-03 14:23:32,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0004 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:23:32,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0004_000002 to scheduler from user hadoop in queue default
2018-01-03 14:23:32,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000002 State change from SUBMITTED to SCHEDULED
2018-01-03 14:23:33,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0004_02_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:23:33,264 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0004	CONTAINERID=container_1514955805909_0004_02_000001
2018-01-03 14:23:33,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0004_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:23:33,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0004_000002 container=container_1514955805909_0004_02_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1956a760 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:23:33,266 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:23:33,267 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:23:33,270 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0004_02_000001
2018-01-03 14:23:33,276 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0004_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:23:33,276 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0004_000002
2018-01-03 14:23:33,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0004 AttemptId: appattempt_1514955805909_0004_000002 MasterContainer: Container: [ContainerId: container_1514955805909_0004_02_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 14:23:33,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000002 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:23:33,278 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000002 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:23:33,280 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0004_000002
2018-01-03 14:23:33,288 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0004_02_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0004_000002
2018-01-03 14:23:33,289 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0004_000002
2018-01-03 14:23:33,289 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0004_000002
2018-01-03 14:23:33,297 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:23:43,307 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:23:57,415 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:24:07,419 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:24:17,427 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:24:27,453 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:24:37,462 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:24:47,468 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:25:01,130 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:25:11,138 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:25:21,147 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:25:31,154 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:25:41,180 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:25:51,187 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:26:04,358 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:26:14,364 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:26:24,379 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:26:34,386 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:26:44,392 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:26:44,394 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0004_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 14:26:44,394 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0004_000002 with final state: FAILED, and exit status: -1000
2018-01-03 14:26:44,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000002 State change from ALLOCATED to FINAL_SAVING
2018-01-03 14:26:44,395 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0004_000002
2018-01-03 14:26:44,395 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0004_000002
2018-01-03 14:26:44,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0004_000002 State change from FINAL_SAVING to FAILED
2018-01-03 14:26:44,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2018-01-03 14:26:44,399 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0004 with final state: FAILED
2018-01-03 14:26:44,399 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0004
2018-01-03 14:26:44,399 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0004 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2018-01-03 14:26:44,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0004_000002 is done. finalState=FAILED
2018-01-03 14:26:44,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1514955805909_0004 failed 2 times due to Error launching appattempt_1514955805909_0004_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.
2018-01-03 14:26:44,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0004 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2018-01-03 14:26:44,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0004_02_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 14:26:44,402 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0004	CONTAINERID=container_1514955805909_0004_02_000001
2018-01-03 14:26:44,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0004_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:26:44,402 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1514955805909_0004 failed 2 times due to Error launching appattempt_1514955805909_0004_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.	APPID=application_1514955805909_0004
2018-01-03 14:26:44,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0004 requests cleared
2018-01-03 14:26:44,403 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0004,name=sparklyr,user=hadoop,queue=default,state=FAILED,trackingUrl=http://hadoop-master:8088/cluster/app/application_1514955805909_0004,appMasterHost=N/A,startTime=1514956815985,finishTime=1514957204399,finalStatus=FAILED,memorySeconds=396952,vcoreSeconds=387,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 14:26:44,404 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0004 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:26:44,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0004 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 14:29:11,830 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2018-01-03 14:29:23,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0005' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 14:29:23,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0005 for the user: hadoop
2018-01-03 14:29:23,512 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 5 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 14:29:23,513 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user hadoop
2018-01-03 14:29:23,513 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0005
2018-01-03 14:29:23,514 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0005
2018-01-03 14:29:23,514 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0005 State change from NEW to NEW_SAVING on event=START
2018-01-03 14:29:23,519 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0005
2018-01-03 14:29:23,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0005 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 14:29:23,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0005 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 14:29:23,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0005 from user: hadoop, in queue: default
2018-01-03 14:29:23,537 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0005 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 14:29:23,538 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0005_000001
2018-01-03 14:29:23,538 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000001 State change from NEW to SUBMITTED
2018-01-03 14:29:23,538 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0005 from user: hadoop activated in queue: default
2018-01-03 14:29:23,538 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0005 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:29:23,538 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0005_000001 to scheduler from user hadoop in queue default
2018-01-03 14:29:23,542 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 14:29:23,782 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:29:23,782 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0005	CONTAINERID=container_1514955805909_0005_01_000001
2018-01-03 14:29:23,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0005_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:29:23,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0005_000001 container=container_1514955805909_0005_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1c6b3217 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:29:23,783 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:29:23,784 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:29:23,785 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0005_01_000001
2018-01-03 14:29:23,788 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:29:23,788 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0005_000001
2018-01-03 14:29:23,788 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0005 AttemptId: appattempt_1514955805909_0005_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0005_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 14:29:23,789 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:29:23,789 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:29:23,791 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0005_000001
2018-01-03 14:29:23,798 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0005_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0005_000001
2018-01-03 14:29:23,798 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0005_000001
2018-01-03 14:29:23,798 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0005_000001
2018-01-03 14:29:23,803 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:29:33,810 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:29:43,820 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:29:53,838 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:30:05,088 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:30:15,093 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:30:25,097 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:30:35,103 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:30:46,115 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:30:56,123 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:31:06,126 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:31:16,129 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:31:26,135 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:31:36,141 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:31:46,148 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:31:56,155 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:06,160 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:16,166 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:26,173 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:26,175 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0005_000001. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker01.local:41166 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 14:32:26,176 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0005_000001 with final state: FAILED, and exit status: -1000
2018-01-03 14:32:26,176 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000001 State change from ALLOCATED to FINAL_SAVING
2018-01-03 14:32:26,177 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0005_000001
2018-01-03 14:32:26,177 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0005_000001
2018-01-03 14:32:26,177 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000001 State change from FINAL_SAVING to FAILED
2018-01-03 14:32:26,178 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2018-01-03 14:32:26,178 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0005_000002
2018-01-03 14:32:26,178 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000002 State change from NEW to SUBMITTED
2018-01-03 14:32:26,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0005_000001 is done. finalState=FAILED
2018-01-03 14:32:26,187 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0005_01_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 14:32:26,187 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0005	CONTAINERID=container_1514955805909_0005_01_000001
2018-01-03 14:32:26,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0005_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:32:26,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0005 requests cleared
2018-01-03 14:32:26,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0005 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:32:26,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0005 from user: hadoop activated in queue: default
2018-01-03 14:32:26,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0005 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 14:32:26,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0005_000002 to scheduler from user hadoop in queue default
2018-01-03 14:32:26,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000002 State change from SUBMITTED to SCHEDULED
2018-01-03 14:32:26,244 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0005_02_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 14:32:26,244 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0005	CONTAINERID=container_1514955805909_0005_02_000001
2018-01-03 14:32:26,244 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0005_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 14:32:26,245 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0005_000002 container=container_1514955805909_0005_02_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@713e6944 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 14:32:26,247 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0005_02_000001
2018-01-03 14:32:26,249 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0005_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 14:32:26,250 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0005_000002
2018-01-03 14:32:26,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0005 AttemptId: appattempt_1514955805909_0005_000002 MasterContainer: Container: [ContainerId: container_1514955805909_0005_02_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 14:32:26,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000002 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 14:32:26,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 14:32:26,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 14:32:26,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000002 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 14:32:26,252 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0005_000002
2018-01-03 14:32:26,255 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0005_02_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0005_000002
2018-01-03 14:32:26,256 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0005_000002
2018-01-03 14:32:26,256 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0005_000002
2018-01-03 14:32:26,260 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:36,728 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:46,735 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:32:56,757 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:33:06,767 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:33:16,776 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:33:26,788 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:33:36,795 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:33:46,802 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:33:56,816 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:34:06,830 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:34:16,835 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:34:26,842 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:34:36,847 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:34:46,853 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:34:56,857 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:35:06,862 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:35:16,867 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:35:26,873 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 14:35:26,879 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0005_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 14:35:26,881 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0005_000002 with final state: FAILED, and exit status: -1000
2018-01-03 14:35:26,881 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000002 State change from ALLOCATED to FINAL_SAVING
2018-01-03 14:35:26,882 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0005_000002
2018-01-03 14:35:26,882 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0005_000002
2018-01-03 14:35:26,882 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0005_000002 State change from FINAL_SAVING to FAILED
2018-01-03 14:35:26,883 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2018-01-03 14:35:26,883 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0005 with final state: FAILED
2018-01-03 14:35:26,884 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0005 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2018-01-03 14:35:26,884 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0005_000002 is done. finalState=FAILED
2018-01-03 14:35:26,885 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0005
2018-01-03 14:35:26,889 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0005_02_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 14:35:26,889 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0005	CONTAINERID=container_1514955805909_0005_02_000001
2018-01-03 14:35:26,889 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0005_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 14:35:26,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1514955805909_0005 failed 2 times due to Error launching appattempt_1514955805909_0005_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.
2018-01-03 14:35:26,892 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0005 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2018-01-03 14:35:26,892 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0005 requests cleared
2018-01-03 14:35:26,897 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1514955805909_0005 failed 2 times due to Error launching appattempt_1514955805909_0005_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor54.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.	APPID=application_1514955805909_0005
2018-01-03 14:35:26,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0005 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 14:35:26,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0005 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 14:35:26,899 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0005,name=sparklyr,user=hadoop,queue=default,state=FAILED,trackingUrl=http://hadoop-master:8088/cluster/app/application_1514955805909_0005,appMasterHost=N/A,startTime=1514957363512,finishTime=1514957726883,finalStatus=FAILED,memorySeconds=371762,vcoreSeconds=362,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 15:18:24,212 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 6
2018-01-03 15:18:36,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0006' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 15:18:36,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0006 for the user: hadoop
2018-01-03 15:18:36,850 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 6 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 15:18:36,851 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 6 submitted by user hadoop
2018-01-03 15:18:36,852 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0006
2018-01-03 15:18:36,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0006
2018-01-03 15:18:36,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0006 State change from NEW to NEW_SAVING on event=START
2018-01-03 15:18:36,859 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0006
2018-01-03 15:18:36,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0006 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 15:18:36,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0006 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 15:18:36,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0006 from user: hadoop, in queue: default
2018-01-03 15:18:36,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0006 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 15:18:36,871 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0006_000001
2018-01-03 15:18:36,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000001 State change from NEW to SUBMITTED
2018-01-03 15:18:36,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0006 from user: hadoop activated in queue: default
2018-01-03 15:18:36,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0006 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:18:36,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0006_000001 to scheduler from user hadoop in queue default
2018-01-03 15:18:36,884 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 15:18:36,947 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0006_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:18:36,947 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0006	CONTAINERID=container_1514955805909_0006_01_000001
2018-01-03 15:18:36,947 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0006_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:18:36,948 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0006_000001 container=container_1514955805909_0006_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3489f4eb clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:18:36,948 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:18:36,949 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:18:36,952 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0006_01_000001
2018-01-03 15:18:36,956 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0006_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:18:36,956 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0006_000001
2018-01-03 15:18:36,956 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0006 AttemptId: appattempt_1514955805909_0006_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0006_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 15:18:36,957 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:18:36,957 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:18:36,960 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0006_000001
2018-01-03 15:18:36,968 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0006_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0006_000001
2018-01-03 15:18:36,968 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0006_000001
2018-01-03 15:18:36,970 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0006_000001
2018-01-03 15:18:36,977 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:18:49,716 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:18:59,732 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:19:09,757 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:19:19,761 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:19:29,763 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:19:39,770 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:19:52,232 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:20:02,275 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:20:12,297 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:20:22,307 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:20:32,317 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:20:42,322 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:20:54,490 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:04,496 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:14,501 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:24,508 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:34,516 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:44,535 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:44,537 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0006_000001. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 15:21:44,538 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0006_000001 with final state: FAILED, and exit status: -1000
2018-01-03 15:21:44,538 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000001 State change from ALLOCATED to FINAL_SAVING
2018-01-03 15:21:44,539 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0006_000001
2018-01-03 15:21:44,539 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0006_000001
2018-01-03 15:21:44,539 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000001 State change from FINAL_SAVING to FAILED
2018-01-03 15:21:44,539 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2018-01-03 15:21:44,540 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0006_000002
2018-01-03 15:21:44,540 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000002 State change from NEW to SUBMITTED
2018-01-03 15:21:44,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0006_000001 is done. finalState=FAILED
2018-01-03 15:21:44,543 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0006_01_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 15:21:44,543 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0006	CONTAINERID=container_1514955805909_0006_01_000001
2018-01-03 15:21:44,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0006_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:21:44,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0006 requests cleared
2018-01-03 15:21:44,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0006 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 15:21:44,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0006 from user: hadoop activated in queue: default
2018-01-03 15:21:44,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0006 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:21:44,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0006_000002 to scheduler from user hadoop in queue default
2018-01-03 15:21:44,548 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000002 State change from SUBMITTED to SCHEDULED
2018-01-03 15:21:45,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0006_02_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:21:45,003 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0006	CONTAINERID=container_1514955805909_0006_02_000001
2018-01-03 15:21:45,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0006_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:21:45,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0006_000002 container=container_1514955805909_0006_02_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@184828bd clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:21:45,004 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0006_02_000001
2018-01-03 15:21:45,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0006_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:21:45,006 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0006_000002
2018-01-03 15:21:45,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0006 AttemptId: appattempt_1514955805909_0006_000002 MasterContainer: Container: [ContainerId: container_1514955805909_0006_02_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 15:21:45,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:21:45,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000002 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:21:45,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:21:45,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000002 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:21:45,008 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0006_000002
2018-01-03 15:21:45,012 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0006_02_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0006_000002
2018-01-03 15:21:45,012 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0006_000002
2018-01-03 15:21:45,012 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0006_000002
2018-01-03 15:21:45,014 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:21:56,857 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:22:06,864 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:22:16,873 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:22:26,881 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:22:36,886 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:22:46,895 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:22:58,475 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:23:08,488 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:23:18,499 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:23:28,502 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:23:38,507 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:23:48,511 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:23:59,787 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:24:09,796 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:24:19,820 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:24:29,833 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:24:39,838 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:24:49,842 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:24:49,845 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0006_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker01.local:41166 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 15:24:49,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0006_000002 with final state: FAILED, and exit status: -1000
2018-01-03 15:24:49,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000002 State change from ALLOCATED to FINAL_SAVING
2018-01-03 15:24:49,847 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0006_000002
2018-01-03 15:24:49,847 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0006_000002
2018-01-03 15:24:49,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0006_000002 State change from FINAL_SAVING to FAILED
2018-01-03 15:24:49,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2018-01-03 15:24:49,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0006 with final state: FAILED
2018-01-03 15:24:49,849 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0006 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2018-01-03 15:24:49,849 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0006
2018-01-03 15:24:49,849 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0006_000002 is done. finalState=FAILED
2018-01-03 15:24:49,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1514955805909_0006 failed 2 times due to Error launching appattempt_1514955805909_0006_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker01.local:41166 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.
2018-01-03 15:24:49,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0006_02_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 15:24:49,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0006 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2018-01-03 15:24:49,852 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0006	CONTAINERID=container_1514955805909_0006_02_000001
2018-01-03 15:24:49,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0006_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:24:49,855 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1514955805909_0006 failed 2 times due to Error launching appattempt_1514955805909_0006_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker01.local:41166 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.	APPID=application_1514955805909_0006
2018-01-03 15:24:49,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0006 requests cleared
2018-01-03 15:24:49,856 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0006 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 15:24:49,856 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0006 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 15:24:49,856 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0006,name=sparklyr,user=hadoop,queue=default,state=FAILED,trackingUrl=http://hadoop-master:8088/cluster/app/application_1514955805909_0006,appMasterHost=N/A,startTime=1514960316850,finishTime=1514960689848,finalStatus=FAILED,memorySeconds=381384,vcoreSeconds=371,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 15:27:23,043 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 7
2018-01-03 15:27:36,076 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0007' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 15:27:36,076 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0007 for the user: hadoop
2018-01-03 15:27:36,077 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 7 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 15:27:36,078 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 7 submitted by user hadoop
2018-01-03 15:27:36,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0007
2018-01-03 15:27:36,078 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0007
2018-01-03 15:27:36,079 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0007 State change from NEW to NEW_SAVING on event=START
2018-01-03 15:27:36,080 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0007
2018-01-03 15:27:36,080 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0007 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 15:27:36,080 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0007 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 15:27:36,080 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0007 from user: hadoop, in queue: default
2018-01-03 15:27:36,089 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0007 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 15:27:36,089 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0007_000001
2018-01-03 15:27:36,089 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000001 State change from NEW to SUBMITTED
2018-01-03 15:27:36,089 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0007 from user: hadoop activated in queue: default
2018-01-03 15:27:36,090 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0007 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:27:36,090 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0007_000001 to scheduler from user hadoop in queue default
2018-01-03 15:27:36,092 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 15:27:36,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0007_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:27:36,371 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0007	CONTAINERID=container_1514955805909_0007_01_000001
2018-01-03 15:27:36,371 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0007_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:27:36,371 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0007_000001 container=container_1514955805909_0007_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@5df65a29 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:27:36,374 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0007_01_000001
2018-01-03 15:27:36,382 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0007_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:27:36,383 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0007_000001
2018-01-03 15:27:36,383 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0007 AttemptId: appattempt_1514955805909_0007_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0007_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 15:27:36,385 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:27:36,385 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:27:36,386 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:27:36,386 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:27:36,388 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0007_000001
2018-01-03 15:27:36,394 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0007_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0007_000001
2018-01-03 15:27:36,395 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0007_000001
2018-01-03 15:27:36,395 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0007_000001
2018-01-03 15:27:36,400 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:27:46,408 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:28:03,384 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:28:13,392 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:28:23,398 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:28:33,403 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:28:43,407 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:28:53,411 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:29:09,686 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:29:19,689 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:29:30,696 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:29:40,699 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:29:50,702 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:00,709 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:16,525 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:26,537 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:36,546 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:46,553 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:56,565 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker01.local/192.168.28.131:41166: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:30:56,566 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0007_000001. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker01.local:41166 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0007_000001 with final state: FAILED, and exit status: -1000
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000001 State change from ALLOCATED to FINAL_SAVING
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0007_000001
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0007_000001
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000001 State change from FINAL_SAVING to FAILED
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0007_000002
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000002 State change from NEW to SUBMITTED
2018-01-03 15:30:56,567 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0007_000001 is done. finalState=FAILED
2018-01-03 15:30:56,570 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0007_01_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 15:30:56,570 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0007	CONTAINERID=container_1514955805909_0007_01_000001
2018-01-03 15:30:56,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0007_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:30:56,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0007 requests cleared
2018-01-03 15:30:56,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0007 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 15:30:56,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0007 from user: hadoop activated in queue: default
2018-01-03 15:30:56,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0007 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:30:56,571 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0007_000002 to scheduler from user hadoop in queue default
2018-01-03 15:30:56,572 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000002 State change from SUBMITTED to SCHEDULED
2018-01-03 15:30:56,614 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0007_02_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:30:56,614 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0007	CONTAINERID=container_1514955805909_0007_02_000001
2018-01-03 15:30:56,614 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0007_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:30:56,615 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0007_000002 container=container_1514955805909_0007_02_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@5f806c9a clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:30:56,617 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0007_02_000001
2018-01-03 15:30:56,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0007_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:30:56,621 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0007_000002
2018-01-03 15:30:56,621 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0007 AttemptId: appattempt_1514955805909_0007_000002 MasterContainer: Container: [ContainerId: container_1514955805909_0007_02_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 15:30:56,621 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:30:56,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000002 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:30:56,622 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:30:56,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000002 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:30:56,624 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0007_000002
2018-01-03 15:30:56,630 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0007_02_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0007_000002
2018-01-03 15:30:56,631 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0007_000002
2018-01-03 15:30:56,631 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0007_000002
2018-01-03 15:30:56,637 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:31:06,642 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:31:21,931 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:31:31,934 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:31:41,938 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:31:51,957 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:32:01,965 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:32:11,970 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:32:26,789 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:32:36,799 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:32:46,805 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:32:56,808 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:33:06,814 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:33:16,841 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:33:31,095 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:33:41,102 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:33:51,109 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:34:01,121 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:34:11,129 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:34:11,131 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error launching appattempt_1514955805909_0007_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more

2018-01-03 15:34:11,132 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0007_000002 with final state: FAILED, and exit status: -1000
2018-01-03 15:34:11,132 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000002 State change from ALLOCATED to FINAL_SAVING
2018-01-03 15:34:11,132 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0007_000002
2018-01-03 15:34:11,133 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0007_000002
2018-01-03 15:34:11,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0007_000002 State change from FINAL_SAVING to FAILED
2018-01-03 15:34:11,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2018-01-03 15:34:11,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0007 with final state: FAILED
2018-01-03 15:34:11,133 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0007 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2018-01-03 15:34:11,133 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0007_000002 is done. finalState=FAILED
2018-01-03 15:34:11,134 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0007
2018-01-03 15:34:11,135 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1514955805909_0007 failed 2 times due to Error launching appattempt_1514955805909_0007_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.
2018-01-03 15:34:11,135 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0007 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2018-01-03 15:34:11,135 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1514955805909_0007 failed 2 times due to Error launching appattempt_1514955805909_0007_000002. Got exception: java.net.NoRouteToHostException: No Route to Host from  hadoop-master/192.168.28.129 to hadoop-worker02.local:45394 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor57.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:758)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 19 more
. Failing the application.	APPID=application_1514955805909_0007
2018-01-03 15:34:11,136 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0007,name=sparklyr,user=hadoop,queue=default,state=FAILED,trackingUrl=http://hadoop-master:8088/cluster/app/application_1514955805909_0007,appMasterHost=N/A,startTime=1514960856077,finishTime=1514961251133,finalStatus=FAILED,memorySeconds=401722,vcoreSeconds=392,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 15:34:11,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0007_02_000001 Container Transitioned from ACQUIRED to KILLED
2018-01-03 15:34:11,138 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0007	CONTAINERID=container_1514955805909_0007_02_000001
2018-01-03 15:34:11,138 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0007_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:34:11,139 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0007 requests cleared
2018-01-03 15:34:11,139 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0007 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 15:34:11,139 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0007 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 15:36:04,021 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 8
2018-01-03 15:36:14,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0008' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 15:36:14,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0008 for the user: hadoop
2018-01-03 15:36:14,009 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 8 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 8 submitted by user hadoop
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0008
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0008
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0008 State change from NEW to NEW_SAVING on event=START
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0008
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0008 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0008 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 15:36:14,010 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0008 from user: hadoop, in queue: default
2018-01-03 15:36:14,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0008 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 15:36:14,011 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0008_000001
2018-01-03 15:36:14,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from NEW to SUBMITTED
2018-01-03 15:36:14,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0008 from user: hadoop activated in queue: default
2018-01-03 15:36:14,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0008 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:36:14,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0008_000001 to scheduler from user hadoop in queue default
2018-01-03 15:36:14,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 15:36:14,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:36:14,584 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0008	CONTAINERID=container_1514955805909_0008_01_000001
2018-01-03 15:36:14,584 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0008_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:36:14,584 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0008_000001 container=container_1514955805909_0008_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@7d013cda clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:36:14,587 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0008_01_000001
2018-01-03 15:36:14,591 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:36:14,592 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0008_000001
2018-01-03 15:36:14,592 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0008 AttemptId: appattempt_1514955805909_0008_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0008_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 15:36:14,592 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:36:14,592 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:36:14,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:36:14,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:36:14,596 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0008_000001
2018-01-03 15:36:14,604 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0008_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0008_000001
2018-01-03 15:36:14,605 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0008_000001
2018-01-03 15:36:14,605 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0008_000001
2018-01-03 15:36:14,609 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:36:24,614 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:36:37,235 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:36:47,241 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:36:57,245 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:37:07,248 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: hadoop-worker02.local/192.168.28.132:45394: retries get failed due to exceeded maximum allowed retries number: 0
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:682)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:778)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)
	at sun.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-01-03 15:37:17,379 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0008_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0008_000001
2018-01-03 15:37:17,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 15:37:17,885 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:38:31,990 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 9
2018-01-03 15:38:42,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0009' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 15:38:42,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0009 for the user: hadoop
2018-01-03 15:38:42,207 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 9 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 15:38:42,208 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 9 submitted by user hadoop
2018-01-03 15:38:42,208 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0009
2018-01-03 15:38:42,208 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0009
2018-01-03 15:38:42,209 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from NEW to NEW_SAVING on event=START
2018-01-03 15:38:42,209 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0009
2018-01-03 15:38:42,209 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 15:38:42,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0009 user: hadoop leaf-queue of parent: root #applications: 2
2018-01-03 15:38:42,210 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0009 from user: hadoop, in queue: default
2018-01-03 15:38:42,220 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 15:38:42,220 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0009_000001
2018-01-03 15:38:42,220 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from NEW to SUBMITTED
2018-01-03 15:38:42,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0009 from user: hadoop activated in queue: default
2018-01-03 15:38:42,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0009 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 2 #queue-pending-applications: 0 #queue-active-applications: 2
2018-01-03 15:38:42,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0009_000001 to scheduler from user hadoop in queue default
2018-01-03 15:38:42,232 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 15:38:42,710 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:38:42,710 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0009	CONTAINERID=container_1514955805909_0009_01_000001
2018-01-03 15:38:42,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0009_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which has 2 containers, <memory:2048, vCores:2> used and <memory:6144, vCores:6> available after allocation
2018-01-03 15:38:42,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0009_000001 container=container_1514955805909_0009_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@12c91641 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:38:42,712 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0009_01_000001
2018-01-03 15:38:42,714 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:38:42,715 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0009_000001
2018-01-03 15:38:42,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0009 AttemptId: appattempt_1514955805909_0009_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0009_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ]
2018-01-03 15:38:42,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:2>, usedCapacity=0.125, absoluteUsedCapacity=0.125, numApps=2, numContainers=2
2018-01-03 15:38:42,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:38:42,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:2048, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 15:38:42,716 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:38:42,717 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0009_000001
2018-01-03 15:38:42,724 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0009_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0009_000001
2018-01-03 15:38:42,725 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0009_000001
2018-01-03 15:38:42,725 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0009_000001
2018-01-03 15:38:42,809 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0009_01_000001, Version: 0, NodeId: hadoop-worker02.local:45394, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:45394 }, ] for AM appattempt_1514955805909_0009_000001
2018-01-03 15:38:42,810 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 15:38:43,727 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:38:57,556 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514955805909_0009_000001 (auth:SIMPLE)
2018-01-03 15:38:57,564 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514955805909_0009_000001
2018-01-03 15:38:57,564 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514955805909_0009	APPATTEMPTID=appattempt_1514955805909_0009_000001
2018-01-03 15:38:57,564 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from LAUNCHED to RUNNING
2018-01-03 15:38:57,564 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 15:38:57,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:38:57,846 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0009	CONTAINERID=container_1514955805909_0009_01_000002
2018-01-03 15:38:57,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0009_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 3 containers, <memory:4096, vCores:3> used and <memory:4096, vCores:5> available after allocation
2018-01-03 15:38:57,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0009_000001 container=container_1514955805909_0009_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@12c91641 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:38:57,846 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=2, numContainers=3
2018-01-03 15:38:57,847 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:4096, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 15:38:58,054 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0009_01_000002
2018-01-03 15:38:58,057 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:38:58,856 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:38:58,857 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0009	CONTAINERID=container_1514955805909_0009_01_000003
2018-01-03 15:38:58,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0009_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 15:38:58,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0009_000001 container=container_1514955805909_0009_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@12c91641 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:38:58,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:4>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=2, numContainers=4
2018-01-03 15:38:58,857 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:6144, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 15:38:58,928 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:38:59,375 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0009_01_000003
2018-01-03 15:38:59,378 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:38:59,993 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:39:02,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0009
2018-01-03 15:39:11,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:39:11,409 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0008	CONTAINERID=container_1514955805909_0008_01_000001
2018-01-03 15:39:11,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0008_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-03 15:39:11,418 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0008_000001 with final state: FAILED, and exit status: 10
2018-01-03 15:39:11,418 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from LAUNCHED to FINAL_SAVING
2018-01-03 15:39:11,419 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0008_000001
2018-01-03 15:39:11,419 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0008_000001
2018-01-03 15:39:11,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000001 State change from FINAL_SAVING to FAILED
2018-01-03 15:39:11,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2018-01-03 15:39:11,420 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0008_000002
2018-01-03 15:39:11,420 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from NEW to SUBMITTED
2018-01-03 15:39:11,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0008_000001 is done. finalState=FAILED
2018-01-03 15:39:11,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0008 requests cleared
2018-01-03 15:39:11,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0008 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:39:11,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0008 from user: hadoop activated in queue: default
2018-01-03 15:39:11,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0008 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 2 #queue-pending-applications: 0 #queue-active-applications: 2
2018-01-03 15:39:11,423 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0008_000002 to scheduler from user hadoop in queue default
2018-01-03 15:39:11,430 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from SUBMITTED to SCHEDULED
2018-01-03 15:39:12,377 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_02_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:39:12,377 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0008	CONTAINERID=container_1514955805909_0008_02_000001
2018-01-03 15:39:12,377 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0008_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 15:39:12,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0008_000002 container=container_1514955805909_0008_02_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4e714c3e clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:39:12,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:6144, vCores:4>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=2, numContainers=4
2018-01-03 15:39:12,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:6144, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 15:39:12,394 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0008_02_000001
2018-01-03 15:39:12,400 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_02_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:39:12,400 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0008_000002
2018-01-03 15:39:12,400 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0008 AttemptId: appattempt_1514955805909_0008_000002 MasterContainer: Container: [ContainerId: container_1514955805909_0008_02_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 15:39:12,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:39:12,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:39:12,403 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0008_000002
2018-01-03 15:39:12,413 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0008_02_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0008_000002
2018-01-03 15:39:12,413 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0008_000002
2018-01-03 15:39:12,413 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0008_000002
2018-01-03 15:39:12,488 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0008_02_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0008_000002
2018-01-03 15:39:12,488 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from ALLOCATED to LAUNCHED
2018-01-03 15:39:13,450 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_02_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:41:03,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0008_02_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:41:03,756 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0008	CONTAINERID=container_1514955805909_0008_02_000001
2018-01-03 15:41:03,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0008_000002 with final state: FAILED, and exit status: 10
2018-01-03 15:41:03,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from LAUNCHED to FINAL_SAVING
2018-01-03 15:41:03,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0008_02_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0008_000002
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0008_000002
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0008_000002 State change from FINAL_SAVING to FAILED
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 2. The max attempts is 2
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0008 with final state: FAILED
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0008 State change from ACCEPTED to FINAL_SAVING on event=ATTEMPT_FAILED
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0008
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0008_000002 is done. finalState=FAILED
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0008 requests cleared
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1514955805909_0008 failed 2 times due to AM Container for appattempt_1514955805909_0008_000002 exited with  exitCode: 10
Failing this attempt.Diagnostics: Exception from container-launch.
Container id: container_1514955805909_0008_02_000001
Exit code: 10
Stack trace: ExitCodeException exitCode=10: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:972)
	at org.apache.hadoop.util.Shell.run(Shell.java:869)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 10
For more detailed output, check the application tracking page: http://hadoop-master:8088/cluster/app/application_1514955805909_0008 Then click on links to logs of each attempt.
. Failing the application.
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0008 State change from FINAL_SAVING to FAILED on event=APP_UPDATE_SAVED
2018-01-03 15:41:03,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0008 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:41:03,758 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1514955805909_0008 failed 2 times due to AM Container for appattempt_1514955805909_0008_000002 exited with  exitCode: 10
Failing this attempt.Diagnostics: Exception from container-launch.
Container id: container_1514955805909_0008_02_000001
Exit code: 10
Stack trace: ExitCodeException exitCode=10: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:972)
	at org.apache.hadoop.util.Shell.run(Shell.java:869)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:236)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:305)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:84)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 10
For more detailed output, check the application tracking page: http://hadoop-master:8088/cluster/app/application_1514955805909_0008 Then click on links to logs of each attempt.
. Failing the application.	APPID=application_1514955805909_0008
2018-01-03 15:41:03,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0008 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 15:41:03,759 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0008,name=Spark shell,user=hadoop,queue=default,state=FAILED,trackingUrl=http://hadoop-master:8088/cluster/app/application_1514955805909_0008,appMasterHost=N/A,startTime=1514961374009,finishTime=1514961663757,finalStatus=FAILED,memorySeconds=295121,vcoreSeconds=287,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 15:44:12,622 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:44:12,623 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0009	CONTAINERID=container_1514955805909_0009_01_000002
2018-01-03 15:44:12,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0009_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-03 15:44:12,635 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:44:12,635 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0009	CONTAINERID=container_1514955805909_0009_01_000003
2018-01-03 15:44:12,635 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0009_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:44:12,751 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0009_000001 with final state: FINISHING, and exit status: -1000
2018-01-03 15:44:12,752 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 15:44:12,752 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0009 with final state: FINISHING
2018-01-03 15:44:12,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-03 15:44:12,753 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0009
2018-01-03 15:44:12,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from FINAL_SAVING to FINISHING
2018-01-03 15:44:12,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-03 15:44:12,847 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514955805909_0009 unregistered successfully. 
2018-01-03 15:44:13,263 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0009_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:44:13,263 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0009	CONTAINERID=container_1514955805909_0009_01_000001
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0009_000001
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0009_000001
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0009_000001 State change from FINISHING to FINISHED
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0009_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0009 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0009_000001 is done. finalState=FINISHED
2018-01-03 15:44:13,264 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514955805909_0009
2018-01-03 15:44:13,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0009 requests cleared
2018-01-03 15:44:13,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0009 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 15:44:13,265 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0009,name=Spark shell,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514955805909_0009/,appMasterHost=192.168.28.132,startTime=1514961522207,finishTime=1514961852752,finalStatus=SUCCEEDED,memorySeconds=1625766,vcoreSeconds=957,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 15:44:13,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0009 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 15:44:13,265 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514955805909_0009_000001
2018-01-03 15:44:14,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0009_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 15:44:15,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0009_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 15:45:34,842 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 10
2018-01-03 15:45:42,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0010' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 15:45:42,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0010 for the user: hadoop
2018-01-03 15:45:42,755 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 10 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 15:45:42,756 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 10 submitted by user hadoop
2018-01-03 15:45:42,756 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0010
2018-01-03 15:45:42,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0010
2018-01-03 15:45:42,756 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from NEW to NEW_SAVING on event=START
2018-01-03 15:45:42,756 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0010
2018-01-03 15:45:42,757 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 15:45:42,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0010 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 15:45:42,757 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0010 from user: hadoop, in queue: default
2018-01-03 15:45:42,759 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 15:45:42,759 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0010_000001
2018-01-03 15:45:42,759 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from NEW to SUBMITTED
2018-01-03 15:45:42,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0010 from user: hadoop activated in queue: default
2018-01-03 15:45:42,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0010 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:45:42,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0010_000001 to scheduler from user hadoop in queue default
2018-01-03 15:45:42,763 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 15:45:43,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:45:43,402 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000001
2018-01-03 15:45:43,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0010_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:45:43,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0010_000001 container=container_1514955805909_0010_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4506b450 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:45:43,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:45:43,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:45:43,412 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0010_01_000001
2018-01-03 15:45:43,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:45:43,419 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0010_000001
2018-01-03 15:45:43,420 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0010 AttemptId: appattempt_1514955805909_0010_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0010_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 15:45:43,420 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:45:43,422 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:45:43,426 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0010_000001
2018-01-03 15:45:43,436 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0010_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0010_000001
2018-01-03 15:45:43,436 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0010_000001
2018-01-03 15:45:43,437 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0010_000001
2018-01-03 15:45:43,494 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0010_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0010_000001
2018-01-03 15:45:43,494 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 15:45:44,405 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:45:52,002 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514955805909_0010_000001 (auth:SIMPLE)
2018-01-03 15:45:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514955805909_0010_000001
2018-01-03 15:45:52,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514955805909_0010	APPATTEMPTID=appattempt_1514955805909_0010_000001
2018-01-03 15:45:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from LAUNCHED to RUNNING
2018-01-03 15:45:52,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 15:45:52,488 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:45:52,501 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000002
2018-01-03 15:45:52,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0010_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 15:45:52,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0010_000001 container=container_1514955805909_0010_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4506b450 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:45:52,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 15:45:52,502 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 15:45:52,505 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0010_01_000002
2018-01-03 15:45:52,512 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:45:52,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:45:52,723 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000003
2018-01-03 15:45:52,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0010_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 15:45:52,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0010_000001 container=container_1514955805909_0010_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4506b450 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:45:52,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 15:45:52,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 15:45:52,961 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0010_01_000003
2018-01-03 15:45:52,962 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:45:53,542 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:45:53,683 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:45:53,683 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000004
2018-01-03 15:45:53,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0010_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-03 15:45:53,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0010_000001 container=container_1514955805909_0010_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4506b450 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:45:53,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-03 15:45:53,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 15:45:53,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:46:01,251 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0010
2018-01-03 15:46:01,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:46:04,659 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-03 15:46:04,660 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000004
2018-01-03 15:46:04,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0010_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-03 15:46:56,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1514955805909_0010_000001 with final state: FINISHING, and exit status: -1000
2018-01-03 15:46:56,833 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from RUNNING to FINAL_SAVING
2018-01-03 15:46:56,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1514955805909_0010 with final state: FINISHING
2018-01-03 15:46:56,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-03 15:46:56,834 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1514955805909_0010
2018-01-03 15:46:56,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from FINAL_SAVING to FINISHING
2018-01-03 15:46:56,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-03 15:46:56,895 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:46:56,895 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000003
2018-01-03 15:46:56,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0010_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:46:56,907 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:46:56,907 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000002
2018-01-03 15:46:56,908 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0010_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-03 15:46:56,941 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1514955805909_0010 unregistered successfully. 
2018-01-03 15:46:57,410 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0010_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0010	CONTAINERID=container_1514955805909_0010_01_000001
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0010_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1514955805909_0010_000001
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1514955805909_0010_000001
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0010_000001 State change from FINISHING to FINISHED
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0010 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-03 15:46:57,411 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1514955805909_0010
2018-01-03 15:46:57,412 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1514955805909_0010,name=Spark shell,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1514955805909_0010/,appMasterHost=192.168.28.131,startTime=1514961942755,finishTime=1514962016834,finalStatus=SUCCEEDED,memorySeconds=361619,vcoreSeconds=212,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-03 15:46:57,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1514955805909_0010_000001 is done. finalState=FINISHED
2018-01-03 15:46:57,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1514955805909_0010 requests cleared
2018-01-03 15:46:57,413 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1514955805909_0010_000001
2018-01-03 15:46:57,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1514955805909_0010 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-03 15:46:57,414 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1514955805909_0010 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-03 15:47:03,352 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0010_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 15:47:03,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1514955805909_0010_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-03 15:47:59,493 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 11
2018-01-03 15:48:14,765 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1514955805909_0011' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-03 15:48:14,765 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1514955805909_0011 for the user: hadoop
2018-01-03 15:48:14,766 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 11 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-03 15:48:14,768 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 11 submitted by user hadoop
2018-01-03 15:48:14,768 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1514955805909_0011
2018-01-03 15:48:14,768 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1514955805909_0011
2018-01-03 15:48:14,768 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0011 State change from NEW to NEW_SAVING on event=START
2018-01-03 15:48:14,769 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1514955805909_0011
2018-01-03 15:48:14,769 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0011 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-03 15:48:14,769 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1514955805909_0011 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-03 15:48:14,769 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1514955805909_0011 from user: hadoop, in queue: default
2018-01-03 15:48:14,770 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0011 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-03 15:48:14,770 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1514955805909_0011_000001
2018-01-03 15:48:14,770 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0011_000001 State change from NEW to SUBMITTED
2018-01-03 15:48:14,770 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1514955805909_0011 from user: hadoop activated in queue: default
2018-01-03 15:48:14,770 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1514955805909_0011 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-03 15:48:14,770 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1514955805909_0011_000001 to scheduler from user hadoop in queue default
2018-01-03 15:48:14,773 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0011_000001 State change from SUBMITTED to SCHEDULED
2018-01-03 15:48:14,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:48:14,862 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0011	CONTAINERID=container_1514955805909_0011_01_000001
2018-01-03 15:48:14,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0011_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41166, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-03 15:48:14,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0011_000001 container=container_1514955805909_0011_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3115b7c6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:48:14,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-03 15:48:14,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-03 15:48:14,863 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0011_01_000001
2018-01-03 15:48:14,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:48:14,865 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1514955805909_0011_000001
2018-01-03 15:48:14,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1514955805909_0011 AttemptId: appattempt_1514955805909_0011_000001 MasterContainer: Container: [ContainerId: container_1514955805909_0011_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ]
2018-01-03 15:48:14,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0011_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-03 15:48:14,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0011_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-03 15:48:14,867 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1514955805909_0011_000001
2018-01-03 15:48:14,870 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1514955805909_0011_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0011_000001
2018-01-03 15:48:14,870 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1514955805909_0011_000001
2018-01-03 15:48:14,870 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1514955805909_0011_000001
2018-01-03 15:48:14,891 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1514955805909_0011_01_000001, Version: 0, NodeId: hadoop-worker01.local:41166, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41166 }, ] for AM appattempt_1514955805909_0011_000001
2018-01-03 15:48:14,891 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0011_000001 State change from ALLOCATED to LAUNCHED
2018-01-03 15:48:15,977 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:48:23,991 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1514955805909_0011_000001 (auth:SIMPLE)
2018-01-03 15:48:24,022 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1514955805909_0011_000001
2018-01-03 15:48:24,023 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1514955805909_0011	APPATTEMPTID=appattempt_1514955805909_0011_000001
2018-01-03 15:48:24,027 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1514955805909_0011_000001 State change from LAUNCHED to RUNNING
2018-01-03 15:48:24,027 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1514955805909_0011 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-03 15:48:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:48:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0011	CONTAINERID=container_1514955805909_0011_01_000002
2018-01-03 15:48:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0011_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-03 15:48:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0011_000001 container=container_1514955805909_0011_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3115b7c6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:48:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-03 15:48:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-03 15:48:24,630 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41166 for container : container_1514955805909_0011_01_000002
2018-01-03 15:48:24,631 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:48:25,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:48:25,161 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0011	CONTAINERID=container_1514955805909_0011_01_000003
2018-01-03 15:48:25,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0011_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:45394, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-03 15:48:25,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0011_000001 container=container_1514955805909_0011_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3115b7c6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:48:25,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-03 15:48:25,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-03 15:48:25,291 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:45394 for container : container_1514955805909_0011_01_000003
2018-01-03 15:48:25,295 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:48:25,481 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:48:25,483 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-03 15:48:25,483 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0011	CONTAINERID=container_1514955805909_0011_01_000004
2018-01-03 15:48:25,483 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1514955805909_0011_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-03 15:48:25,483 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1514955805909_0011_000001 container=container_1514955805909_0011_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3115b7c6 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-03 15:48:25,483 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-03 15:48:25,483 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-03 15:48:26,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-03 15:48:28,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1514955805909_0011
2018-01-03 15:48:28,377 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-03 15:48:31,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1514955805909_0011_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-03 15:48:31,437 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1514955805909_0011	CONTAINERID=container_1514955805909_0011_01_000004
2018-01-03 15:48:31,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1514955805909_0011_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41166, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-03 15:51:48,770 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-03 15:51:48,797 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-03 15:51:48,802 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-03 15:51:48,904 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-03 15:51:48,911 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-03 15:51:48,911 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 15:51:48,912 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-03 15:51:48,920 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-03 15:51:48,922 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-03 15:51:48,923 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-03 15:51:48,924 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 15:51:48,926 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-03 15:51:48,990 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-03 15:51:48,991 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 15:51:49,001 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-03 15:51:49,010 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-03 15:51:49,011 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-03 15:51:49,017 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-03 15:51:49,027 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-03 15:51:49,029 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-03 15:51:49,029 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-03 15:51:49,030 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-03 15:51:49,029 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-03 15:51:49,029 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-03 15:51:49,035 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-03 15:51:49,040 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-03 15:51:49,040 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-03 15:51:49,040 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-03 15:51:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-03 15:51:49,041 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-05 14:57:39,493 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-05 14:57:39,595 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-05 14:57:40,744 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-05 14:57:41,079 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-05 14:57:41,365 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-05 14:57:42,274 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-05 14:57:43,500 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-05 14:57:43,531 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-05 14:57:43,561 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-05 14:57:43,857 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-05 14:57:43,864 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-05 14:57:43,865 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-05 14:57:44,036 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-05 14:57:44,038 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-05 14:57:44,040 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-05 14:57:44,042 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-05 14:57:44,285 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-05 14:57:44,491 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-05 14:57:44,491 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-05 14:57:44,595 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-05 14:57:44,652 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-05 14:57:44,676 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-05 14:57:44,688 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-05 14:57:44,692 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-05 14:57:44,752 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-05 14:57:45,268 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-05 14:57:45,268 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-05 14:57:45,281 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-05 14:57:45,282 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-05 14:57:45,393 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-05 14:57:45,393 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-05 14:57:45,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-05 14:57:45,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-05 14:57:45,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-05 14:57:45,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-05 14:57:45,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-05 14:57:45,413 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-05 14:57:45,451 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-05 14:57:45,469 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-05 14:57:45,469 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-05 14:57:45,511 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-05 14:57:45,615 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-05 14:57:45,615 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-05 14:57:45,616 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-05 14:57:45,616 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-05 14:57:45,617 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-05 14:57:45,617 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-05 14:57:45,687 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-05 14:57:45,660 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-05 14:57:45,843 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-05 14:57:45,864 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-05 14:57:46,181 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-05 14:57:46,229 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-05 14:57:46,253 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-05 14:57:47,002 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-05 14:57:47,011 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-05 14:57:47,016 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-05 14:57:47,313 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-05 14:57:47,362 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-05 14:57:47,463 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-05 14:57:47,476 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-05 14:57:47,495 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-05 14:57:48,441 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-05 14:57:48,451 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-05 14:57:48,494 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-05 14:57:48,496 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-05 14:57:48,497 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-05 14:57:48,552 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-05 14:57:48,990 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-05 14:57:49,029 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-05 14:57:49,042 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-05 14:57:49,078 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-05 14:57:49,087 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-05 14:57:49,087 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-05 14:57:49,087 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-05 14:57:49,088 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-05 14:57:49,088 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-05 14:57:49,088 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-05 14:57:49,100 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-05 14:57:49,106 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-05 14:57:50,421 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-05 14:57:50,428 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-05 14:57:50,428 INFO org.mortbay.log: jetty-6.1.26
2018-01-05 14:57:50,608 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-05 14:57:51,447 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-05 14:57:51,462 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-05 14:57:51,480 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-05 14:58:00,905 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-05 14:58:00,905 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-05 14:58:01,087 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-05 14:58:01,093 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-05 14:58:01,100 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-05 14:58:01,107 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-05 14:58:01,109 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-05 14:58:04,687 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 42785 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:42785
2018-01-05 14:58:04,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:42785 Node Transitioned from NEW to RUNNING
2018-01-05 14:58:04,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:42785 clusterResource: <memory:8192, vCores:8>
2018-01-05 14:58:05,238 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:45474 Node Transitioned from NEW to RUNNING
2018-01-05 14:58:05,239 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:45474 clusterResource: <memory:16384, vCores:16>
2018-01-05 14:58:05,201 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 45474 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:45474
2018-01-05 15:08:24,078 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-05 15:38:45,734 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-05 15:39:09,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515131865471_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-05 15:39:09,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515131865471_0001 for the user: hadoop
2018-01-05 15:39:09,675 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-05 15:39:09,696 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-05 15:39:09,702 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515131865471_0001
2018-01-05 15:39:09,697 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515131865471_0001
2018-01-05 15:39:09,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from NEW to NEW_SAVING on event=START
2018-01-05 15:39:09,735 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515131865471_0001
2018-01-05 15:39:09,738 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-05 15:39:09,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515131865471_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-05 15:39:09,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515131865471_0001 from user: hadoop, in queue: default
2018-01-05 15:39:09,923 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-05 15:39:09,986 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515131865471_0001_000001
2018-01-05 15:39:09,987 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from NEW to SUBMITTED
2018-01-05 15:39:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515131865471_0001 from user: hadoop activated in queue: default
2018-01-05 15:39:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515131865471_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-05 15:39:10,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515131865471_0001_000001 to scheduler from user hadoop in queue default
2018-01-05 15:39:10,050 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-05 15:39:11,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-05 15:39:11,026 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000001
2018-01-05 15:39:11,029 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:45474, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-05 15:39:11,029 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0001_000001 container=container_1515131865471_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@6ce43b9 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 15:39:11,096 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:45474 for container : container_1515131865471_0001_01_000001
2018-01-05 15:39:11,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 15:39:11,113 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515131865471_0001_000001
2018-01-05 15:39:11,114 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515131865471_0001 AttemptId: appattempt_1515131865471_0001_000001 MasterContainer: Container: [ContainerId: container_1515131865471_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ]
2018-01-05 15:39:11,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-05 15:39:11,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-05 15:39:11,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-05 15:39:11,152 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-05 15:39:11,168 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515131865471_0001_000001
2018-01-05 15:39:11,320 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515131865471_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ] for AM appattempt_1515131865471_0001_000001
2018-01-05 15:39:11,320 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515131865471_0001_000001
2018-01-05 15:39:11,328 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515131865471_0001_000001
2018-01-05 15:39:12,921 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515131865471_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ] for AM appattempt_1515131865471_0001_000001
2018-01-05 15:39:12,922 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-05 15:39:13,047 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 15:39:38,750 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0001_000001 (auth:SIMPLE)
2018-01-05 15:39:38,780 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515131865471_0001_000001
2018-01-05 15:39:38,781 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515131865471_0001	APPATTEMPTID=appattempt_1515131865471_0001_000001
2018-01-05 15:39:38,781 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from LAUNCHED to RUNNING
2018-01-05 15:39:38,781 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-05 15:39:39,239 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-05 15:39:39,239 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000002
2018-01-05 15:39:39,239 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-05 15:39:39,239 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0001_000001 container=container_1515131865471_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@6ce43b9 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 15:39:39,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-05 15:39:39,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-05 15:39:39,298 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:42785 for container : container_1515131865471_0001_01_000002
2018-01-05 15:39:39,302 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 15:39:39,508 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-05 15:39:39,508 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000003
2018-01-05 15:39:39,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-05 15:39:39,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0001_000001 container=container_1515131865471_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@6ce43b9 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 15:39:39,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-05 15:39:39,509 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-05 15:39:39,758 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:45474 for container : container_1515131865471_0001_01_000003
2018-01-05 15:39:39,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 15:39:40,333 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-05 15:39:40,334 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000004
2018-01-05 15:39:40,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which has 2 containers, <memory:4096, vCores:2> used and <memory:4096, vCores:6> available after allocation
2018-01-05 15:39:40,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0001_000001 container=container_1515131865471_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@6ce43b9 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 15:39:40,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-05 15:39:40,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-05 15:39:42,020 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 15:39:43,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515131865471_0001
2018-01-05 15:39:43,410 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 15:39:44,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 15:39:46,920 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-05 15:39:47,472 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000004
2018-01-05 15:39:49,827 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-05 15:39:49,836 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1897ms
No GCs detected
2018-01-05 15:40:06,496 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10293ms
No GCs detected
2018-01-05 15:40:15,446 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5333ms
No GCs detected
2018-01-05 15:40:16,188 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0001_000001 (auth:SIMPLE)
2018-01-05 15:40:24,987 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1069ms
No GCs detected
2018-01-05 15:40:26,545 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1056ms
No GCs detected
2018-01-05 15:40:39,191 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2076ms
No GCs detected
2018-01-05 16:58:39,107 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1710ms
No GCs detected
2018-01-05 16:59:06,908 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1797ms
No GCs detected
2018-01-05 16:59:07,065 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0001_000001 (auth:SIMPLE)
2018-01-05 16:59:30,217 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2989ms
No GCs detected
2018-01-05 16:59:38,668 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0001_000001 (auth:SIMPLE)
2018-01-05 17:00:15,498 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:00:15,499 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000003
2018-01-05 17:00:15,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-05 17:00:19,627 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000005 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:00:19,627 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000005
2018-01-05 17:00:19,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0001_01_000005 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-05 17:00:19,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0001_000001 container=container_1515131865471_0001_01_000005 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@6ce43b9 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:00:19,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-05 17:00:19,629 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-05 17:00:20,423 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000005 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:00:20,689 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000005 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:00:23,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515131865471_0001
2018-01-05 17:02:19,827 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515131865471_0001_000001 with final state: FINISHING, and exit status: -1000
2018-01-05 17:02:19,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-05 17:02:19,829 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515131865471_0001 with final state: FINISHING
2018-01-05 17:02:19,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-05 17:02:19,856 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515131865471_0001
2018-01-05 17:02:19,881 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from FINAL_SAVING to FINISHING
2018-01-05 17:02:19,881 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-05 17:02:19,972 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515131865471_0001 unregistered successfully. 
2018-01-05 17:02:20,336 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000005 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:02:20,337 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000005
2018-01-05 17:02:20,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0001_01_000005 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-05 17:02:20,552 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:02:20,552 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000001
2018-01-05 17:02:20,552 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515131865471_0001_000001
2018-01-05 17:02:20,552 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:45474, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-05 17:02:20,553 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515131865471_0001_000001
2018-01-05 17:02:20,555 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0001_000001 State change from FINISHING to FINISHED
2018-01-05 17:02:20,560 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-05 17:02:20,562 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515131865471_0001
2018-01-05 17:02:20,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515131865471_0001_000001 is done. finalState=FINISHED
2018-01-05 17:02:20,568 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0001_01_000002 Container Transitioned from RUNNING to KILLED
2018-01-05 17:02:20,568 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0001	CONTAINERID=container_1515131865471_0001_01_000002
2018-01-05 17:02:20,567 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515131865471_0001_000001
2018-01-05 17:02:20,569 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515131865471_0001 requests cleared
2018-01-05 17:02:20,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515131865471_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-05 17:02:20,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515131865471_0001 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-05 17:02:20,571 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515131865471_0001,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515131865471_0001/,appMasterHost=192.168.28.131,startTime=1515134349674,finishTime=1515139339829,finalStatus=SUCCEEDED,memorySeconds=25434888,vcoreSeconds=14911,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-05 17:02:20,938 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:02:20,957 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-05 17:02:21,947 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:02:22,785 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0001_01_000005 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:02:44,379 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2018-01-05 17:02:59,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515131865471_0002' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-05 17:02:59,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515131865471_0002 for the user: hadoop
2018-01-05 17:02:59,724 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-05 17:02:59,725 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user hadoop
2018-01-05 17:02:59,725 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515131865471_0002
2018-01-05 17:02:59,725 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515131865471_0002
2018-01-05 17:02:59,725 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from NEW to NEW_SAVING on event=START
2018-01-05 17:02:59,725 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515131865471_0002
2018-01-05 17:02:59,726 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-05 17:02:59,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515131865471_0002 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-05 17:02:59,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515131865471_0002 from user: hadoop, in queue: default
2018-01-05 17:02:59,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-05 17:02:59,728 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515131865471_0002_000001
2018-01-05 17:02:59,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from NEW to SUBMITTED
2018-01-05 17:02:59,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515131865471_0002 from user: hadoop activated in queue: default
2018-01-05 17:02:59,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515131865471_0002 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-05 17:02:59,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515131865471_0002_000001 to scheduler from user hadoop in queue default
2018-01-05 17:02:59,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from SUBMITTED to SCHEDULED
2018-01-05 17:03:00,503 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:03:00,503 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000001
2018-01-05 17:03:00,503 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:45474, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-05 17:03:00,504 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0002_000001 container=container_1515131865471_0002_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@56e48eba clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:03:00,505 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:45474 for container : container_1515131865471_0002_01_000001
2018-01-05 17:03:00,507 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:03:00,507 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515131865471_0002_000001
2018-01-05 17:03:00,507 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515131865471_0002 AttemptId: appattempt_1515131865471_0002_000001 MasterContainer: Container: [ContainerId: container_1515131865471_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ]
2018-01-05 17:03:00,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-05 17:03:00,507 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-05 17:03:00,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-05 17:03:00,509 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-05 17:03:00,510 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515131865471_0002_000001
2018-01-05 17:03:00,515 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515131865471_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ] for AM appattempt_1515131865471_0002_000001
2018-01-05 17:03:00,515 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515131865471_0002_000001
2018-01-05 17:03:00,515 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515131865471_0002_000001
2018-01-05 17:03:00,562 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515131865471_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ] for AM appattempt_1515131865471_0002_000001
2018-01-05 17:03:00,563 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from ALLOCATED to LAUNCHED
2018-01-05 17:03:03,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:03:16,876 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0002_000001 (auth:SIMPLE)
2018-01-05 17:03:16,927 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515131865471_0002_000001
2018-01-05 17:03:16,927 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515131865471_0002	APPATTEMPTID=appattempt_1515131865471_0002_000001
2018-01-05 17:03:16,927 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from LAUNCHED to RUNNING
2018-01-05 17:03:16,927 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-05 17:03:17,362 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:03:17,362 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000002
2018-01-05 17:03:17,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-05 17:03:17,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0002_000001 container=container_1515131865471_0002_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@56e48eba clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:03:17,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-05 17:03:17,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-05 17:03:17,625 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:42785 for container : container_1515131865471_0002_01_000002
2018-01-05 17:03:17,654 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:03:17,664 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:03:17,664 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000003
2018-01-05 17:03:17,664 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-05 17:03:17,664 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0002_000001 container=container_1515131865471_0002_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@56e48eba clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:03:17,665 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-05 17:03:17,665 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-05 17:03:18,482 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:45474 for container : container_1515131865471_0002_01_000003
2018-01-05 17:03:18,639 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:03:18,931 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:03:18,931 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000004
2018-01-05 17:03:18,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0002_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which has 2 containers, <memory:4096, vCores:2> used and <memory:4096, vCores:6> available after allocation
2018-01-05 17:03:18,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0002_000001 container=container_1515131865471_0002_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@56e48eba clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:03:18,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-05 17:03:18,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-05 17:03:20,262 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:03:21,203 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:03:22,603 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515131865471_0002
2018-01-05 17:03:22,609 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:03:26,039 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-05 17:03:26,040 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000004
2018-01-05 17:03:26,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0002_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-05 17:04:02,958 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2656ms
No GCs detected
2018-01-05 17:15:16,623 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1848ms
No GCs detected
2018-01-05 17:34:16,838 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515131865471_0002_000001 with final state: FINISHING, and exit status: -1000
2018-01-05 17:34:16,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from RUNNING to FINAL_SAVING
2018-01-05 17:34:16,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515131865471_0002 with final state: FINISHING
2018-01-05 17:34:16,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-05 17:34:16,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from FINAL_SAVING to FINISHING
2018-01-05 17:34:16,848 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515131865471_0002
2018-01-05 17:34:16,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-05 17:34:16,996 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515131865471_0002 unregistered successfully. 
2018-01-05 17:34:17,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:34:17,402 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000002
2018-01-05 17:34:17,404 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-05 17:34:18,761 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:34:18,761 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515131865471_0002_000001
2018-01-05 17:34:18,761 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515131865471_0002_000001
2018-01-05 17:34:18,761 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000001
2018-01-05 17:34:18,762 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0002_000001 State change from FINISHING to FINISHED
2018-01-05 17:34:18,762 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:45474, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-05 17:34:18,762 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-05 17:34:18,796 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515131865471_0002
2018-01-05 17:34:18,783 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:34:18,808 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0002	CONTAINERID=container_1515131865471_0002_01_000003
2018-01-05 17:34:18,809 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515131865471_0002,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515131865471_0002/,appMasterHost=192.168.28.131,startTime=1515139379724,finishTime=1515141256843,finalStatus=SUCCEEDED,memorySeconds=9558825,vcoreSeconds=5606,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-05 17:34:18,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-05 17:34:18,815 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515131865471_0002_000001
2018-01-05 17:34:18,836 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515131865471_0002_000001 is done. finalState=FINISHED
2018-01-05 17:34:19,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515131865471_0002 requests cleared
2018-01-05 17:34:19,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515131865471_0002 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-05 17:34:19,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515131865471_0002 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-05 17:34:20,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0002_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:34:20,929 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0002_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:35:09,472 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2018-01-05 17:35:24,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515131865471_0003' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-05 17:35:24,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515131865471_0003 for the user: hadoop
2018-01-05 17:35:24,144 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 3 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-05 17:35:24,144 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user hadoop
2018-01-05 17:35:24,145 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515131865471_0003
2018-01-05 17:35:24,145 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515131865471_0003
2018-01-05 17:35:24,145 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from NEW to NEW_SAVING on event=START
2018-01-05 17:35:24,145 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515131865471_0003
2018-01-05 17:35:24,145 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-05 17:35:24,146 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515131865471_0003 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-05 17:35:24,146 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515131865471_0003 from user: hadoop, in queue: default
2018-01-05 17:35:24,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-05 17:35:24,147 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515131865471_0003_000001
2018-01-05 17:35:24,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from NEW to SUBMITTED
2018-01-05 17:35:24,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515131865471_0003 from user: hadoop activated in queue: default
2018-01-05 17:35:24,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515131865471_0003 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-05 17:35:24,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515131865471_0003_000001 to scheduler from user hadoop in queue default
2018-01-05 17:35:24,157 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from SUBMITTED to SCHEDULED
2018-01-05 17:35:24,662 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:35:24,663 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0003	CONTAINERID=container_1515131865471_0003_01_000001
2018-01-05 17:35:24,663 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0003_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:45474, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-05 17:35:24,663 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0003_000001 container=container_1515131865471_0003_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@57a0dd46 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:35:24,667 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:45474 for container : container_1515131865471_0003_01_000001
2018-01-05 17:35:24,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:35:24,671 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515131865471_0003_000001
2018-01-05 17:35:24,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515131865471_0003 AttemptId: appattempt_1515131865471_0003_000001 MasterContainer: Container: [ContainerId: container_1515131865471_0003_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ]
2018-01-05 17:35:24,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-05 17:35:24,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-05 17:35:24,672 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-05 17:35:24,672 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-05 17:35:24,673 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515131865471_0003_000001
2018-01-05 17:35:24,679 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515131865471_0003_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ] for AM appattempt_1515131865471_0003_000001
2018-01-05 17:35:24,679 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515131865471_0003_000001
2018-01-05 17:35:24,680 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515131865471_0003_000001
2018-01-05 17:35:24,714 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515131865471_0003_01_000001, Version: 0, NodeId: hadoop-worker01.local:45474, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:45474 }, ] for AM appattempt_1515131865471_0003_000001
2018-01-05 17:35:24,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from ALLOCATED to LAUNCHED
2018-01-05 17:35:25,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:35:38,739 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0003_000001 (auth:SIMPLE)
2018-01-05 17:35:38,814 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515131865471_0003_000001
2018-01-05 17:35:38,815 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515131865471_0003	APPATTEMPTID=appattempt_1515131865471_0003_000001
2018-01-05 17:35:38,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from LAUNCHED to RUNNING
2018-01-05 17:35:38,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-05 17:35:39,556 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:35:39,556 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0003	CONTAINERID=container_1515131865471_0003_01_000002
2018-01-05 17:35:39,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0003_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-05 17:35:39,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0003_000001 container=container_1515131865471_0003_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@57a0dd46 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:35:39,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-05 17:35:39,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-05 17:35:39,604 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-05 17:35:39,605 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0003	CONTAINERID=container_1515131865471_0003_01_000003
2018-01-05 17:35:39,605 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515131865471_0003_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-05 17:35:39,605 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515131865471_0003_000001 container=container_1515131865471_0003_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@57a0dd46 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-05 17:35:39,605 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-05 17:35:39,605 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-05 17:35:39,697 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:42785 for container : container_1515131865471_0003_01_000002
2018-01-05 17:35:39,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:35:39,701 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:45474 for container : container_1515131865471_0003_01_000003
2018-01-05 17:35:39,702 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-05 17:35:41,831 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:35:43,100 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-05 17:35:43,125 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515131865471_0003
2018-01-05 17:36:02,364 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1706ms
No GCs detected
2018-01-05 17:37:14,403 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7070ms
No GCs detected
2018-01-05 17:37:22,033 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7128ms
No GCs detected
2018-01-05 17:37:34,583 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1132ms
No GCs detected
2018-01-05 17:37:47,705 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9620ms
No GCs detected
2018-01-05 17:37:53,261 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4325ms
No GCs detected
2018-01-05 17:37:56,614 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515131865471_0003_000001 (auth:SIMPLE)
2018-01-05 17:38:49,817 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3004ms
No GCs detected
2018-01-05 17:39:07,044 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12723ms
No GCs detected
2018-01-05 17:41:01,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515131865471_0003_000001 with final state: FINISHING, and exit status: -1000
2018-01-05 17:41:01,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from RUNNING to FINAL_SAVING
2018-01-05 17:41:01,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515131865471_0003 with final state: FINISHING
2018-01-05 17:41:01,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-05 17:41:01,301 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515131865471_0003
2018-01-05 17:41:01,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from FINAL_SAVING to FINISHING
2018-01-05 17:41:01,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-05 17:41:01,409 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515131865471_0003 unregistered successfully. 
2018-01-05 17:41:01,669 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:41:01,669 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0003	CONTAINERID=container_1515131865471_0003_01_000002
2018-01-05 17:41:01,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0003_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42785, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-05 17:41:01,941 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:41:01,941 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0003	CONTAINERID=container_1515131865471_0003_01_000003
2018-01-05 17:41:01,941 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0003_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:45474, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-05 17:41:01,987 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515131865471_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-05 17:41:01,987 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515131865471_0003	CONTAINERID=container_1515131865471_0003_01_000001
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515131865471_0003_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:45474, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515131865471_0003_000001
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515131865471_0003_000001
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515131865471_0003_000001 State change from FINISHING to FINISHED
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515131865471_0003 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515131865471_0003_000001 is done. finalState=FINISHED
2018-01-05 17:41:01,988 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515131865471_0003
2018-01-05 17:41:01,989 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515131865471_0003 requests cleared
2018-01-05 17:41:01,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515131865471_0003 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-05 17:41:01,990 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515131865471_0003,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515131865471_0003/,appMasterHost=192.168.28.131,startTime=1515141324144,finishTime=1515141661300,finalStatus=SUCCEEDED,memorySeconds=1665255,vcoreSeconds=981,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-05 17:41:01,990 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515131865471_0003 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-05 17:41:01,992 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515131865471_0003_000001
2018-01-05 17:41:03,475 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0003_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:41:03,992 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515131865471_0003_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-05 17:48:36,983 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2697ms
No GCs detected
2018-01-05 19:01:59,719 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-05 19:01:59,896 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-05 19:01:59,913 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-05 19:02:00,024 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-05 19:02:00,112 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-05 19:02:00,115 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-05 19:02:00,122 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-05 19:02:00,134 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-05 19:02:00,139 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-05 19:02:00,142 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-05 19:02:00,147 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-05 19:02:00,155 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-05 19:02:00,178 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-05 19:02:00,179 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-05 19:02:00,178 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-05 19:02:00,192 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-05 19:02:00,193 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-05 19:02:00,195 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-05 19:02:00,205 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-05 19:02:00,212 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-05 19:02:00,228 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-05 19:02:00,227 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-05 19:02:00,227 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-05 19:02:00,228 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-05 19:02:00,258 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-05 19:02:00,278 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-05 19:02:00,280 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-05 19:02:00,281 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-05 19:02:00,288 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-05 19:02:00,292 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-07 12:44:50,425 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-07 12:44:50,441 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-07 12:44:51,790 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-07 12:44:52,112 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-07 12:44:52,399 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-07 12:44:53,377 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-07 12:45:00,283 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-07 12:45:00,389 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-07 12:45:00,430 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-07 12:45:00,992 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-07 12:45:01,001 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-07 12:45:01,001 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-07 12:45:01,069 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-07 12:45:01,071 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-07 12:45:01,072 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-07 12:45:01,074 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-07 12:45:01,306 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-07 12:45:01,689 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-07 12:45:01,689 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-07 12:45:01,754 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-07 12:45:01,843 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-07 12:45:01,849 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-07 12:45:01,866 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-07 12:45:01,888 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-07 12:45:01,918 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-07 12:45:02,477 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-07 12:45:02,477 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-07 12:45:02,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-07 12:45:02,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-07 12:45:02,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-07 12:45:02,551 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-07 12:45:02,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-07 12:45:02,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 12:45:02,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 12:45:02,656 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 12:45:02,656 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-07 12:45:02,658 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-07 12:45:02,665 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-07 12:45:02,698 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-07 12:45:02,698 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-07 12:45:02,729 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-07 12:45:02,783 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-07 12:45:02,783 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-07 12:45:02,784 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-07 12:45:02,784 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 12:45:02,785 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-07 12:45:02,785 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-07 12:45:02,828 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-07 12:45:02,796 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-07 12:45:02,889 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 12:45:03,106 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-07 12:45:03,107 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-07 12:45:03,178 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 12:45:03,225 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-07 12:45:04,741 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-07 12:45:04,750 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-07 12:45:04,751 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 12:45:04,980 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 12:45:05,010 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-07 12:45:05,045 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-07 12:45:05,049 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 12:45:05,060 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-07 12:45:05,549 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 12:45:05,562 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-07 12:45:05,703 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-07 12:45:05,710 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 12:45:05,729 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-07 12:45:06,747 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-07 12:45:07,682 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-07 12:45:07,730 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-07 12:45:07,774 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-07 12:45:07,805 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-07 12:45:07,812 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-07 12:45:07,812 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-07 12:45:07,812 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-07 12:45:07,813 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-07 12:45:07,814 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-07 12:45:07,814 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-07 12:45:07,819 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-07 12:45:07,820 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-07 12:45:09,141 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-07 12:45:09,145 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-07 12:45:09,145 INFO org.mortbay.log: jetty-6.1.26
2018-01-07 12:45:09,253 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-07 12:45:09,748 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 12:45:09,796 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-07 12:45:09,799 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 12:45:16,261 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-07 12:45:16,261 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-07 12:45:16,427 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 12:45:16,449 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-07 12:45:16,454 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-07 12:45:16,485 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 12:45:16,486 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-07 12:45:20,445 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 38529 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:38529
2018-01-07 12:45:20,560 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:38529 Node Transitioned from NEW to RUNNING
2018-01-07 12:45:20,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:38529 clusterResource: <memory:8192, vCores:8>
2018-01-07 12:45:21,088 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:35596 Node Transitioned from NEW to RUNNING
2018-01-07 12:45:21,087 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 35596 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:35596
2018-01-07 12:45:21,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:35596 clusterResource: <memory:16384, vCores:16>
2018-01-07 12:55:54,501 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-07 13:08:07,219 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker02.local:38529 has shutdown, hence unregistering the node.
2018-01-07 13:08:07,219 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node with node id : hadoop-worker01.local:35596 has shutdown, hence unregistering the node.
2018-01-07 13:08:07,229 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker02.local:38529 as it is now SHUTDOWN
2018-01-07 13:08:07,230 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:38529 Node Transitioned from RUNNING to SHUTDOWN
2018-01-07 13:08:07,230 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker01.local:35596 as it is now SHUTDOWN
2018-01-07 13:08:07,230 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:35596 Node Transitioned from RUNNING to SHUTDOWN
2018-01-07 13:08:07,235 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker02.local:38529 clusterResource: <memory:8192, vCores:8>
2018-01-07 13:08:07,236 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker01.local:35596 clusterResource: <memory:0, vCores:0>
2018-01-07 13:09:07,033 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 33665 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:33665
2018-01-07 13:09:07,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:33665 Node Transitioned from NEW to RUNNING
2018-01-07 13:09:07,036 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:33665 clusterResource: <memory:8192, vCores:8>
2018-01-07 13:09:07,237 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 41482 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:41482
2018-01-07 13:09:07,237 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:41482 Node Transitioned from NEW to RUNNING
2018-01-07 13:09:07,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:41482 clusterResource: <memory:16384, vCores:16>
2018-01-07 13:13:22,228 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-07 13:13:48,177 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515296702700_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-07 13:13:48,177 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515296702700_0001 for the user: hadoop
2018-01-07 13:13:48,207 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-07 13:13:48,217 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-07 13:13:48,220 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515296702700_0001
2018-01-07 13:13:48,224 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515296702700_0001
2018-01-07 13:13:48,241 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515296702700_0001 State change from NEW to NEW_SAVING on event=START
2018-01-07 13:13:48,241 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515296702700_0001
2018-01-07 13:13:48,243 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515296702700_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-07 13:13:48,248 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515296702700_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-07 13:13:48,250 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515296702700_0001 from user: hadoop, in queue: default
2018-01-07 13:13:48,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515296702700_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-07 13:13:48,329 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515296702700_0001_000001
2018-01-07 13:13:48,332 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from NEW to SUBMITTED
2018-01-07 13:13:48,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515296702700_0001 from user: hadoop activated in queue: default
2018-01-07 13:13:48,405 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515296702700_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-07 13:13:48,406 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515296702700_0001_000001 to scheduler from user hadoop in queue default
2018-01-07 13:13:48,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-07 13:13:49,157 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-07 13:13:49,157 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515296702700_0001	CONTAINERID=container_1515296702700_0001_01_000001
2018-01-07 13:13:49,159 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515296702700_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:33665, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-07 13:13:49,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515296702700_0001_000001 container=container_1515296702700_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1b9f6112 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 13:13:49,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-07 13:13:49,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-07 13:13:49,193 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:33665 for container : container_1515296702700_0001_01_000001
2018-01-07 13:13:49,204 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 13:13:49,205 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515296702700_0001_000001
2018-01-07 13:13:49,205 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515296702700_0001 AttemptId: appattempt_1515296702700_0001_000001 MasterContainer: Container: [ContainerId: container_1515296702700_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:33665, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:33665 }, ]
2018-01-07 13:13:49,217 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-07 13:13:49,224 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-07 13:13:49,230 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515296702700_0001_000001
2018-01-07 13:13:49,308 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515296702700_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:33665, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:33665 }, ] for AM appattempt_1515296702700_0001_000001
2018-01-07 13:13:49,309 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515296702700_0001_000001
2018-01-07 13:13:49,313 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515296702700_0001_000001
2018-01-07 13:13:49,845 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515296702700_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:33665, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:33665 }, ] for AM appattempt_1515296702700_0001_000001
2018-01-07 13:13:49,846 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-07 13:13:50,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-07 13:14:13,472 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515296702700_0001_000001 (auth:SIMPLE)
2018-01-07 13:14:13,683 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515296702700_0001_000001
2018-01-07 13:14:13,687 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515296702700_0001	APPATTEMPTID=appattempt_1515296702700_0001_000001
2018-01-07 13:14:13,693 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from LAUNCHED to RUNNING
2018-01-07 13:14:13,694 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515296702700_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-07 13:14:15,036 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-07 13:14:15,037 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515296702700_0001	CONTAINERID=container_1515296702700_0001_01_000002
2018-01-07 13:14:15,037 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515296702700_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41482, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-07 13:14:15,037 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515296702700_0001_000001 container=container_1515296702700_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1b9f6112 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 13:14:15,037 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-07 13:14:15,037 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-07 13:14:15,097 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-07 13:14:15,097 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515296702700_0001	CONTAINERID=container_1515296702700_0001_01_000003
2018-01-07 13:14:15,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515296702700_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:33665, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-07 13:14:15,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515296702700_0001_000001 container=container_1515296702700_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@1b9f6112 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 13:14:15,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-07 13:14:15,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-07 13:14:15,673 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:41482 for container : container_1515296702700_0001_01_000002
2018-01-07 13:14:15,696 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 13:14:15,697 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:33665 for container : container_1515296702700_0001_01_000003
2018-01-07 13:14:15,710 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 13:14:19,101 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2179ms
No GCs detected
2018-01-07 13:14:19,517 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515296702700_0001
2018-01-07 13:14:27,085 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-07 13:14:32,881 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-07 13:14:39,575 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1529ms
No GCs detected
2018-01-07 13:14:52,020 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2056ms
No GCs detected
2018-01-07 13:14:57,394 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4873ms
No GCs detected
2018-01-07 13:15:09,260 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11366ms
No GCs detected
2018-01-07 13:16:07,471 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 57710ms
No GCs detected
2018-01-07 13:16:23,339 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15367ms
No GCs detected
2018-01-07 13:16:30,550 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6710ms
No GCs detected
2018-01-07 13:16:36,801 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5750ms
No GCs detected
2018-01-07 13:17:23,346 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 46045ms
No GCs detected
2018-01-07 13:17:32,182 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3817ms
No GCs detected
2018-01-07 13:17:34,639 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515296702700_0001_000001 (auth:SIMPLE)
2018-01-07 13:17:45,505 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6329ms
No GCs detected
2018-01-07 13:17:50,257 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515296702700_0001_000001 (auth:SIMPLE)
2018-01-07 13:17:57,737 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5991ms
No GCs detected
2018-01-07 13:18:06,091 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3470ms
No GCs detected
2018-01-07 13:18:13,594 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4229ms
No GCs detected
2018-01-07 13:18:16,296 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1580ms
No GCs detected
2018-01-07 13:18:19,659 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1467ms
No GCs detected
2018-01-07 13:18:21,131 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515296702700_0001_000001 (auth:SIMPLE)
2018-01-07 13:18:30,298 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6457ms
No GCs detected
2018-01-07 13:18:32,183 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1384ms
No GCs detected
2018-01-07 13:18:41,605 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8237ms
GC pool 'Copy' had collection(s): count=1 time=6ms
2018-01-07 13:19:45,802 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 46979ms
No GCs detected
2018-01-07 13:19:56,573 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7589ms
No GCs detected
2018-01-07 13:19:59,531 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2457ms
No GCs detected
2018-01-07 13:20:36,395 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 36363ms
No GCs detected
2018-01-07 13:20:52,288 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7379ms
No GCs detected
2018-01-07 13:20:57,367 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4579ms
No GCs detected
2018-01-07 13:21:05,894 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8026ms
No GCs detected
2018-01-07 13:21:14,036 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7641ms
No GCs detected
2018-01-07 13:21:21,950 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7413ms
No GCs detected
2018-01-07 13:21:36,977 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1006ms
No GCs detected
2018-01-07 13:21:42,109 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4632ms
No GCs detected
2018-01-07 13:24:20,476 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 156030ms
No GCs detected
2018-01-07 13:24:25,641 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4665ms
No GCs detected
2018-01-07 13:24:41,850 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1116ms
No GCs detected
2018-01-07 13:26:27,377 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 97462ms
No GCs detected
2018-01-07 13:26:39,281 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11403ms
No GCs detected
2018-01-07 13:27:05,654 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25872ms
No GCs detected
2018-01-07 13:27:17,929 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8912ms
No GCs detected
2018-01-07 13:27:35,893 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11117ms
No GCs detected
2018-01-07 13:27:44,271 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1038ms
No GCs detected
2018-01-07 13:27:58,052 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13280ms
No GCs detected
2018-01-07 13:28:22,944 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9093ms
No GCs detected
2018-01-07 13:28:36,089 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8704ms
No GCs detected
2018-01-07 13:29:28,149 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22811ms
No GCs detected
2018-01-07 13:30:43,237 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 74587ms
No GCs detected
2018-01-07 13:31:30,077 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:appattempt_1515296702700_0001_000001 Timed out after 600 secs
2018-01-07 13:31:30,079 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 46342ms
No GCs detected
2018-01-07 13:31:30,077 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:hadoop-worker01.local:33665 Timed out after 600 secs
2018-01-07 13:33:42,138 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515296702700_0001_000001 with final state: FAILED, and exit status: -1000
2018-01-07 13:33:42,139 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-07 13:33:42,139 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker01.local:33665 as it is now LOST
2018-01-07 13:33:42,140 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:33665 Node Transitioned from RUNNING to LOST
2018-01-07 13:33:42,143 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 97445ms
No GCs detected
2018-01-07 13:33:42,146 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515296702700_0001_000001
2018-01-07 13:33:42,147 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515296702700_0001_000001
2018-01-07 13:33:42,148 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000001 State change from FINAL_SAVING to FAILED
2018-01-07 13:33:42,148 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The number of failed attempts is 1. The max attempts is 2
2018-01-07 13:33:42,149 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515296702700_0001 State change from RUNNING to ACCEPTED on event=ATTEMPT_FAILED
2018-01-07 13:33:42,149 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515296702700_0001_000002
2018-01-07 13:33:42,150 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000002 State change from NEW to SUBMITTED
2018-01-07 13:33:47,626 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4429ms
No GCs detected
2018-01-07 13:33:52,856 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4729ms
No GCs detected
2018-01-07 13:33:59,258 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000001 Container Transitioned from RUNNING to KILLED
2018-01-07 13:33:59,259 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515296702700_0001	CONTAINERID=container_1515296702700_0001_01_000001
2018-01-07 13:33:59,262 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000003 Container Transitioned from RUNNING to KILLED
2018-01-07 13:33:59,262 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515296702700_0001	CONTAINERID=container_1515296702700_0001_01_000003
2018-01-07 13:33:59,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker01.local:33665 clusterResource: <memory:8192, vCores:8>
2018-01-07 13:33:59,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515296702700_0001_000001 is done. finalState=FAILED
2018-01-07 13:33:59,290 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515296702700_0001_01_000002 Container Transitioned from RUNNING to KILLED
2018-01-07 13:33:59,290 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515296702700_0001	CONTAINERID=container_1515296702700_0001_01_000002
2018-01-07 13:33:59,277 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5920ms
No GCs detected
2018-01-07 13:33:59,278 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515296702700_0001_000001
2018-01-07 13:34:05,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515296702700_0001 requests cleared
2018-01-07 13:34:05,354 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515296702700_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-07 13:34:05,355 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515296702700_0001 from user: hadoop activated in queue: default
2018-01-07 13:34:05,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515296702700_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-07 13:34:05,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515296702700_0001_000002 to scheduler from user hadoop in queue default
2018-01-07 13:34:05,774 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515296702700_0001_000002 State change from SUBMITTED to SCHEDULED
2018-01-07 13:34:18,935 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4061ms
No GCs detected
2018-01-07 13:34:39,418 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4079ms
No GCs detected
2018-01-07 13:34:46,661 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3239ms
No GCs detected
2018-01-07 13:35:03,254 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16093ms
No GCs detected
2018-01-07 13:35:30,525 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1465ms
No GCs detected
2018-01-07 13:35:39,930 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1656ms
No GCs detected
2018-01-07 13:36:00,328 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19367ms
No GCs detected
2018-01-07 13:36:21,924 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21095ms
No GCs detected
2018-01-07 13:36:21,940 WARN org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.28.129:54958 remote=hadoop-worker01.local/192.168.28.131:33665]
2018-01-07 13:36:21,950 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Error cleaning master 
java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.28.129:54958 remote=hadoop-worker01.local/192.168.28.131:33665]; Host Details : local host is: "hadoop-master/192.168.28.129"; destination host is: "hadoop-worker01.local":33665; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1487)
	at org.apache.hadoop.ipc.Client.call(Client.java:1429)
	at org.apache.hadoop.ipc.Client.call(Client.java:1339)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy86.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:120)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy87.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.cleanup(AMLauncher.java:139)
	at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:264)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.28.129:54958 remote=hadoop-worker01.local/192.168.28.131:33665]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:752)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:715)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:805)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1544)
	at org.apache.hadoop.ipc.Client.call(Client.java:1375)
	... 20 more
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.28.129:54958 remote=hadoop-worker01.local/192.168.28.131:33665]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1788)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:364)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:614)
	at org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:410)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:792)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:788)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:787)
	... 23 more
2018-01-07 13:36:38,987 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16562ms
No GCs detected
2018-01-07 13:36:46,349 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1274ms
No GCs detected
2018-01-07 13:37:18,493 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 30448ms
No GCs detected
2018-01-07 13:37:18,495 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:hadoop-worker02.local:41482 Timed out after 600 secs
2018-01-07 13:37:39,445 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15469ms
No GCs detected
2018-01-07 13:37:41,024 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1078ms
No GCs detected
2018-01-07 13:37:58,675 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Deactivating Node hadoop-worker02.local:41482 as it is now LOST
2018-01-07 13:38:31,708 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 42735ms
No GCs detected
2018-01-07 13:38:31,710 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:41482 Node Transitioned from RUNNING to LOST
2018-01-07 13:38:46,163 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13953ms
No GCs detected
2018-01-07 13:38:46,163 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Removed node hadoop-worker02.local:41482 clusterResource: <memory:0, vCores:0>
2018-01-07 13:39:57,464 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27669ms
No GCs detected
2018-01-07 13:40:47,566 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23255ms
No GCs detected
2018-01-07 13:41:07,184 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19118ms
No GCs detected
2018-01-07 13:41:28,696 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20392ms
No GCs detected
2018-01-07 13:41:40,477 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11280ms
No GCs detected
2018-01-07 13:41:40,621 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node not found resyncing hadoop-worker02.local:41482
2018-01-07 13:42:02,879 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 21901ms
No GCs detected
2018-01-07 13:42:20,261 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16881ms
No GCs detected
2018-01-07 13:42:34,229 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6045ms
No GCs detected
2018-01-07 13:42:39,203 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4474ms
No GCs detected
2018-01-07 13:42:43,392 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3688ms
No GCs detected
2018-01-07 13:42:46,959 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3067ms
No GCs detected
2018-01-07 13:43:25,573 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25498ms
No GCs detected
2018-01-07 13:43:31,083 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4478ms
No GCs detected
2018-01-07 13:43:40,914 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9330ms
No GCs detected
2018-01-07 13:43:44,229 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2815ms
No GCs detected
2018-01-07 13:44:05,321 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13114ms
No GCs detected
2018-01-07 13:44:11,310 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5488ms
No GCs detected
2018-01-07 13:44:18,037 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6226ms
No GCs detected
2018-01-07 13:44:24,726 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6189ms
No GCs detected
2018-01-07 13:44:28,033 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2806ms
No GCs detected
2018-01-07 13:44:53,619 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1276ms
No GCs detected
2018-01-07 13:45:15,483 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4941ms
No GCs detected
2018-01-07 13:45:27,690 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11706ms
No GCs detected
2018-01-07 13:45:38,050 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3849ms
No GCs detected
2018-01-07 13:46:41,085 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13973ms
No GCs detected
2018-01-07 13:46:59,715 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3630ms
No GCs detected
2018-01-07 13:47:20,867 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1107ms
No GCs detected
2018-01-07 13:47:27,146 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2275ms
No GCs detected
2018-01-07 13:47:40,703 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2543ms
No GCs detected
2018-01-07 13:48:13,898 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2665ms
No GCs detected
2018-01-07 13:48:27,162 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5259ms
No GCs detected
2018-01-07 13:49:17,940 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4127ms
No GCs detected
2018-01-07 13:49:21,422 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2467ms
No GCs detected
2018-01-07 13:49:26,394 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4471ms
No GCs detected
2018-01-07 13:49:33,491 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3094ms
No GCs detected
2018-01-07 13:49:35,278 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1286ms
No GCs detected
2018-01-07 13:49:44,437 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4151ms
No GCs detected
2018-01-07 13:49:48,678 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3740ms
No GCs detected
2018-01-07 13:49:52,886 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3708ms
No GCs detected
2018-01-07 13:49:57,275 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3888ms
No GCs detected
2018-01-07 13:50:10,048 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11771ms
No GCs detected
2018-01-07 13:50:19,816 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9267ms
No GCs detected
2018-01-07 14:18:30,471 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-07 14:18:30,483 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-07 14:18:30,928 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-07 14:18:31,101 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-07 14:18:31,252 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-07 14:18:31,724 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-07 14:18:32,409 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-07 14:18:32,417 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-07 14:18:32,433 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-07 14:18:32,709 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-07 14:18:32,717 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-07 14:18:32,717 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-07 14:18:32,797 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-07 14:18:32,799 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-07 14:18:32,805 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-07 14:18:32,807 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-07 14:18:32,933 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-07 14:18:33,176 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-07 14:18:33,176 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-07 14:18:33,201 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-07 14:18:33,251 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-07 14:18:33,256 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-07 14:18:33,277 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-07 14:18:33,280 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-07 14:18:33,302 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-07 14:18:33,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-07 14:18:33,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-07 14:18:33,560 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-07 14:18:33,560 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-07 14:18:33,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-07 14:18:33,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-07 14:18:33,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-07 14:18:33,650 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 14:18:33,651 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 14:18:33,746 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 14:18:33,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-07 14:18:33,755 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-07 14:18:33,760 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-07 14:18:33,797 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-07 14:18:33,797 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-07 14:18:33,815 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-07 14:18:33,875 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-07 14:18:33,876 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-07 14:18:33,876 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-07 14:18:33,876 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 14:18:33,877 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-07 14:18:33,878 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-07 14:18:33,908 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-07 14:18:33,908 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 14:18:33,909 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-07 14:18:33,909 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-07 14:18:33,921 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-07 14:18:34,026 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 14:18:39,744 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-07 14:18:40,369 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-07 14:18:40,378 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 14:18:40,389 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-07 14:18:40,612 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 14:18:40,629 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-07 14:18:40,658 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-07 14:18:40,662 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 14:18:40,664 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-07 14:18:41,231 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 14:18:41,266 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-07 14:18:41,267 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-07 14:18:41,325 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 14:18:41,330 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-07 14:18:41,700 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-07 14:18:42,079 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-07 14:18:42,132 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-07 14:18:42,148 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-07 14:18:42,188 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-07 14:18:42,194 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-07 14:18:42,194 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-07 14:18:42,194 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-07 14:18:42,196 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-07 14:18:42,196 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-07 14:18:42,196 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-07 14:18:42,203 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-07 14:18:42,204 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-07 14:18:43,787 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-07 14:18:43,792 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-07 14:18:43,792 INFO org.mortbay.log: jetty-6.1.26
2018-01-07 14:18:43,933 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-07 14:18:44,889 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 14:18:44,893 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-07 14:18:44,987 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 14:18:50,067 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-07 14:18:50,067 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-07 14:18:50,440 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 14:18:50,461 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-07 14:18:50,510 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-07 14:18:50,550 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 14:18:50,552 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-07 14:18:59,064 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 34371 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:34371
2018-01-07 14:18:59,075 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 42559 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:42559
2018-01-07 14:18:59,098 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:34371 Node Transitioned from NEW to RUNNING
2018-01-07 14:18:59,098 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:42559 Node Transitioned from NEW to RUNNING
2018-01-07 14:18:59,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:34371 clusterResource: <memory:8192, vCores:8>
2018-01-07 14:18:59,176 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:42559 clusterResource: <memory:16384, vCores:16>
2018-01-07 14:21:06,811 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-07 14:21:22,383 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515302313799_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-07 14:21:22,383 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515302313799_0001 for the user: hadoop
2018-01-07 14:21:22,404 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-07 14:21:22,462 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-07 14:21:22,462 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515302313799_0001
2018-01-07 14:21:22,464 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515302313799_0001
2018-01-07 14:21:22,475 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515302313799_0001 State change from NEW to NEW_SAVING on event=START
2018-01-07 14:21:22,475 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515302313799_0001
2018-01-07 14:21:22,476 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515302313799_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-07 14:21:22,478 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515302313799_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-07 14:21:22,480 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515302313799_0001 from user: hadoop, in queue: default
2018-01-07 14:21:22,496 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515302313799_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-07 14:21:22,540 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515302313799_0001_000001
2018-01-07 14:21:22,542 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515302313799_0001_000001 State change from NEW to SUBMITTED
2018-01-07 14:21:22,577 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515302313799_0001 from user: hadoop activated in queue: default
2018-01-07 14:21:22,577 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515302313799_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-07 14:21:22,577 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515302313799_0001_000001 to scheduler from user hadoop in queue default
2018-01-07 14:21:22,580 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515302313799_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-07 14:21:22,667 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-07 14:21:22,667 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515302313799_0001	CONTAINERID=container_1515302313799_0001_01_000001
2018-01-07 14:21:22,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515302313799_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:42559, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-07 14:21:22,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515302313799_0001_000001 container=container_1515302313799_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@9544f5f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 14:21:22,699 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:42559 for container : container_1515302313799_0001_01_000001
2018-01-07 14:21:22,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 14:21:22,718 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515302313799_0001_000001
2018-01-07 14:21:22,718 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515302313799_0001 AttemptId: appattempt_1515302313799_0001_000001 MasterContainer: Container: [ContainerId: container_1515302313799_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:42559, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:42559 }, ]
2018-01-07 14:21:22,718 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-07 14:21:22,718 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-07 14:21:22,735 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515302313799_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-07 14:21:22,742 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515302313799_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-07 14:21:22,749 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515302313799_0001_000001
2018-01-07 14:21:22,837 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515302313799_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:42559, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:42559 }, ] for AM appattempt_1515302313799_0001_000001
2018-01-07 14:21:22,838 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515302313799_0001_000001
2018-01-07 14:21:22,843 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515302313799_0001_000001
2018-01-07 14:21:23,402 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515302313799_0001_01_000001, Version: 0, NodeId: hadoop-worker02.local:42559, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:42559 }, ] for AM appattempt_1515302313799_0001_000001
2018-01-07 14:21:23,403 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515302313799_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-07 14:21:23,573 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-07 14:21:36,118 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515302313799_0001_000001 (auth:SIMPLE)
2018-01-07 14:21:36,137 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515302313799_0001_000001
2018-01-07 14:21:36,143 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515302313799_0001	APPATTEMPTID=appattempt_1515302313799_0001_000001
2018-01-07 14:21:36,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515302313799_0001_000001 State change from LAUNCHED to RUNNING
2018-01-07 14:21:36,144 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515302313799_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-07 14:21:36,782 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-07 14:21:36,782 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515302313799_0001	CONTAINERID=container_1515302313799_0001_01_000002
2018-01-07 14:21:36,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515302313799_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:34371, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-07 14:21:36,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515302313799_0001_000001 container=container_1515302313799_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@9544f5f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 14:21:36,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-07 14:21:36,782 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-07 14:21:36,992 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:34371 for container : container_1515302313799_0001_01_000002
2018-01-07 14:21:37,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 14:21:37,186 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-07 14:21:37,187 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515302313799_0001	CONTAINERID=container_1515302313799_0001_01_000003
2018-01-07 14:21:37,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515302313799_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42559, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-07 14:21:37,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515302313799_0001_000001 container=container_1515302313799_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@9544f5f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 14:21:37,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-07 14:21:37,187 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-07 14:21:37,796 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:42559 for container : container_1515302313799_0001_01_000003
2018-01-07 14:21:37,808 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 14:21:38,206 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-07 14:21:38,229 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-07 14:21:38,229 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515302313799_0001	CONTAINERID=container_1515302313799_0001_01_000004
2018-01-07 14:21:38,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515302313799_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42559, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-07 14:21:38,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515302313799_0001_000001 container=container_1515302313799_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@9544f5f clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-07 14:21:38,230 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-07 14:21:38,230 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-07 14:21:39,263 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-07 14:21:40,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515302313799_0001
2018-01-07 14:21:40,957 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-07 14:21:44,049 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515302313799_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-07 14:21:44,075 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515302313799_0001	CONTAINERID=container_1515302313799_0001_01_000004
2018-01-07 14:21:44,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515302313799_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:42559, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-07 14:29:00,702 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-07 16:13:45,420 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-07 16:13:45,440 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-07 16:13:45,443 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-07 16:13:45,448 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-07 16:13:45,456 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-07 16:13:45,456 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-07 16:13:45,459 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 16:13:45,464 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-07 16:13:45,464 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-07 16:13:45,466 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 16:13:45,467 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-07 16:13:45,468 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-07 16:13:45,474 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-07 16:13:45,474 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 16:13:45,476 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-07 16:13:45,480 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 16:13:45,480 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-07 16:13:45,481 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-07 16:13:45,481 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-07 16:13:45,482 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-07 16:13:45,485 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-07 16:13:45,485 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-07 16:13:45,485 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-07 16:13:45,486 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-07 16:13:45,488 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-07 16:13:45,490 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-07 16:13:45,491 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-07 16:13:45,491 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-07 16:13:45,492 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-07 16:13:45,493 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-07 21:10:45,672 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-07 21:10:45,690 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-07 21:10:46,143 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-07 21:10:46,366 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-07 21:10:46,533 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-07 21:10:47,053 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-07 21:10:47,815 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-07 21:10:47,826 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-07 21:10:47,851 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-07 21:10:48,009 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-07 21:10:48,063 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-07 21:10:48,064 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-07 21:10:48,166 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-07 21:10:48,167 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-07 21:10:48,169 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-07 21:10:48,171 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-07 21:10:48,427 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-07 21:10:48,591 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-07 21:10:48,591 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-07 21:10:48,622 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-07 21:10:48,669 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-07 21:10:48,677 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-07 21:10:48,690 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-07 21:10:48,693 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-07 21:10:48,704 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-07 21:10:48,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-07 21:10:48,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-07 21:10:49,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-07 21:10:49,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-07 21:10:49,036 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-07 21:10:49,036 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-07 21:10:49,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-07 21:10:49,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 21:10:49,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 21:10:49,073 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-07 21:10:49,073 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-07 21:10:49,075 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-07 21:10:49,083 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-07 21:10:49,126 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-07 21:10:49,126 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-07 21:10:49,160 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-07 21:10:49,207 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-07 21:10:49,207 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-07 21:10:49,208 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-07 21:10:49,238 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 21:10:49,239 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-07 21:10:49,240 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-07 21:10:49,279 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-07 21:10:49,279 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 21:10:49,279 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-07 21:10:49,280 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-07 21:10:49,289 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-07 21:10:49,368 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 21:10:49,434 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-07 21:10:50,060 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-07 21:10:50,068 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 21:10:50,105 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-07 21:10:50,485 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 21:10:50,510 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-07 21:10:50,534 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-07 21:10:50,536 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 21:10:50,546 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-07 21:10:51,610 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 21:10:51,611 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-07 21:10:51,663 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-07 21:10:51,679 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-07 21:10:51,681 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 21:10:52,133 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-07 21:10:52,407 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-07 21:10:52,449 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-07 21:10:52,461 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-07 21:10:52,500 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-07 21:10:52,513 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-07 21:10:52,514 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-07 21:10:52,514 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-07 21:10:52,515 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-07 21:10:52,515 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-07 21:10:52,515 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-07 21:10:52,523 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-07 21:10:52,523 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-07 21:10:53,754 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-07 21:10:53,758 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-07 21:10:53,758 INFO org.mortbay.log: jetty-6.1.26
2018-01-07 21:10:53,824 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-07 21:10:54,303 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 21:10:54,305 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-07 21:10:54,313 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-07 21:10:58,889 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-07 21:10:58,890 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-07 21:10:59,260 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-07 21:10:59,262 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-07 21:10:59,274 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-07 21:10:59,297 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-07 21:10:59,348 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-07 21:11:03,174 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 41439 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:41439
2018-01-07 21:11:03,174 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 35302 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:35302
2018-01-07 21:11:03,185 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:41439 Node Transitioned from NEW to RUNNING
2018-01-07 21:11:03,186 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:35302 Node Transitioned from NEW to RUNNING
2018-01-07 21:11:03,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:41439 clusterResource: <memory:8192, vCores:8>
2018-01-07 21:11:03,213 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:35302 clusterResource: <memory:16384, vCores:16>
2018-01-07 21:21:13,336 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-07 23:35:37,757 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-07 23:35:37,790 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-07 23:35:37,795 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-07 23:35:37,903 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-07 23:35:37,927 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-07 23:35:37,929 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 23:35:37,934 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-07 23:35:37,945 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 23:35:37,945 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-07 23:35:37,948 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-07 23:35:37,950 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-07 23:35:37,950 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-07 23:35:37,956 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-07 23:35:37,958 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-07 23:35:37,966 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 23:35:37,971 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-07 23:35:37,972 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-07 23:35:37,969 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-07 23:35:37,968 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-07 23:35:37,972 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-07 23:35:37,980 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-07 23:35:37,984 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-07 23:35:37,987 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-07 23:35:37,987 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-07 23:35:37,987 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-07 23:35:37,994 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-07 23:35:37,995 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-07 23:35:37,995 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-07 23:35:37,997 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-07 23:35:37,998 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-08 07:14:26,368 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-08 07:14:26,378 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-08 07:14:26,857 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-08 07:14:27,008 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-08 07:14:27,180 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-08 07:14:27,638 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-08 07:14:28,309 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-08 07:14:28,334 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-08 07:14:28,344 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-08 07:14:28,486 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-08 07:14:28,500 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-08 07:14:28,500 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-08 07:14:28,565 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-08 07:14:28,566 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-08 07:14:28,567 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-08 07:14:28,569 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-08 07:14:28,698 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-08 07:14:28,892 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-08 07:14:28,893 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-08 07:14:28,924 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-08 07:14:28,952 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-08 07:14:28,964 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-08 07:14:28,980 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-08 07:14:28,984 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-08 07:14:29,030 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-08 07:14:29,222 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-08 07:14:29,223 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-08 07:14:29,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-08 07:14:29,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-08 07:14:29,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-08 07:14:29,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-08 07:14:29,286 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-08 07:14:29,287 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-08 07:14:29,287 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-08 07:14:29,410 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-08 07:14:29,410 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-08 07:14:29,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-08 07:14:29,470 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-08 07:14:29,508 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-08 07:14:29,508 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-08 07:14:29,535 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-08 07:14:29,593 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-08 07:14:29,594 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-08 07:14:29,594 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-08 07:14:29,594 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 07:14:29,595 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-08 07:14:29,596 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-08 07:14:29,599 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-08 07:14:29,599 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 07:14:29,599 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-08 07:14:29,600 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-08 07:14:29,621 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-08 07:14:29,728 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 07:14:29,777 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-08 07:14:30,503 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-08 07:14:30,505 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 07:14:30,523 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-08 07:14:30,920 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 07:14:30,948 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-08 07:14:30,999 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-08 07:14:31,005 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 07:14:31,059 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-08 07:14:31,598 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 07:14:31,623 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-08 07:14:31,663 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-08 07:14:31,667 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 07:14:31,715 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-08 07:14:32,059 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-08 07:14:32,378 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-08 07:14:32,437 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-08 07:14:32,462 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-08 07:14:32,478 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-08 07:14:32,484 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-08 07:14:32,484 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-08 07:14:32,485 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-08 07:14:32,486 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-08 07:14:32,486 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-08 07:14:32,486 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-08 07:14:32,497 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-08 07:14:32,497 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-08 07:14:34,011 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-08 07:14:34,014 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-08 07:14:34,015 INFO org.mortbay.log: jetty-6.1.26
2018-01-08 07:14:34,169 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-08 07:14:35,060 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 07:14:35,061 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-08 07:14:35,078 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 07:14:40,606 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-08 07:14:40,612 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-08 07:14:40,764 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 07:14:40,780 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-08 07:14:40,785 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-08 07:14:40,826 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 07:14:40,833 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-08 07:14:53,838 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 37910 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:37910
2018-01-08 07:14:53,840 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 36273 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:36273
2018-01-08 07:14:53,855 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:37910 Node Transitioned from NEW to RUNNING
2018-01-08 07:14:53,855 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:36273 Node Transitioned from NEW to RUNNING
2018-01-08 07:14:53,872 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:37910 clusterResource: <memory:8192, vCores:8>
2018-01-08 07:14:53,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:36273 clusterResource: <memory:16384, vCores:16>
2018-01-08 07:24:51,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-08 07:41:19,537 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-08 07:41:34,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515363269510_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-08 07:41:34,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515363269510_0001 for the user: hadoop
2018-01-08 07:41:34,534 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-08 07:41:34,540 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-08 07:41:34,540 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515363269510_0001
2018-01-08 07:41:34,542 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515363269510_0001
2018-01-08 07:41:34,554 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515363269510_0001 State change from NEW to NEW_SAVING on event=START
2018-01-08 07:41:34,554 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515363269510_0001
2018-01-08 07:41:34,555 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515363269510_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-08 07:41:34,559 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515363269510_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-08 07:41:34,560 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515363269510_0001 from user: hadoop, in queue: default
2018-01-08 07:41:34,598 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515363269510_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-08 07:41:34,640 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515363269510_0001_000001
2018-01-08 07:41:34,642 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515363269510_0001_000001 State change from NEW to SUBMITTED
2018-01-08 07:41:34,669 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515363269510_0001 from user: hadoop activated in queue: default
2018-01-08 07:41:34,669 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515363269510_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-08 07:41:34,670 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515363269510_0001_000001 to scheduler from user hadoop in queue default
2018-01-08 07:41:34,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515363269510_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-08 07:41:34,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-08 07:41:34,897 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515363269510_0001	CONTAINERID=container_1515363269510_0001_01_000001
2018-01-08 07:41:34,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515363269510_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:36273, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-08 07:41:34,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515363269510_0001_000001 container=container_1515363269510_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@462e5d3d clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 07:41:34,939 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:36273 for container : container_1515363269510_0001_01_000001
2018-01-08 07:41:34,955 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 07:41:34,956 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515363269510_0001_000001
2018-01-08 07:41:34,956 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-08 07:41:34,956 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515363269510_0001 AttemptId: appattempt_1515363269510_0001_000001 MasterContainer: Container: [ContainerId: container_1515363269510_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:36273, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:36273 }, ]
2018-01-08 07:41:34,956 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-08 07:41:34,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515363269510_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-08 07:41:34,981 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515363269510_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-08 07:41:34,985 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515363269510_0001_000001
2018-01-08 07:41:35,058 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515363269510_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:36273, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:36273 }, ] for AM appattempt_1515363269510_0001_000001
2018-01-08 07:41:35,058 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515363269510_0001_000001
2018-01-08 07:41:35,061 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515363269510_0001_000001
2018-01-08 07:41:35,548 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515363269510_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:36273, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:36273 }, ] for AM appattempt_1515363269510_0001_000001
2018-01-08 07:41:35,549 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515363269510_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-08 07:41:35,770 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 07:41:47,450 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515363269510_0001_000001 (auth:SIMPLE)
2018-01-08 07:41:47,491 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515363269510_0001_000001
2018-01-08 07:41:47,493 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515363269510_0001	APPATTEMPTID=appattempt_1515363269510_0001_000001
2018-01-08 07:41:47,497 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515363269510_0001_000001 State change from LAUNCHED to RUNNING
2018-01-08 07:41:47,497 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515363269510_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-08 07:41:48,171 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-08 07:41:48,172 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515363269510_0001	CONTAINERID=container_1515363269510_0001_01_000002
2018-01-08 07:41:48,173 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515363269510_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:37910, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-08 07:41:48,173 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515363269510_0001_000001 container=container_1515363269510_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@462e5d3d clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 07:41:48,174 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-08 07:41:48,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-08 07:41:48,285 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:37910 for container : container_1515363269510_0001_01_000002
2018-01-08 07:41:48,288 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 07:41:48,420 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-08 07:41:48,420 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515363269510_0001	CONTAINERID=container_1515363269510_0001_01_000003
2018-01-08 07:41:48,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515363269510_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:36273, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-08 07:41:48,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515363269510_0001_000001 container=container_1515363269510_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@462e5d3d clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 07:41:48,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-08 07:41:48,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-08 07:41:49,173 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:36273 for container : container_1515363269510_0001_01_000003
2018-01-08 07:41:49,231 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 07:41:49,353 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-08 07:41:49,353 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515363269510_0001	CONTAINERID=container_1515363269510_0001_01_000004
2018-01-08 07:41:49,353 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515363269510_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:36273, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-08 07:41:49,353 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515363269510_0001_000001 container=container_1515363269510_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@462e5d3d clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 07:41:49,353 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-08 07:41:49,353 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-08 07:41:50,082 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 07:41:50,336 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 07:41:52,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515363269510_0001
2018-01-08 07:41:52,341 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 07:41:56,082 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515363269510_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-08 07:41:56,082 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515363269510_0001	CONTAINERID=container_1515363269510_0001_01_000004
2018-01-08 07:41:56,144 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515363269510_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:36273, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-08 07:45:49,846 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-08 07:45:49,858 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-08 07:45:49,861 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-08 07:45:49,963 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-08 07:45:49,970 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-08 07:45:49,971 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-08 07:45:49,978 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 07:45:49,979 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-08 07:45:49,979 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-08 07:45:49,980 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-08 07:45:49,981 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-08 07:45:49,981 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 07:45:49,995 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 07:45:49,995 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-08 07:45:50,000 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-08 07:45:50,003 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-08 07:45:50,003 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-08 07:45:50,004 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-08 07:45:50,004 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 07:45:50,034 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-08 07:45:50,036 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-08 07:45:50,038 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-08 07:45:50,040 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-08 07:45:50,040 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-08 07:45:50,040 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-08 07:45:50,044 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-08 07:45:50,044 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-08 07:45:50,046 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-08 07:45:50,047 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-08 07:45:50,048 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-08 10:13:39,792 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-08 10:13:39,807 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-08 10:13:40,382 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-08 10:13:40,652 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-08 10:13:40,867 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-08 10:13:41,470 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-08 10:13:42,338 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-08 10:13:42,355 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-08 10:13:42,404 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-08 10:13:42,576 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-08 10:13:42,619 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-08 10:13:42,620 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-08 10:13:42,773 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-08 10:13:42,776 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-08 10:13:42,778 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-08 10:13:42,780 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-08 10:13:43,040 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-08 10:13:43,293 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-08 10:13:43,293 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-08 10:13:43,364 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-08 10:13:43,415 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-08 10:13:43,418 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-08 10:13:43,453 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-08 10:13:43,457 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-08 10:13:43,556 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-08 10:13:44,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-08 10:13:44,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-08 10:13:44,062 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-08 10:13:44,062 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-08 10:13:44,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-08 10:13:44,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-08 10:13:44,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-08 10:13:44,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-08 10:13:44,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-08 10:13:44,151 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-08 10:13:44,151 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-08 10:13:44,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-08 10:13:44,160 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-08 10:13:44,195 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-08 10:13:44,195 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-08 10:13:44,218 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-08 10:13:44,373 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-08 10:13:44,374 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-08 10:13:44,374 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-08 10:13:44,375 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 10:13:44,376 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-08 10:13:44,376 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-08 10:13:44,404 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-08 10:13:44,404 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 10:13:44,404 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-08 10:13:44,405 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-08 10:13:44,450 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-08 10:13:44,552 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 10:13:44,619 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-08 10:13:45,219 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-08 10:13:45,225 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 10:13:45,231 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-08 10:13:45,748 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 10:13:45,773 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-08 10:13:45,859 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-08 10:13:45,861 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 10:13:45,866 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-08 10:13:46,735 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 10:13:46,739 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-08 10:13:46,836 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-08 10:13:46,847 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 10:13:46,851 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-08 10:13:47,059 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-08 10:13:47,442 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-08 10:13:47,473 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-08 10:13:47,487 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-08 10:13:47,532 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-08 10:13:47,537 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-08 10:13:47,538 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-08 10:13:47,538 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-08 10:13:47,539 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-08 10:13:47,539 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-08 10:13:47,539 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-08 10:13:47,544 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-08 10:13:47,545 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-08 10:13:48,850 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-08 10:13:48,855 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-08 10:13:48,855 INFO org.mortbay.log: jetty-6.1.26
2018-01-08 10:13:49,055 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-08 10:13:49,809 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 10:13:49,825 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-08 10:13:49,828 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-08 10:13:55,757 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-08 10:13:55,758 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-08 10:13:55,970 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-08 10:13:55,975 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-08 10:13:55,999 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-08 10:13:56,017 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-08 10:13:56,021 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-08 10:13:59,760 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 42554 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:42554
2018-01-08 10:13:59,761 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 41781 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:41781
2018-01-08 10:13:59,776 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:41781 Node Transitioned from NEW to RUNNING
2018-01-08 10:13:59,776 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:42554 Node Transitioned from NEW to RUNNING
2018-01-08 10:13:59,800 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:41781 clusterResource: <memory:8192, vCores:8>
2018-01-08 10:13:59,809 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:42554 clusterResource: <memory:16384, vCores:16>
2018-01-08 10:24:24,117 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-08 10:42:23,569 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-08 10:42:40,132 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515374024197_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-08 10:42:40,132 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515374024197_0001 for the user: hadoop
2018-01-08 10:42:40,155 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-08 10:42:40,168 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-08 10:42:40,169 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515374024197_0001
2018-01-08 10:42:40,174 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515374024197_0001
2018-01-08 10:42:40,183 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from NEW to NEW_SAVING on event=START
2018-01-08 10:42:40,183 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515374024197_0001
2018-01-08 10:42:40,184 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-08 10:42:40,189 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515374024197_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-08 10:42:40,190 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515374024197_0001 from user: hadoop, in queue: default
2018-01-08 10:42:40,211 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-08 10:42:40,260 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515374024197_0001_000001
2018-01-08 10:42:40,262 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from NEW to SUBMITTED
2018-01-08 10:42:40,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515374024197_0001 from user: hadoop activated in queue: default
2018-01-08 10:42:40,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515374024197_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-08 10:42:40,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515374024197_0001_000001 to scheduler from user hadoop in queue default
2018-01-08 10:42:40,316 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-08 10:42:40,541 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:42:40,542 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000001
2018-01-08 10:42:40,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:42554, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-08 10:42:40,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0001_000001 container=container_1515374024197_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3e8c9b75 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:42:40,575 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:42554 for container : container_1515374024197_0001_01_000001
2018-01-08 10:42:40,599 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:42:40,603 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515374024197_0001_000001
2018-01-08 10:42:40,604 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515374024197_0001 AttemptId: appattempt_1515374024197_0001_000001 MasterContainer: Container: [ContainerId: container_1515374024197_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:42554, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:42554 }, ]
2018-01-08 10:42:40,612 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-08 10:42:40,614 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-08 10:42:40,631 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-08 10:42:40,644 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-08 10:42:40,649 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515374024197_0001_000001
2018-01-08 10:42:40,733 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515374024197_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:42554, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:42554 }, ] for AM appattempt_1515374024197_0001_000001
2018-01-08 10:42:40,733 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515374024197_0001_000001
2018-01-08 10:42:40,738 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515374024197_0001_000001
2018-01-08 10:42:41,463 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515374024197_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:42554, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:42554 }, ] for AM appattempt_1515374024197_0001_000001
2018-01-08 10:42:41,463 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-08 10:42:41,630 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 10:42:54,945 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515374024197_0001_000001 (auth:SIMPLE)
2018-01-08 10:42:54,964 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515374024197_0001_000001
2018-01-08 10:42:54,965 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515374024197_0001	APPATTEMPTID=appattempt_1515374024197_0001_000001
2018-01-08 10:42:54,966 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from LAUNCHED to RUNNING
2018-01-08 10:42:54,966 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-08 10:42:55,872 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:42:55,873 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000002
2018-01-08 10:42:55,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41781, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-08 10:42:55,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0001_000001 container=container_1515374024197_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3e8c9b75 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:42:55,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-08 10:42:55,876 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-08 10:42:55,910 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:41781 for container : container_1515374024197_0001_01_000002
2018-01-08 10:42:55,918 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:42:56,228 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:42:56,228 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000003
2018-01-08 10:42:56,228 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:42554, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-08 10:42:56,228 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0001_000001 container=container_1515374024197_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3e8c9b75 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:42:56,228 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-08 10:42:56,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-08 10:42:56,913 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:42554 for container : container_1515374024197_0001_01_000003
2018-01-08 10:42:56,919 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:42:57,438 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 10:42:57,445 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:42:57,445 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000004
2018-01-08 10:42:57,445 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:42554, which has 3 containers, <memory:5120, vCores:3> used and <memory:3072, vCores:5> available after allocation
2018-01-08 10:42:57,445 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0001_000001 container=container_1515374024197_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@3e8c9b75 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:42:57,445 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-08 10:42:57,445 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-08 10:42:58,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 10:43:00,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515374024197_0001
2018-01-08 10:43:00,231 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:43:03,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-08 10:43:03,585 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000004
2018-01-08 10:43:03,586 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:42554, which currently has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available, release resources=true
2018-01-08 10:43:14,757 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1859ms
No GCs detected
2018-01-08 10:52:33,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515374024197_0001_000001 with final state: FINISHING, and exit status: -1000
2018-01-08 10:52:33,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-08 10:52:33,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515374024197_0001 with final state: FINISHING
2018-01-08 10:52:33,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-08 10:52:33,304 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515374024197_0001
2018-01-08 10:52:33,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from FINAL_SAVING to FINISHING
2018-01-08 10:52:33,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-08 10:52:33,412 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515374024197_0001 unregistered successfully. 
2018-01-08 10:52:33,743 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-08 10:52:33,743 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000002
2018-01-08 10:52:33,743 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41781, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-08 10:52:33,922 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-08 10:52:33,923 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000001
2018-01-08 10:52:33,923 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:42554, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-08 10:52:33,924 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515374024197_0001_000001
2018-01-08 10:52:33,925 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515374024197_0001_000001
2018-01-08 10:52:33,926 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0001_000001 State change from FINISHING to FINISHED
2018-01-08 10:52:33,932 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-08 10:52:33,934 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515374024197_0001_000001 is done. finalState=FINISHED
2018-01-08 10:52:33,934 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0001_01_000003 Container Transitioned from RUNNING to KILLED
2018-01-08 10:52:33,935 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0001	CONTAINERID=container_1515374024197_0001_01_000003
2018-01-08 10:52:33,938 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515374024197_0001_000001
2018-01-08 10:52:33,946 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515374024197_0001
2018-01-08 10:52:33,945 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515374024197_0001 requests cleared
2018-01-08 10:52:33,959 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515374024197_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-08 10:52:33,959 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515374024197_0001 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-08 10:52:34,000 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515374024197_0001,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515374024197_0001/,appMasterHost=192.168.28.131,startTime=1515375760155,finishTime=1515376353303,finalStatus=SUCCEEDED,memorySeconds=2986818,vcoreSeconds=1753,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-08 10:52:34,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Container container_1515374024197_0001_01_000003 already scheduled for cleanup, no further processing
2018-01-08 10:52:34,001 WARN org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Container container_1515374024197_0001_01_000003 was running but not reported from hadoop-worker01.local:42554
2018-01-08 10:52:34,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515374024197_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-08 10:52:34,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:42554, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-08 10:52:34,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515374024197_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-08 10:52:35,754 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515374024197_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-08 10:58:00,321 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2018-01-08 10:58:12,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515374024197_0002' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-08 10:58:12,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515374024197_0002 for the user: hadoop
2018-01-08 10:58:12,954 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-08 10:58:12,955 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user hadoop
2018-01-08 10:58:12,955 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515374024197_0002
2018-01-08 10:58:12,955 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515374024197_0002
2018-01-08 10:58:12,955 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from NEW to NEW_SAVING on event=START
2018-01-08 10:58:12,955 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515374024197_0002
2018-01-08 10:58:12,956 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-08 10:58:12,956 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515374024197_0002 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-08 10:58:12,956 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515374024197_0002 from user: hadoop, in queue: default
2018-01-08 10:58:12,961 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-08 10:58:12,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515374024197_0002_000001
2018-01-08 10:58:12,962 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from NEW to SUBMITTED
2018-01-08 10:58:12,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515374024197_0002 from user: hadoop activated in queue: default
2018-01-08 10:58:12,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515374024197_0002 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-08 10:58:12,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515374024197_0002_000001 to scheduler from user hadoop in queue default
2018-01-08 10:58:12,964 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from SUBMITTED to SCHEDULED
2018-01-08 10:58:13,056 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:58:13,056 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000001
2018-01-08 10:58:13,056 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:42554, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-08 10:58:13,056 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0002_000001 container=container_1515374024197_0002_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@614b37c1 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:58:13,057 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0625, absoluteUsedCapacity=0.0625, numApps=1, numContainers=1
2018-01-08 10:58:13,059 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0625 absoluteUsedCapacity=0.0625 used=<memory:1024, vCores:1> cluster=<memory:16384, vCores:16>
2018-01-08 10:58:13,059 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:42554 for container : container_1515374024197_0002_01_000001
2018-01-08 10:58:13,062 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:58:13,062 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515374024197_0002_000001
2018-01-08 10:58:13,062 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515374024197_0002 AttemptId: appattempt_1515374024197_0002_000001 MasterContainer: Container: [ContainerId: container_1515374024197_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:42554, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:42554 }, ]
2018-01-08 10:58:13,062 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-08 10:58:13,063 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-08 10:58:13,065 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515374024197_0002_000001
2018-01-08 10:58:13,069 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515374024197_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:42554, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:42554 }, ] for AM appattempt_1515374024197_0002_000001
2018-01-08 10:58:13,070 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515374024197_0002_000001
2018-01-08 10:58:13,070 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515374024197_0002_000001
2018-01-08 10:58:13,093 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515374024197_0002_01_000001, Version: 0, NodeId: hadoop-worker01.local:42554, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:42554 }, ] for AM appattempt_1515374024197_0002_000001
2018-01-08 10:58:13,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from ALLOCATED to LAUNCHED
2018-01-08 10:58:14,088 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 10:58:22,071 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515374024197_0002_000001 (auth:SIMPLE)
2018-01-08 10:58:22,095 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515374024197_0002_000001
2018-01-08 10:58:22,096 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515374024197_0002	APPATTEMPTID=appattempt_1515374024197_0002_000001
2018-01-08 10:58:22,097 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from LAUNCHED to RUNNING
2018-01-08 10:58:22,097 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-08 10:58:22,624 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:58:22,625 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000002
2018-01-08 10:58:22,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41781, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-08 10:58:22,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0002_000001 container=container_1515374024197_0002_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@614b37c1 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:58:22,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.1875, absoluteUsedCapacity=0.1875, numApps=1, numContainers=2
2018-01-08 10:58:22,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.1875 absoluteUsedCapacity=0.1875 used=<memory:3072, vCores:2> cluster=<memory:16384, vCores:16>
2018-01-08 10:58:22,754 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:41781 for container : container_1515374024197_0002_01_000002
2018-01-08 10:58:22,761 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:58:23,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:58:23,252 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000003
2018-01-08 10:58:23,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:42554, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-08 10:58:23,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0002_000001 container=container_1515374024197_0002_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@614b37c1 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:58:23,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.3125, absoluteUsedCapacity=0.3125, numApps=1, numContainers=3
2018-01-08 10:58:23,252 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.3125 absoluteUsedCapacity=0.3125 used=<memory:5120, vCores:3> cluster=<memory:16384, vCores:16>
2018-01-08 10:58:23,323 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:42554 for container : container_1515374024197_0002_01_000003
2018-01-08 10:58:23,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:58:23,745 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 10:58:23,908 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-08 10:58:23,908 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000004
2018-01-08 10:58:23,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515374024197_0002_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41781, which has 2 containers, <memory:4096, vCores:2> used and <memory:4096, vCores:6> available after allocation
2018-01-08 10:58:23,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515374024197_0002_000001 container=container_1515374024197_0002_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@614b37c1 clusterResource=<memory:16384, vCores:16> type=OFF_SWITCH requestedPartition=
2018-01-08 10:58:23,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.4375, absoluteUsedCapacity=0.4375, numApps=1, numContainers=4
2018-01-08 10:58:23,909 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.4375 absoluteUsedCapacity=0.4375 used=<memory:7168, vCores:4> cluster=<memory:16384, vCores:16>
2018-01-08 10:58:24,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-08 10:58:26,591 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515374024197_0002
2018-01-08 10:58:26,754 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-08 10:58:29,899 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-08 10:58:29,899 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000004
2018-01-08 10:58:29,900 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0002_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41781, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-08 11:12:18,703 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515374024197_0002_000001 with final state: FINISHING, and exit status: -1000
2018-01-08 11:12:18,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from RUNNING to FINAL_SAVING
2018-01-08 11:12:18,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515374024197_0002 with final state: FINISHING
2018-01-08 11:12:18,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-08 11:12:18,705 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515374024197_0002
2018-01-08 11:12:18,705 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from FINAL_SAVING to FINISHING
2018-01-08 11:12:18,705 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-08 11:12:18,824 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515374024197_0002 unregistered successfully. 
2018-01-08 11:12:18,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-08 11:12:18,951 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000002
2018-01-08 11:12:18,952 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:41781, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-08 11:12:19,073 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-08 11:12:19,073 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000003
2018-01-08 11:12:19,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:42554, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-08 11:12:19,323 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515374024197_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-08 11:12:19,323 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515374024197_0002	CONTAINERID=container_1515374024197_0002_01_000001
2018-01-08 11:12:19,323 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515374024197_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:42554, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-08 11:12:19,323 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515374024197_0002_000001
2018-01-08 11:12:19,324 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515374024197_0002_000001
2018-01-08 11:12:19,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515374024197_0002_000001 State change from FINISHING to FINISHED
2018-01-08 11:12:19,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515374024197_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-08 11:12:19,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515374024197_0002_000001 is done. finalState=FINISHED
2018-01-08 11:12:19,324 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515374024197_0002
2018-01-08 11:12:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515374024197_0002 requests cleared
2018-01-08 11:12:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515374024197_0002 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-08 11:12:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515374024197_0002 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-08 11:12:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515374024197_0002_000001
2018-01-08 11:12:19,327 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515374024197_0002,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515374024197_0002/,appMasterHost=192.168.28.131,startTime=1515376692954,finishTime=1515377538704,finalStatus=SUCCEEDED,memorySeconds=4303406,vcoreSeconds=2522,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-08 11:12:21,178 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515374024197_0002_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-08 11:12:21,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515374024197_0002_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-08 11:13:27,108 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-08 11:13:27,124 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-08 11:13:27,127 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-08 11:13:27,230 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-08 11:13:27,238 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-08 11:13:27,238 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 11:13:27,239 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-08 11:13:27,249 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-08 11:13:27,250 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 11:13:27,251 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-08 11:13:27,254 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-08 11:13:27,255 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-08 11:13:27,277 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-08 11:13:27,277 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 11:13:27,279 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-08 11:13:27,341 INFO org.apache.hadoop.ipc.Server: Socket Reader #1 for port 8031: readAndProcess from client 192.168.28.132:44470 threw exception [java.nio.channels.ClosedByInterruptException]
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:407)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3065)
	at org.apache.hadoop.ipc.Server.access$2500(Server.java:136)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1864)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1128)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:984)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:955)
2018-01-08 11:13:27,351 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-08 11:13:27,352 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-08 11:13:27,352 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-08 11:13:27,352 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-08 11:13:27,354 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-08 11:13:27,354 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-08 11:13:27,355 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-08 11:13:27,375 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-08 11:13:27,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-08 11:13:27,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-08 11:13:27,376 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-08 11:13:27,355 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-08 11:13:27,354 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-08 11:13:27,381 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-08 11:13:27,383 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-11 11:43:07,262 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-11 11:43:07,275 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-11 11:43:07,773 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-11 11:43:08,102 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-11 11:43:08,408 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-11 11:43:09,065 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-11 11:43:10,056 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-11 11:43:10,111 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-11 11:43:10,137 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-11 11:43:10,357 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-11 11:43:10,421 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-11 11:43:10,421 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-11 11:43:10,511 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-11 11:43:10,513 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-11 11:43:10,515 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-11 11:43:10,516 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-11 11:43:10,690 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-11 11:43:10,946 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-11 11:43:10,946 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-11 11:43:11,135 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-11 11:43:11,207 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-11 11:43:11,223 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-11 11:43:11,253 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-11 11:43:11,256 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-11 11:43:11,441 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-11 11:43:11,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-11 11:43:11,881 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-11 11:43:11,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-11 11:43:11,899 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-11 11:43:11,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-11 11:43:11,920 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-11 11:43:11,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-11 11:43:11,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 11:43:11,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 11:43:11,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 11:43:11,955 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-11 11:43:11,956 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-11 11:43:11,962 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-11 11:43:11,987 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-11 11:43:11,988 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-11 11:43:12,009 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-11 11:43:12,153 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-11 11:43:12,153 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-11 11:43:12,154 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-11 11:43:12,154 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:43:12,156 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-11 11:43:12,156 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 11:43:12,161 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 11:43:12,162 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:43:12,162 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-11 11:43:12,162 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 11:43:12,171 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-11 11:43:12,278 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:43:12,325 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-11 11:43:12,833 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-11 11:43:12,853 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:43:12,856 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-11 11:43:13,164 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:43:13,175 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-11 11:43:13,246 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-11 11:43:13,252 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:43:13,283 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-11 11:43:15,929 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:43:15,953 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-11 11:43:15,973 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-11 11:43:15,991 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:43:16,024 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-11 11:43:16,550 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-11 11:43:16,812 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-11 11:43:16,910 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-11 11:43:16,949 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-11 11:43:17,018 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-11 11:43:17,023 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-11 11:43:17,023 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-11 11:43:17,023 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-11 11:43:17,024 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-11 11:43:17,024 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-11 11:43:17,024 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-11 11:43:17,029 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-11 11:43:17,030 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-11 11:43:18,653 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-11 11:43:18,657 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-11 11:43:18,658 INFO org.mortbay.log: jetty-6.1.26
2018-01-11 11:43:18,757 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-11 11:43:20,070 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:43:20,077 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 11:43:20,092 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:43:28,331 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 11:43:28,331 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-11 11:43:28,424 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:43:28,431 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-11 11:43:28,501 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-11 11:43:28,522 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:43:28,596 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-11 11:43:35,316 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 43017 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:43017
2018-01-11 11:43:35,317 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 36822 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:36822
2018-01-11 11:43:35,326 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 45986 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:45986
2018-01-11 11:43:35,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:43017 Node Transitioned from NEW to RUNNING
2018-01-11 11:43:35,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:45986 Node Transitioned from NEW to RUNNING
2018-01-11 11:43:35,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:36822 Node Transitioned from NEW to RUNNING
2018-01-11 11:43:35,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:43017 clusterResource: <memory:8192, vCores:8>
2018-01-11 11:43:35,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:45986 clusterResource: <memory:16384, vCores:16>
2018-01-11 11:43:35,365 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:36822 clusterResource: <memory:24576, vCores:24>
2018-01-11 11:44:35,911 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-11 11:44:35,924 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 11:44:35,928 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 11:44:36,036 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-11 11:44:36,053 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-11 11:44:36,053 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 11:44:36,071 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-11 11:44:36,073 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 11:44:36,075 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-11 11:44:36,073 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-11 11:44:36,079 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-11 11:44:36,083 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-11 11:44:36,093 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-11 11:44:36,094 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 11:44:36,094 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-11 11:44:36,110 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 11:44:36,111 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-11 11:44:36,111 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-11 11:44:36,111 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-11 11:44:36,111 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 11:44:36,113 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 11:44:36,113 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 11:44:36,113 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-11 11:44:36,113 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 11:44:36,114 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-11 11:44:36,118 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-11 11:44:36,118 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-11 11:44:36,118 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 11:44:36,118 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-11 11:44:36,119 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-11 11:50:36,122 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-11 11:50:36,139 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-11 11:50:36,653 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-11 11:50:36,831 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-11 11:50:37,030 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-11 11:50:37,662 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-11 11:50:38,554 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-11 11:50:38,560 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-11 11:50:38,569 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-11 11:50:38,693 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-11 11:50:38,698 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-11 11:50:38,698 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-11 11:50:38,847 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-11 11:50:38,848 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-11 11:50:38,850 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-11 11:50:38,852 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-11 11:50:39,001 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-11 11:50:39,248 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-11 11:50:39,248 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-11 11:50:39,273 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-11 11:50:39,376 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-11 11:50:39,380 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-11 11:50:39,408 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-11 11:50:39,418 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-11 11:50:39,507 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-11 11:50:39,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-11 11:50:39,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-11 11:50:39,851 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-11 11:50:39,851 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-11 11:50:39,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-11 11:50:39,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-11 11:50:39,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-11 11:50:39,870 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 11:50:39,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 11:50:39,968 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 11:50:39,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-11 11:50:39,970 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-11 11:50:39,977 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-11 11:50:39,995 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-11 11:50:39,996 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-11 11:50:40,060 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-11 11:50:40,151 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-11 11:50:40,151 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-11 11:50:40,151 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-11 11:50:40,152 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:50:40,301 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-11 11:50:40,301 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 11:50:40,351 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 11:50:40,352 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:50:40,352 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-11 11:50:40,352 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 11:50:40,375 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-11 11:50:40,577 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:50:40,626 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-11 11:50:41,252 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-11 11:50:41,273 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:50:41,294 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-11 11:50:42,252 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:50:42,311 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-11 11:50:42,398 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-11 11:50:42,411 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:50:42,420 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-11 11:50:43,369 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:50:43,381 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-11 11:50:43,416 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-11 11:50:43,417 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:50:43,464 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-11 11:50:43,747 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-11 11:50:44,069 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-11 11:50:44,191 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-11 11:50:44,203 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-11 11:50:44,259 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-11 11:50:44,265 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-11 11:50:44,266 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-11 11:50:44,266 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-11 11:50:44,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-11 11:50:44,267 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-11 11:50:44,267 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-11 11:50:44,277 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-11 11:50:44,277 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-11 11:50:46,121 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-11 11:50:46,124 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-11 11:50:46,124 INFO org.mortbay.log: jetty-6.1.26
2018-01-11 11:50:46,226 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-11 11:50:47,331 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:50:47,332 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 11:50:47,333 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 11:50:52,495 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 11:50:52,495 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-11 11:50:53,544 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 11:50:53,553 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-11 11:50:53,567 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-11 11:50:53,574 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 11:50:53,582 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-11 11:50:58,321 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 42747 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:42747
2018-01-11 11:50:58,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:42747 Node Transitioned from NEW to RUNNING
2018-01-11 11:50:58,334 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 41691 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:41691
2018-01-11 11:50:58,365 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:41691 Node Transitioned from NEW to RUNNING
2018-01-11 11:50:58,451 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:42747 clusterResource: <memory:8192, vCores:8>
2018-01-11 11:50:58,452 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:41691 clusterResource: <memory:16384, vCores:16>
2018-01-11 11:50:58,452 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 35213 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:35213
2018-01-11 11:50:58,453 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:35213 Node Transitioned from NEW to RUNNING
2018-01-11 11:50:58,454 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:35213 clusterResource: <memory:24576, vCores:24>
2018-01-11 12:01:06,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-11 12:43:38,466 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-11 12:43:38,483 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 12:43:38,487 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 12:43:38,590 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-11 12:43:38,608 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-11 12:43:38,618 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-11 12:43:38,620 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 12:43:38,627 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-11 12:43:38,628 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-11 12:43:38,630 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 12:43:38,630 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-11 12:43:38,630 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-11 12:43:38,638 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-11 12:43:38,638 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 12:43:38,637 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-11 12:43:38,650 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-11 12:43:38,653 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 12:43:38,654 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-11 12:43:38,657 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 12:43:38,657 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-11 12:43:38,657 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 12:43:38,657 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 12:43:38,660 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-11 12:43:38,660 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 12:43:38,667 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-11 12:43:38,671 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-11 12:43:38,681 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-11 12:43:38,681 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 12:43:38,682 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-11 12:43:38,683 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-11 16:22:53,096 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-11 16:22:53,115 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-11 16:22:54,253 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-11 16:22:54,512 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-11 16:22:54,741 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-11 16:22:55,548 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-11 16:22:57,117 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-11 16:22:57,125 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-11 16:22:57,135 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-11 16:22:57,359 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-11 16:22:57,391 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-11 16:22:57,391 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-11 16:22:57,529 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-11 16:22:57,533 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-11 16:22:57,543 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-11 16:22:57,545 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-11 16:22:57,935 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-11 16:22:58,234 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-11 16:22:58,234 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-11 16:22:58,262 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-11 16:22:58,338 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-11 16:22:58,342 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-11 16:22:58,402 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-11 16:22:58,406 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-11 16:22:58,553 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-11 16:22:58,989 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-11 16:22:58,989 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-11 16:22:59,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-11 16:22:59,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-11 16:22:59,084 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-11 16:22:59,084 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-11 16:22:59,089 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-11 16:22:59,089 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 16:22:59,090 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 16:22:59,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 16:22:59,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-11 16:22:59,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-11 16:22:59,214 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-11 16:22:59,232 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-11 16:22:59,232 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-11 16:22:59,262 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-11 16:22:59,339 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-11 16:22:59,340 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-11 16:22:59,340 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-11 16:22:59,340 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 16:22:59,421 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-11 16:22:59,421 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 16:22:59,471 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-11 16:22:59,456 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 16:22:59,694 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 16:22:59,732 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-11 16:22:59,789 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 16:22:59,809 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 16:22:59,852 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-11 16:23:00,714 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-11 16:23:00,727 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 16:23:00,732 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-11 16:23:00,929 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 16:23:00,976 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-11 16:23:01,083 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-11 16:23:01,094 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 16:23:01,107 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-11 16:23:02,106 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 16:23:02,121 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-11 16:23:02,323 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-11 16:23:02,336 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 16:23:02,377 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-11 16:23:03,500 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-11 16:23:03,949 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-11 16:23:04,034 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-11 16:23:04,051 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-11 16:23:04,176 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-11 16:23:04,201 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-11 16:23:04,218 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-11 16:23:04,218 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-11 16:23:04,219 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-11 16:23:04,219 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-11 16:23:04,220 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-11 16:23:04,226 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-11 16:23:04,227 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-11 16:23:05,892 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-11 16:23:05,931 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-11 16:23:05,931 INFO org.mortbay.log: jetty-6.1.26
2018-01-11 16:23:06,050 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-11 16:23:06,662 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 16:23:06,689 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 16:23:06,700 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 16:23:14,088 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 16:23:14,089 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-11 16:23:15,269 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 16:23:15,276 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-11 16:23:15,310 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-11 16:23:15,312 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 16:23:15,381 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-11 16:23:19,314 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 44632 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:44632
2018-01-11 16:23:20,547 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:44632 Node Transitioned from NEW to RUNNING
2018-01-11 16:23:20,571 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 44050 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:44050
2018-01-11 16:23:20,572 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:44050 Node Transitioned from NEW to RUNNING
2018-01-11 16:23:20,584 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:46330 Node Transitioned from NEW to RUNNING
2018-01-11 16:23:20,584 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 46330 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:46330
2018-01-11 16:23:20,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:44632 clusterResource: <memory:8192, vCores:8>
2018-01-11 16:23:20,599 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:44050 clusterResource: <memory:16384, vCores:16>
2018-01-11 16:23:20,600 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:46330 clusterResource: <memory:24576, vCores:24>
2018-01-11 16:28:23,752 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-11 16:28:23,777 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 16:28:23,782 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 16:28:23,787 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-11 16:28:23,801 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-11 16:28:23,805 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 16:28:23,809 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-11 16:28:23,812 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-11 16:28:23,813 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-11 16:28:23,813 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 16:28:23,814 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-11 16:28:23,815 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-11 16:28:23,821 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-11 16:28:23,821 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-11 16:28:23,822 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 16:28:23,829 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 16:28:23,829 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-11 16:28:23,828 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-11 16:28:23,830 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-11 16:28:23,831 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 16:28:23,832 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 16:28:23,832 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 16:28:23,857 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-11 16:28:23,858 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 16:28:23,858 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-11 16:28:23,884 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-11 16:28:23,885 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-11 16:28:23,886 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 16:28:23,886 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-11 16:28:23,888 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-11 17:22:24,013 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-11 17:22:24,029 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-11 17:22:24,494 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-11 17:22:24,675 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-11 17:22:24,949 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-11 17:22:25,603 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-11 17:22:26,550 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-11 17:22:26,574 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-11 17:22:26,600 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-11 17:22:26,865 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-11 17:22:26,872 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-11 17:22:26,872 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-11 17:22:26,954 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-11 17:22:26,957 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-11 17:22:26,960 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-11 17:22:26,962 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-11 17:22:27,163 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-11 17:22:27,559 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-11 17:22:27,560 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-11 17:22:27,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-11 17:22:27,707 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-11 17:22:27,713 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-11 17:22:27,760 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-11 17:22:27,764 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-11 17:22:27,798 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-11 17:22:28,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-11 17:22:28,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-11 17:22:28,408 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-11 17:22:28,409 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-11 17:22:28,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-11 17:22:28,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-11 17:22:28,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-11 17:22:28,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 17:22:28,440 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 17:22:28,447 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 17:22:28,447 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-11 17:22:28,449 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-11 17:22:28,455 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-11 17:22:28,475 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-11 17:22:28,476 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-11 17:22:28,533 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-11 17:22:28,669 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-11 17:22:28,669 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-11 17:22:28,670 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-11 17:22:28,670 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:22:28,672 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-11 17:22:28,672 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 17:22:28,720 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 17:22:28,720 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:22:28,720 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-11 17:22:28,720 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 17:22:28,763 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-11 17:22:29,066 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:22:29,143 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-11 17:22:30,235 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-11 17:22:30,276 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:22:30,289 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-11 17:22:30,521 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:22:30,535 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-11 17:22:30,592 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-11 17:22:30,624 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:22:30,665 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-11 17:22:32,086 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:22:32,098 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-11 17:22:32,240 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-11 17:22:32,279 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:22:32,320 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-11 17:22:32,628 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-11 17:22:33,083 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-11 17:22:33,171 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-11 17:22:33,221 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-11 17:22:33,351 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-11 17:22:33,360 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-11 17:22:33,360 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-11 17:22:33,361 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-11 17:22:33,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-11 17:22:33,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-11 17:22:33,362 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-11 17:22:33,370 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-11 17:22:33,371 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-11 17:22:35,296 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-11 17:22:35,311 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-11 17:22:35,311 INFO org.mortbay.log: jetty-6.1.26
2018-01-11 17:22:35,426 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-11 17:22:36,328 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:22:36,332 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 17:22:36,339 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:22:40,762 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 17:22:40,762 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-11 17:22:40,997 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:22:41,049 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-11 17:22:41,115 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-11 17:22:41,131 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:22:41,167 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-11 17:22:49,091 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 41160 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:41160
2018-01-11 17:22:49,092 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 37686 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:37686
2018-01-11 17:22:49,098 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 33713 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:33713
2018-01-11 17:22:49,105 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:41160 Node Transitioned from NEW to RUNNING
2018-01-11 17:22:49,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:37686 Node Transitioned from NEW to RUNNING
2018-01-11 17:22:49,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:33713 Node Transitioned from NEW to RUNNING
2018-01-11 17:22:49,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:41160 clusterResource: <memory:8192, vCores:8>
2018-01-11 17:22:49,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:37686 clusterResource: <memory:16384, vCores:16>
2018-01-11 17:22:49,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:33713 clusterResource: <memory:24576, vCores:24>
2018-01-11 17:29:00,168 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-11 17:29:00,182 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 17:29:00,184 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 17:29:00,288 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-11 17:29:00,306 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-11 17:29:00,311 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-11 17:29:00,324 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:29:00,329 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-11 17:29:00,329 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:29:00,330 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-11 17:29:00,332 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-11 17:29:00,333 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-11 17:29:00,349 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-11 17:29:00,354 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-11 17:29:00,357 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:29:00,357 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-11 17:29:00,358 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-11 17:29:00,358 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-11 17:29:00,362 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:29:00,364 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 17:29:00,368 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 17:29:00,370 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 17:29:00,370 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-11 17:29:00,371 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 17:29:00,372 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-11 17:29:00,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-11 17:29:00,376 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-11 17:29:00,376 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 17:29:00,379 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-11 17:29:00,380 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-11 17:35:07,447 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-11 17:35:07,462 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-11 17:35:07,875 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-11 17:35:07,983 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-11 17:35:08,087 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-11 17:35:08,812 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-11 17:35:09,630 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-11 17:35:09,669 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-11 17:35:09,680 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-11 17:35:09,847 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-11 17:35:09,853 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-11 17:35:09,853 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-11 17:35:09,897 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-11 17:35:09,898 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-11 17:35:09,899 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-11 17:35:09,900 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-11 17:35:10,045 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-11 17:35:10,267 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-11 17:35:10,267 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-11 17:35:10,319 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-11 17:35:10,504 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-11 17:35:10,522 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-11 17:35:10,534 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-11 17:35:10,537 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-11 17:35:10,565 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-11 17:35:10,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-11 17:35:10,816 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-11 17:35:10,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-11 17:35:10,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-11 17:35:10,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-11 17:35:10,858 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-11 17:35:10,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-11 17:35:10,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 17:35:10,863 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 17:35:10,901 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 17:35:10,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-11 17:35:10,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-11 17:35:10,909 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-11 17:35:10,929 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-11 17:35:10,929 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-11 17:35:10,957 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-11 17:35:10,987 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-11 17:35:10,988 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-11 17:35:10,988 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-11 17:35:10,988 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:35:10,989 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-11 17:35:10,989 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 17:35:10,996 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 17:35:10,997 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:35:10,997 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-11 17:35:10,997 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 17:35:11,006 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-11 17:35:11,176 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:35:11,208 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-11 17:35:11,838 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-11 17:35:11,848 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:35:12,009 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-11 17:35:12,356 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:35:12,382 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-11 17:35:12,510 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-11 17:35:12,526 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:35:12,528 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-11 17:35:13,191 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:35:13,235 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-11 17:35:13,248 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-11 17:35:13,269 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:35:13,277 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-11 17:35:14,230 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-11 17:35:14,545 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-11 17:35:14,574 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-11 17:35:14,596 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-11 17:35:14,623 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-11 17:35:14,628 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-11 17:35:14,628 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-11 17:35:14,628 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-11 17:35:14,629 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-11 17:35:14,629 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-11 17:35:14,630 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-11 17:35:14,636 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-11 17:35:14,636 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-11 17:35:15,885 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-11 17:35:15,888 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-11 17:35:15,889 INFO org.mortbay.log: jetty-6.1.26
2018-01-11 17:35:15,970 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-11 17:35:16,677 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:35:16,678 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 17:35:16,712 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 17:35:26,629 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 17:35:26,629 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-11 17:35:27,108 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 17:35:27,110 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-11 17:35:27,124 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-11 17:35:27,125 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 17:35:27,126 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-11 17:35:31,867 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 45309 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:45309
2018-01-11 17:35:31,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:45309 Node Transitioned from NEW to RUNNING
2018-01-11 17:35:31,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:42134 Node Transitioned from NEW to RUNNING
2018-01-11 17:35:31,875 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 42134 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:42134
2018-01-11 17:35:31,945 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:45309 clusterResource: <memory:8192, vCores:8>
2018-01-11 17:35:31,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:42134 clusterResource: <memory:16384, vCores:16>
2018-01-11 17:35:32,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 39516 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:39516
2018-01-11 17:35:32,961 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:39516 Node Transitioned from NEW to RUNNING
2018-01-11 17:35:32,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:39516 clusterResource: <memory:24576, vCores:24>
2018-01-11 17:37:01,492 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9226ms
No GCs detected
2018-01-11 17:37:12,527 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1021ms
No GCs detected
2018-01-11 17:45:35,771 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-11 17:47:39,558 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-11 17:47:39,569 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 17:47:39,573 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 17:47:39,582 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-11 17:47:39,596 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-11 17:47:39,599 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-11 17:47:39,612 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:47:39,615 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-11 17:47:39,615 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:47:39,616 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-11 17:47:39,617 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-11 17:47:39,617 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-11 17:47:39,622 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-11 17:47:39,622 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-11 17:47:39,625 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:47:39,655 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-11 17:47:39,656 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-11 17:47:39,656 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 17:47:39,659 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 17:47:39,656 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-11 17:47:39,662 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 17:47:39,663 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-11 17:47:39,666 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-11 17:47:39,666 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 17:47:39,669 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 17:47:39,671 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-11 17:47:39,671 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-11 17:47:39,671 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 17:47:39,674 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-11 17:47:39,675 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-11 18:49:34,042 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-11 18:49:34,056 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-11 18:49:34,471 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-11 18:49:34,598 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-11 18:49:34,770 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-11 18:49:35,474 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-11 18:49:36,302 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-11 18:49:36,310 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-11 18:49:36,321 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-11 18:49:36,600 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-11 18:49:36,610 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-11 18:49:36,611 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-11 18:49:36,703 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-11 18:49:36,704 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-11 18:49:36,705 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-11 18:49:36,707 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-11 18:49:36,956 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-11 18:49:37,263 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-11 18:49:37,263 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-11 18:49:37,285 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-11 18:49:37,389 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-11 18:49:37,392 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-11 18:49:37,402 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-11 18:49:37,405 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-11 18:49:37,424 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-11 18:49:37,594 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-11 18:49:37,594 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-11 18:49:37,610 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-11 18:49:37,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-11 18:49:37,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-11 18:49:37,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-11 18:49:37,701 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-11 18:49:37,702 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 18:49:37,702 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 18:49:37,796 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-11 18:49:37,796 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-11 18:49:37,799 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-11 18:49:37,805 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-11 18:49:37,837 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-11 18:49:37,837 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-11 18:49:37,904 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-11 18:49:38,011 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-11 18:49:38,011 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-11 18:49:38,011 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-11 18:49:38,012 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 18:49:38,013 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-11 18:49:38,013 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 18:49:38,044 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 18:49:38,044 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 18:49:38,044 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-11 18:49:38,044 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-11 18:49:38,102 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-11 18:49:38,249 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 18:49:38,290 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-11 18:49:38,856 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-11 18:49:38,868 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 18:49:38,879 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-11 18:49:39,248 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 18:49:39,301 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-11 18:49:39,337 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-11 18:49:39,346 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 18:49:39,508 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-11 18:49:40,009 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 18:49:40,025 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-11 18:49:40,031 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-11 18:49:40,042 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 18:49:40,048 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-11 18:49:40,496 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-11 18:49:40,834 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-11 18:49:40,931 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-11 18:49:40,948 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-11 18:49:41,118 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-11 18:49:41,123 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-11 18:49:41,124 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-11 18:49:41,124 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-11 18:49:41,125 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-11 18:49:41,125 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-11 18:49:41,125 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-11 18:49:41,135 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-11 18:49:41,135 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-11 18:49:42,594 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-11 18:49:42,599 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-11 18:49:42,599 INFO org.mortbay.log: jetty-6.1.26
2018-01-11 18:49:42,841 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-11 18:49:46,880 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 18:49:46,896 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-11 18:49:46,902 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-11 18:49:53,599 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 18:49:53,599 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-11 18:49:53,703 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-11 18:49:53,704 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-11 18:49:53,722 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-11 18:49:53,730 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-11 18:49:53,731 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-11 18:49:57,030 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 41621 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:41621
2018-01-11 18:49:57,037 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:41621 Node Transitioned from NEW to RUNNING
2018-01-11 18:49:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:41621 clusterResource: <memory:8192, vCores:8>
2018-01-11 18:49:58,902 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 39118 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:39118
2018-01-11 18:49:58,918 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:39118 Node Transitioned from NEW to RUNNING
2018-01-11 18:49:58,965 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:39118 clusterResource: <memory:16384, vCores:16>
2018-01-11 18:49:59,833 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 39909 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:39909
2018-01-11 18:49:59,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:39909 Node Transitioned from NEW to RUNNING
2018-01-11 18:49:59,835 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:39909 clusterResource: <memory:24576, vCores:24>
2018-01-11 19:00:00,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-11 19:10:46,330 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1255ms
No GCs detected
2018-01-11 19:11:30,216 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-11 19:11:49,655 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515664177839_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-11 19:11:49,655 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515664177839_0001 for the user: hadoop
2018-01-11 19:11:49,678 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-11 19:11:49,685 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-11 19:11:49,685 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515664177839_0001
2018-01-11 19:11:49,688 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515664177839_0001
2018-01-11 19:11:49,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from NEW to NEW_SAVING on event=START
2018-01-11 19:11:49,699 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515664177839_0001
2018-01-11 19:11:49,700 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-11 19:11:49,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515664177839_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-11 19:11:49,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515664177839_0001 from user: hadoop, in queue: default
2018-01-11 19:11:49,753 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-11 19:11:49,785 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515664177839_0001_000001
2018-01-11 19:11:49,787 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from NEW to SUBMITTED
2018-01-11 19:11:49,821 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515664177839_0001 from user: hadoop activated in queue: default
2018-01-11 19:11:49,821 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515664177839_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-11 19:11:49,821 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515664177839_0001_000001 to scheduler from user hadoop in queue default
2018-01-11 19:11:49,826 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-11 19:11:50,079 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:11:50,079 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000001
2018-01-11 19:11:50,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41621, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-11 19:11:50,081 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0001_000001 container=container_1515664177839_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@43bcfc46 clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:11:50,107 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41621 for container : container_1515664177839_0001_01_000001
2018-01-11 19:11:50,121 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:11:50,123 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515664177839_0001_000001
2018-01-11 19:11:50,123 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515664177839_0001 AttemptId: appattempt_1515664177839_0001_000001 MasterContainer: Container: [ContainerId: container_1515664177839_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:41621, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41621 }, ]
2018-01-11 19:11:50,123 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.041666668, absoluteUsedCapacity=0.041666668, numApps=1, numContainers=1
2018-01-11 19:11:50,124 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.041666668 absoluteUsedCapacity=0.041666668 used=<memory:1024, vCores:1> cluster=<memory:24576, vCores:24>
2018-01-11 19:11:50,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-11 19:11:50,145 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-11 19:11:50,155 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515664177839_0001_000001
2018-01-11 19:11:50,222 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515664177839_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:41621, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41621 }, ] for AM appattempt_1515664177839_0001_000001
2018-01-11 19:11:50,222 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515664177839_0001_000001
2018-01-11 19:11:50,226 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515664177839_0001_000001
2018-01-11 19:11:50,695 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515664177839_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:41621, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:41621 }, ] for AM appattempt_1515664177839_0001_000001
2018-01-11 19:11:50,696 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-11 19:11:51,069 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:12:04,192 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515664177839_0001_000001 (auth:SIMPLE)
2018-01-11 19:12:04,209 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515664177839_0001_000001
2018-01-11 19:12:04,210 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515664177839_0001	APPATTEMPTID=appattempt_1515664177839_0001_000001
2018-01-11 19:12:04,210 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from LAUNCHED to RUNNING
2018-01-11 19:12:04,210 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-11 19:12:05,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:12:05,004 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000002
2018-01-11 19:12:05,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:39909, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-11 19:12:05,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0001_000001 container=container_1515664177839_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@43bcfc46 clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:12:05,004 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.125, absoluteUsedCapacity=0.125, numApps=1, numContainers=2
2018-01-11 19:12:05,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:3072, vCores:2> cluster=<memory:24576, vCores:24>
2018-01-11 19:12:05,048 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:39909 for container : container_1515664177839_0001_01_000002
2018-01-11 19:12:05,049 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:12:05,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:12:05,137 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000003
2018-01-11 19:12:05,138 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-11 19:12:05,138 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0001_000001 container=container_1515664177839_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@43bcfc46 clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:12:05,138 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.20833333, absoluteUsedCapacity=0.20833333, numApps=1, numContainers=3
2018-01-11 19:12:05,138 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.20833333 absoluteUsedCapacity=0.20833333 used=<memory:5120, vCores:3> cluster=<memory:24576, vCores:24>
2018-01-11 19:12:05,933 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker03.local:39118 for container : container_1515664177839_0001_01_000003
2018-01-11 19:12:05,937 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:12:06,166 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:12:06,166 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000004
2018-01-11 19:12:06,166 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which has 2 containers, <memory:4096, vCores:2> used and <memory:4096, vCores:6> available after allocation
2018-01-11 19:12:06,166 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0001_000001 container=container_1515664177839_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@43bcfc46 clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:12:06,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.29166666, absoluteUsedCapacity=0.29166666, numApps=1, numContainers=4
2018-01-11 19:12:06,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.29166666 absoluteUsedCapacity=0.29166666 used=<memory:7168, vCores:4> cluster=<memory:24576, vCores:24>
2018-01-11 19:12:07,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:12:08,122 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:12:09,176 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515664177839_0001
2018-01-11 19:12:09,267 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:12:12,549 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-11 19:12:12,550 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000004
2018-01-11 19:12:12,550 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2018-01-11 19:24:09,262 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515664177839_0001_000001 with final state: FINISHING, and exit status: -1000
2018-01-11 19:24:09,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-11 19:24:09,264 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515664177839_0001 with final state: FINISHING
2018-01-11 19:24:09,265 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-11 19:24:09,265 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515664177839_0001
2018-01-11 19:24:09,265 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from FINAL_SAVING to FINISHING
2018-01-11 19:24:09,265 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-11 19:24:09,374 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515664177839_0001 unregistered successfully. 
2018-01-11 19:24:09,674 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-11 19:24:09,675 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000002
2018-01-11 19:24:09,675 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:39909, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-11 19:24:09,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-11 19:24:09,704 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000003
2018-01-11 19:24:09,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-11 19:24:09,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-11 19:24:09,866 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0001	CONTAINERID=container_1515664177839_0001_01_000001
2018-01-11 19:24:09,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:41621, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-11 19:24:09,866 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515664177839_0001_000001
2018-01-11 19:24:09,867 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515664177839_0001_000001
2018-01-11 19:24:09,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0001_000001 State change from FINISHING to FINISHED
2018-01-11 19:24:09,871 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-11 19:24:09,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515664177839_0001_000001 is done. finalState=FINISHED
2018-01-11 19:24:09,873 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515664177839_0001_000001
2018-01-11 19:24:09,875 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515664177839_0001
2018-01-11 19:24:09,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515664177839_0001 requests cleared
2018-01-11 19:24:09,879 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515664177839_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-11 19:24:09,879 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515664177839_0001 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-11 19:24:09,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515664177839_0001,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515664177839_0001/,appMasterHost=192.168.28.131,startTime=1515665509678,finishTime=1515666249264,finalStatus=SUCCEEDED,memorySeconds=3738653,vcoreSeconds=2193,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-11 19:24:11,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515664177839_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-11 19:24:11,730 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515664177839_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-11 19:26:31,681 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2018-01-11 19:26:48,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515664177839_0002' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-11 19:26:48,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515664177839_0002 for the user: hadoop
2018-01-11 19:26:48,040 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-11 19:26:48,040 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user hadoop
2018-01-11 19:26:48,040 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515664177839_0002
2018-01-11 19:26:48,040 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515664177839_0002
2018-01-11 19:26:48,040 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from NEW to NEW_SAVING on event=START
2018-01-11 19:26:48,041 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515664177839_0002
2018-01-11 19:26:48,041 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-11 19:26:48,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515664177839_0002 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-11 19:26:48,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515664177839_0002 from user: hadoop, in queue: default
2018-01-11 19:26:48,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-11 19:26:48,044 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515664177839_0002_000001
2018-01-11 19:26:48,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from NEW to SUBMITTED
2018-01-11 19:26:48,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515664177839_0002 from user: hadoop activated in queue: default
2018-01-11 19:26:48,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515664177839_0002 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-11 19:26:48,045 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515664177839_0002_000001 to scheduler from user hadoop in queue default
2018-01-11 19:26:48,046 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from SUBMITTED to SCHEDULED
2018-01-11 19:26:48,372 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:26:48,372 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0002	CONTAINERID=container_1515664177839_0002_01_000001
2018-01-11 19:26:48,372 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker03.local:39118, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-11 19:26:48,372 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0002_000001 container=container_1515664177839_0002_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@266de75c clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:26:48,374 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker03.local:39118 for container : container_1515664177839_0002_01_000001
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515664177839_0002_000001
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515664177839_0002 AttemptId: appattempt_1515664177839_0002_000001 MasterContainer: Container: [ContainerId: container_1515664177839_0002_01_000001, Version: 0, NodeId: hadoop-worker03.local:39118, NodeHttpAddress: hadoop-worker03.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.134:39118 }, ]
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.041666668, absoluteUsedCapacity=0.041666668, numApps=1, numContainers=1
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.041666668 absoluteUsedCapacity=0.041666668 used=<memory:1024, vCores:1> cluster=<memory:24576, vCores:24>
2018-01-11 19:26:48,375 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-11 19:26:48,378 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515664177839_0002_000001
2018-01-11 19:26:48,388 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515664177839_0002_01_000001, Version: 0, NodeId: hadoop-worker03.local:39118, NodeHttpAddress: hadoop-worker03.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.134:39118 }, ] for AM appattempt_1515664177839_0002_000001
2018-01-11 19:26:48,388 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515664177839_0002_000001
2018-01-11 19:26:48,389 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515664177839_0002_000001
2018-01-11 19:26:48,432 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515664177839_0002_01_000001, Version: 0, NodeId: hadoop-worker03.local:39118, NodeHttpAddress: hadoop-worker03.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.134:39118 }, ] for AM appattempt_1515664177839_0002_000001
2018-01-11 19:26:48,432 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from ALLOCATED to LAUNCHED
2018-01-11 19:26:49,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:26:59,462 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515664177839_0002_000001 (auth:SIMPLE)
2018-01-11 19:26:59,471 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515664177839_0002_000001
2018-01-11 19:26:59,471 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.134	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515664177839_0002	APPATTEMPTID=appattempt_1515664177839_0002_000001
2018-01-11 19:26:59,471 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from LAUNCHED to RUNNING
2018-01-11 19:26:59,471 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-11 19:26:59,692 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:26:59,692 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0002	CONTAINERID=container_1515664177839_0002_01_000002
2018-01-11 19:26:59,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41621, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-11 19:26:59,692 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0002_000001 container=container_1515664177839_0002_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@266de75c clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:26:59,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.125, absoluteUsedCapacity=0.125, numApps=1, numContainers=2
2018-01-11 19:26:59,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:3072, vCores:2> cluster=<memory:24576, vCores:24>
2018-01-11 19:26:59,734 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41621 for container : container_1515664177839_0002_01_000002
2018-01-11 19:26:59,740 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:27:00,260 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:27:00,261 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0002	CONTAINERID=container_1515664177839_0002_01_000003
2018-01-11 19:27:00,261 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-11 19:27:00,261 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0002_000001 container=container_1515664177839_0002_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@266de75c clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:27:00,261 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.20833333, absoluteUsedCapacity=0.20833333, numApps=1, numContainers=3
2018-01-11 19:27:00,261 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.20833333 absoluteUsedCapacity=0.20833333 used=<memory:5120, vCores:3> cluster=<memory:24576, vCores:24>
2018-01-11 19:27:00,365 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker03.local:39118 for container : container_1515664177839_0002_01_000003
2018-01-11 19:27:00,367 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:27:00,651 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:27:01,052 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:27:03,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515664177839_0002
2018-01-11 19:36:41,079 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1192ms
No GCs detected
2018-01-11 19:42:36,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1515664177839_0002_000001 with final state: FINISHING, and exit status: -1000
2018-01-11 19:42:36,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from RUNNING to FINAL_SAVING
2018-01-11 19:42:36,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1515664177839_0002 with final state: FINISHING
2018-01-11 19:42:36,137 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-11 19:42:36,138 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1515664177839_0002
2018-01-11 19:42:36,138 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from FINAL_SAVING to FINISHING
2018-01-11 19:42:36,139 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-11 19:42:36,237 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1515664177839_0002 unregistered successfully. 
2018-01-11 19:42:36,361 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-11 19:42:36,361 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0002	CONTAINERID=container_1515664177839_0002_01_000002
2018-01-11 19:42:36,362 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0002_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41621, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-11 19:42:36,477 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-11 19:42:36,477 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0002	CONTAINERID=container_1515664177839_0002_01_000003
2018-01-11 19:42:36,477 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0002_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-11 19:42:36,638 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-11 19:42:36,638 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0002	CONTAINERID=container_1515664177839_0002_01_000001
2018-01-11 19:42:36,639 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0002_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker03.local:39118, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-11 19:42:36,639 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1515664177839_0002_000001
2018-01-11 19:42:36,639 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1515664177839_0002_000001
2018-01-11 19:42:36,639 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0002_000001 State change from FINISHING to FINISHED
2018-01-11 19:42:36,639 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-11 19:42:36,640 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1515664177839_0002
2018-01-11 19:42:36,641 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1515664177839_0002,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1515664177839_0002/,appMasterHost=192.168.28.134,startTime=1515666408040,finishTime=1515667356137,finalStatus=SUCCEEDED,memorySeconds=4806694,vcoreSeconds=2820,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-11 19:42:36,641 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1515664177839_0002_000001 is done. finalState=FINISHED
2018-01-11 19:42:36,642 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1515664177839_0002_000001
2018-01-11 19:42:36,644 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1515664177839_0002 requests cleared
2018-01-11 19:42:36,645 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1515664177839_0002 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-11 19:42:36,654 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1515664177839_0002 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-11 19:42:38,366 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515664177839_0002_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-11 19:42:38,444 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1515664177839_0002_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-11 19:43:52,313 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2018-01-11 19:44:06,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1515664177839_0003' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-11 19:44:06,330 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1515664177839_0003 for the user: hadoop
2018-01-11 19:44:06,330 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 3 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-11 19:44:06,330 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user hadoop
2018-01-11 19:44:06,330 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1515664177839_0003
2018-01-11 19:44:06,331 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1515664177839_0003
2018-01-11 19:44:06,331 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0003 State change from NEW to NEW_SAVING on event=START
2018-01-11 19:44:06,331 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1515664177839_0003
2018-01-11 19:44:06,331 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-11 19:44:06,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1515664177839_0003 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-11 19:44:06,331 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1515664177839_0003 from user: hadoop, in queue: default
2018-01-11 19:44:06,333 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-11 19:44:06,333 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1515664177839_0003_000001
2018-01-11 19:44:06,333 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0003_000001 State change from NEW to SUBMITTED
2018-01-11 19:44:06,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1515664177839_0003 from user: hadoop activated in queue: default
2018-01-11 19:44:06,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1515664177839_0003 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-11 19:44:06,334 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1515664177839_0003_000001 to scheduler from user hadoop in queue default
2018-01-11 19:44:06,337 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0003_000001 State change from SUBMITTED to SCHEDULED
2018-01-11 19:44:06,927 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:44:06,928 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0003	CONTAINERID=container_1515664177839_0003_01_000001
2018-01-11 19:44:06,928 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0003_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker02.local:39909, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-11 19:44:06,928 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0003_000001 container=container_1515664177839_0003_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@42fc05aa clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:44:06,956 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:39909 for container : container_1515664177839_0003_01_000001
2018-01-11 19:44:06,959 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:44:06,960 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1515664177839_0003_000001
2018-01-11 19:44:06,961 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1515664177839_0003 AttemptId: appattempt_1515664177839_0003_000001 MasterContainer: Container: [ContainerId: container_1515664177839_0003_01_000001, Version: 0, NodeId: hadoop-worker02.local:39909, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:39909 }, ]
2018-01-11 19:44:06,961 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-11 19:44:06,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.041666668, absoluteUsedCapacity=0.041666668, numApps=1, numContainers=1
2018-01-11 19:44:06,962 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-11 19:44:06,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.041666668 absoluteUsedCapacity=0.041666668 used=<memory:1024, vCores:1> cluster=<memory:24576, vCores:24>
2018-01-11 19:44:06,963 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1515664177839_0003_000001
2018-01-11 19:44:06,967 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1515664177839_0003_01_000001, Version: 0, NodeId: hadoop-worker02.local:39909, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:39909 }, ] for AM appattempt_1515664177839_0003_000001
2018-01-11 19:44:06,967 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1515664177839_0003_000001
2018-01-11 19:44:06,967 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1515664177839_0003_000001
2018-01-11 19:44:06,995 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1515664177839_0003_01_000001, Version: 0, NodeId: hadoop-worker02.local:39909, NodeHttpAddress: hadoop-worker02.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.132:39909 }, ] for AM appattempt_1515664177839_0003_000001
2018-01-11 19:44:06,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0003_000001 State change from ALLOCATED to LAUNCHED
2018-01-11 19:44:07,964 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:44:15,835 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1515664177839_0003_000001 (auth:SIMPLE)
2018-01-11 19:44:15,847 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1515664177839_0003_000001
2018-01-11 19:44:15,847 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1515664177839_0003	APPATTEMPTID=appattempt_1515664177839_0003_000001
2018-01-11 19:44:15,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1515664177839_0003_000001 State change from LAUNCHED to RUNNING
2018-01-11 19:44:15,847 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1515664177839_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-11 19:44:16,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:44:16,107 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0003	CONTAINERID=container_1515664177839_0003_01_000002
2018-01-11 19:44:16,107 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0003_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:41621, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-11 19:44:16,107 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0003_000001 container=container_1515664177839_0003_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@42fc05aa clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:44:16,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.125, absoluteUsedCapacity=0.125, numApps=1, numContainers=2
2018-01-11 19:44:16,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:3072, vCores:2> cluster=<memory:24576, vCores:24>
2018-01-11 19:44:16,126 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:41621 for container : container_1515664177839_0003_01_000002
2018-01-11 19:44:16,127 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:44:16,146 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:44:16,146 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0003	CONTAINERID=container_1515664177839_0003_01_000003
2018-01-11 19:44:16,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0003_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:39909, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-11 19:44:16,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0003_000001 container=container_1515664177839_0003_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@42fc05aa clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:44:16,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.20833333, absoluteUsedCapacity=0.20833333, numApps=1, numContainers=3
2018-01-11 19:44:16,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.20833333 absoluteUsedCapacity=0.20833333 used=<memory:5120, vCores:3> cluster=<memory:24576, vCores:24>
2018-01-11 19:44:22,608 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:39909 for container : container_1515664177839_0003_01_000003
2018-01-11 19:44:22,635 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:44:23,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-11 19:44:23,535 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0003	CONTAINERID=container_1515664177839_0003_01_000004
2018-01-11 19:44:23,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1515664177839_0003_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-11 19:44:23,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1515664177839_0003_000001 container=container_1515664177839_0003_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@42fc05aa clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-11 19:44:23,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.29166666, absoluteUsedCapacity=0.29166666, numApps=1, numContainers=4
2018-01-11 19:44:23,537 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.29166666 absoluteUsedCapacity=0.29166666 used=<memory:7168, vCores:4> cluster=<memory:24576, vCores:24>
2018-01-11 19:44:23,689 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:44:23,928 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-11 19:44:25,928 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1515664177839_0003
2018-01-11 19:44:25,929 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker03.local:39118 for container : container_1515664177839_0003_01_000004
2018-01-11 19:44:25,935 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-11 19:44:29,231 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1515664177839_0003_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-11 19:44:29,232 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.132	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1515664177839_0003	CONTAINERID=container_1515664177839_0003_01_000004
2018-01-11 19:44:29,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1515664177839_0003_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:39118, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-11 20:23:10,973 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1710ms
No GCs detected
2018-01-11 21:04:29,540 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2534ms
No GCs detected
2018-01-11 21:04:57,625 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-11 21:04:57,645 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 21:04:57,649 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-11 21:04:57,757 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-11 21:04:57,806 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-11 21:04:57,810 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-11 21:04:57,813 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 21:04:57,840 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-11 21:04:57,842 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 21:04:57,846 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-11 21:04:57,851 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-11 21:04:57,854 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-11 21:04:57,902 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-11 21:04:57,904 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 21:04:57,904 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-11 21:04:57,911 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-11 21:04:57,912 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-11 21:04:57,912 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-11 21:04:57,913 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-11 21:04:57,913 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 21:04:57,915 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-11 21:04:57,915 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 21:04:57,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-11 21:04:57,921 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-11 21:04:57,921 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-11 21:04:57,922 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-11 21:04:57,924 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-11 21:04:57,924 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-11 21:04:57,925 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-11 21:04:57,926 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
2018-01-25 15:34:47,327 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   user = hadoop
STARTUP_MSG:   host = hadoop-master/192.168.28.129
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.2
STARTUP_MSG:   classpath = /opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/etc/hadoop:/opt/hadoop-2.8.2/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hadoop-auth-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jcip-annotations-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/json-smart-1.1.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/common/hadoop-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2-tests.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-api-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-client-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-registry-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-common-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.2/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 66c47f2a01ad9637879e95f80c41f798373828fb; compiled by 'jdu' on 2017-10-19T20:39Z
STARTUP_MSG:   java = 1.8.0_152
************************************************************/
2018-01-25 15:34:47,375 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-25 15:34:48,869 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/core-site.xml
2018-01-25 15:34:49,075 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2018-01-25 15:34:49,421 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-2.8.2/etc/hadoop/yarn-site.xml
2018-01-25 15:34:50,551 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2018-01-25 15:34:52,444 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2018-01-25 15:34:52,454 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2018-01-25 15:34:52,503 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2018-01-25 15:34:52,680 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2018-01-25 15:34:52,687 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2018-01-25 15:34:52,688 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2018-01-25 15:34:52,786 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2018-01-25 15:34:52,789 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2018-01-25 15:34:52,792 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2018-01-25 15:34:52,795 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2018-01-25 15:34:52,999 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-25 15:34:53,318 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2018-01-25 15:34:53,319 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2018-01-25 15:34:53,395 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2018-01-25 15:34:53,436 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2018-01-25 15:34:53,440 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2018-01-25 15:34:53,462 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2018-01-25 15:34:53,468 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2018-01-25 15:34:53,497 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-2.8.2/etc/hadoop/capacity-scheduler.xml
2018-01-25 15:34:53,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2018-01-25 15:34:53,954 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2018-01-25 15:34:54,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,, offswitchPerHeartbeatLimit = 1, reservationsContinueLooking=true
2018-01-25 15:34:54,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2018-01-25 15:34:54,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2018-01-25 15:34:54,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2018-01-25 15:34:54,076 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
reservationsContinueLooking = true
preemptionDisabled = true
defaultAppPriorityPerQueue = 0
2018-01-25 15:34:54,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2018-01-25 15:34:54,077 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-25 15:34:54,193 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2018-01-25 15:34:54,194 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2018-01-25 15:34:54,196 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2018-01-25 15:34:54,205 INFO org.apache.hadoop.conf.Configuration: dynamic-resources.xml not found
2018-01-25 15:34:54,250 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2018-01-25 15:34:54,251 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2018-01-25 15:34:54,288 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2018-01-25 15:34:54,384 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2018-01-25 15:34:54,384 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2018-01-25 15:34:54,385 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2018-01-25 15:34:54,385 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-25 15:34:54,387 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2018-01-25 15:34:54,387 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-25 15:34:54,455 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2018-01-25 15:34:54,394 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-25 15:34:54,770 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-25 15:34:54,783 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-25 15:34:54,894 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2018-01-25 15:34:55,042 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2018-01-25 15:34:55,154 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2018-01-25 15:34:56,275 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2018-01-25 15:34:56,288 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-25 15:34:56,300 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2018-01-25 15:34:56,910 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-25 15:34:56,939 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2018-01-25 15:34:56,984 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2018-01-25 15:34:56,993 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-25 15:34:56,997 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2018-01-25 15:34:59,881 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1403ms
GC pool 'Copy' had collection(s): count=1 time=3ms
GC pool 'MarkSweepCompact' had collection(s): count=1 time=57ms
2018-01-25 15:34:59,910 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-25 15:34:59,940 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2018-01-25 15:34:59,956 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2018-01-25 15:35:00,008 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-25 15:35:00,010 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2018-01-25 15:35:00,729 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2018-01-25 15:35:01,105 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-25 15:35:01,140 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-25 15:35:01,174 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2018-01-25 15:35:01,208 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-25 15:35:01,230 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2018-01-25 15:35:01,230 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2018-01-25 15:35:01,230 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2018-01-25 15:35:01,231 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2018-01-25 15:35:01,231 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-25 15:35:01,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-25 15:35:01,239 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2018-01-25 15:35:01,239 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2018-01-25 15:35:03,315 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2018-01-25 15:35:03,319 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2018-01-25 15:35:03,319 INFO org.mortbay.log: jetty-6.1.26
2018-01-25 15:35:03,456 INFO org.mortbay.log: Extract jar:file:/opt/hadoop-2.8.2/share/hadoop/yarn/hadoop-yarn-common-2.8.2.jar!/webapps/cluster to /tmp/Jetty_hadoop.master_8088_cluster____dnr7xy/webapp
2018-01-25 15:35:04,263 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-25 15:35:04,285 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2018-01-25 15:35:04,344 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2018-01-25 15:35:19,186 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5112ms
GC pool 'Copy' had collection(s): count=1 time=7ms
2018-01-25 15:35:23,804 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4118ms
No GCs detected
2018-01-25 15:35:24,547 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-25 15:35:24,548 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2018-01-25 15:35:25,735 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2018-01-25 15:35:25,741 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2018-01-25 15:35:25,746 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2018-01-25 15:35:25,787 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-25 15:35:25,804 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2018-01-25 15:35:27,467 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker03.local(cmPort: 40044 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker03.local:40044
2018-01-25 15:35:27,472 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker02.local(cmPort: 36219 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker02.local:36219
2018-01-25 15:35:27,467 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node hadoop-worker01.local(cmPort: 34135 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId hadoop-worker01.local:34135
2018-01-25 15:35:27,512 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker03.local:40044 Node Transitioned from NEW to RUNNING
2018-01-25 15:35:27,514 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker01.local:34135 Node Transitioned from NEW to RUNNING
2018-01-25 15:35:27,514 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: hadoop-worker02.local:36219 Node Transitioned from NEW to RUNNING
2018-01-25 15:35:27,633 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker03.local:40044 clusterResource: <memory:8192, vCores:8>
2018-01-25 15:35:27,635 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker01.local:34135 clusterResource: <memory:16384, vCores:16>
2018-01-25 15:35:27,636 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node hadoop-worker02.local:36219 clusterResource: <memory:24576, vCores:24>
2018-01-25 15:45:36,106 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2018-01-25 17:35:36,014 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2018-01-25 17:35:52,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application 'application_1516862094254_0001' is submitted without priority hence considering default queue/cluster priority: 0
2018-01-25 17:35:52,159 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1516862094254_0001 for the user: hadoop
2018-01-25 17:35:52,188 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2018-01-25 17:35:52,203 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user hadoop
2018-01-25 17:35:52,204 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1516862094254_0001
2018-01-25 17:35:52,207 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.130	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1516862094254_0001
2018-01-25 17:35:52,232 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from NEW to NEW_SAVING on event=START
2018-01-25 17:35:52,236 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1516862094254_0001
2018-01-25 17:35:52,241 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2018-01-25 17:35:52,268 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1516862094254_0001 user: hadoop leaf-queue of parent: root #applications: 1
2018-01-25 17:35:52,270 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1516862094254_0001 from user: hadoop, in queue: default
2018-01-25 17:35:52,353 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2018-01-25 17:35:52,413 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1516862094254_0001_000001
2018-01-25 17:35:52,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from NEW to SUBMITTED
2018-01-25 17:35:52,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1516862094254_0001 from user: hadoop activated in queue: default
2018-01-25 17:35:52,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1516862094254_0001 user: hadoop, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2018-01-25 17:35:52,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1516862094254_0001_000001 to scheduler from user hadoop in queue default
2018-01-25 17:35:52,492 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from SUBMITTED to SCHEDULED
2018-01-25 17:35:52,663 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2018-01-25 17:35:52,663 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000001
2018-01-25 17:35:52,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1516862094254_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:34135, which has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available after allocation
2018-01-25 17:35:52,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1516862094254_0001_000001 container=container_1516862094254_0001_01_000001 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4b8fb74e clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-25 17:35:52,702 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:34135 for container : container_1516862094254_0001_01_000001
2018-01-25 17:35:52,715 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-25 17:35:52,716 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1516862094254_0001_000001
2018-01-25 17:35:52,717 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1516862094254_0001 AttemptId: appattempt_1516862094254_0001_000001 MasterContainer: Container: [ContainerId: container_1516862094254_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:34135, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:34135 }, ]
2018-01-25 17:35:52,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.041666668, absoluteUsedCapacity=0.041666668, numApps=1, numContainers=1
2018-01-25 17:35:52,720 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.041666668 absoluteUsedCapacity=0.041666668 used=<memory:1024, vCores:1> cluster=<memory:24576, vCores:24>
2018-01-25 17:35:52,734 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2018-01-25 17:35:52,748 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2018-01-25 17:35:52,756 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1516862094254_0001_000001
2018-01-25 17:35:52,850 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1516862094254_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:34135, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:34135 }, ] for AM appattempt_1516862094254_0001_000001
2018-01-25 17:35:52,851 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1516862094254_0001_000001
2018-01-25 17:35:52,856 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1516862094254_0001_000001
2018-01-25 17:35:53,600 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1516862094254_0001_01_000001, Version: 0, NodeId: hadoop-worker01.local:34135, NodeHttpAddress: hadoop-worker01.local:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 192.168.28.131:34135 }, ] for AM appattempt_1516862094254_0001_000001
2018-01-25 17:35:53,601 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from ALLOCATED to LAUNCHED
2018-01-25 17:35:53,637 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2018-01-25 17:36:07,786 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1516862094254_0001_000001 (auth:SIMPLE)
2018-01-25 17:36:07,804 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1516862094254_0001_000001
2018-01-25 17:36:07,805 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1516862094254_0001	APPATTEMPTID=appattempt_1516862094254_0001_000001
2018-01-25 17:36:07,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from LAUNCHED to RUNNING
2018-01-25 17:36:07,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2018-01-25 17:36:08,453 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2018-01-25 17:36:08,453 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000002
2018-01-25 17:36:08,453 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1516862094254_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:40044, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-25 17:36:08,453 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1516862094254_0001_000001 container=container_1516862094254_0001_01_000002 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4b8fb74e clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-25 17:36:08,453 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.125, absoluteUsedCapacity=0.125, numApps=1, numContainers=2
2018-01-25 17:36:08,454 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.125 absoluteUsedCapacity=0.125 used=<memory:3072, vCores:2> cluster=<memory:24576, vCores:24>
2018-01-25 17:36:08,602 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker03.local:40044 for container : container_1516862094254_0001_01_000002
2018-01-25 17:36:08,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-25 17:36:08,699 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2018-01-25 17:36:08,700 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000003
2018-01-25 17:36:08,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1516862094254_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:34135, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2018-01-25 17:36:08,700 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1516862094254_0001_000001 container=container_1516862094254_0001_01_000003 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4b8fb74e clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-25 17:36:08,701 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5120, vCores:3>, usedCapacity=0.20833333, absoluteUsedCapacity=0.20833333, numApps=1, numContainers=3
2018-01-25 17:36:08,701 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.20833333 absoluteUsedCapacity=0.20833333 used=<memory:5120, vCores:3> cluster=<memory:24576, vCores:24>
2018-01-25 17:36:09,117 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker01.local:34135 for container : container_1516862094254_0001_01_000003
2018-01-25 17:36:09,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-25 17:36:09,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2018-01-25 17:36:09,314 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000004
2018-01-25 17:36:09,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1516862094254_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:36219, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2018-01-25 17:36:09,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1516862094254_0001_000001 container=container_1516862094254_0001_01_000004 queue=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator@4b8fb74e clusterResource=<memory:24576, vCores:24> type=OFF_SWITCH requestedPartition=
2018-01-25 17:36:09,338 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:7168, vCores:4>, usedCapacity=0.29166666, absoluteUsedCapacity=0.29166666, numApps=1, numContainers=4
2018-01-25 17:36:09,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.29166666 absoluteUsedCapacity=0.29166666 used=<memory:7168, vCores:4> cluster=<memory:24576, vCores:24>
2018-01-25 17:36:09,736 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2018-01-25 17:36:12,282 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2018-01-25 17:36:12,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1516862094254_0001
2018-01-25 17:36:12,435 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : hadoop-worker02.local:36219 for container : container_1516862094254_0001_01_000004
2018-01-25 17:36:12,483 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2018-01-25 17:36:15,509 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2018-01-25 17:36:15,509 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	IP=192.168.28.131	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000004
2018-01-25 17:36:15,607 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1516862094254_0001_01_000004 of capacity <memory:2048, vCores:1> on host hadoop-worker02.local:36219, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-25 17:37:54,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1516862094254_0001_000001 with final state: FINISHING, and exit status: -1000
2018-01-25 17:37:54,896 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from RUNNING to FINAL_SAVING
2018-01-25 17:37:54,897 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1516862094254_0001 with final state: FINISHING
2018-01-25 17:37:54,897 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2018-01-25 17:37:54,899 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from FINAL_SAVING to FINISHING
2018-01-25 17:37:54,898 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1516862094254_0001
2018-01-25 17:37:54,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2018-01-25 17:37:55,022 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1516862094254_0001 unregistered successfully. 
2018-01-25 17:37:55,366 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2018-01-25 17:37:55,366 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000003
2018-01-25 17:37:55,367 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1516862094254_0001_01_000003 of capacity <memory:2048, vCores:1> on host hadoop-worker01.local:34135, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:7168, vCores:7> available, release resources=true
2018-01-25 17:37:55,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2018-01-25 17:37:55,407 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000002
2018-01-25 17:37:55,408 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1516862094254_0001_01_000002 of capacity <memory:2048, vCores:1> on host hadoop-worker03.local:40044, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-25 17:37:55,876 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1516862094254_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2018-01-25 17:37:55,876 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1516862094254_0001	CONTAINERID=container_1516862094254_0001_01_000001
2018-01-25 17:37:55,876 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1516862094254_0001_01_000001 of capacity <memory:1024, vCores:1> on host hadoop-worker01.local:34135, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2018-01-25 17:37:55,876 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1516862094254_0001_000001
2018-01-25 17:37:55,878 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1516862094254_0001_000001
2018-01-25 17:37:55,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1516862094254_0001_000001 State change from FINISHING to FINISHED
2018-01-25 17:37:55,957 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1516862094254_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2018-01-25 17:37:55,959 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1516862094254_0001
2018-01-25 17:37:55,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1516862094254_0001_000001 is done. finalState=FINISHED
2018-01-25 17:37:55,963 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1516862094254_0001_000001
2018-01-25 17:37:55,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1516862094254_0001 requests cleared
2018-01-25 17:37:55,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1516862094254_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2018-01-25 17:37:55,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1516862094254_0001 user: hadoop leaf-queue of parent: root #applications: 0
2018-01-25 17:37:55,991 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1516862094254_0001,name=sparklyr,user=hadoop,queue=default,state=FINISHED,trackingUrl=http://hadoop-master:8088/proxy/application_1516862094254_0001/,appMasterHost=192.168.28.131,startTime=1516869352188,finishTime=1516869474897,finalStatus=SUCCEEDED,memorySeconds=576351,vcoreSeconds=341,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2018-01-25 17:37:57,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1516862094254_0001_01_000002 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-25 17:37:58,108 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Container container_1516862094254_0001_01_000003 completed with event FINISHED, but corresponding RMContainer doesn't exist.
2018-01-25 17:48:25,093 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2018-01-25 17:48:25,115 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-25 17:48:25,121 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@hadoop-master:8088
2018-01-25 17:48:25,226 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2018-01-25 17:48:25,239 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2018-01-25 17:48:25,243 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-25 17:48:25,244 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2018-01-25 17:48:25,266 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-25 17:48:25,267 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2018-01-25 17:48:25,268 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2018-01-25 17:48:25,269 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2018-01-25 17:48:25,270 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2018-01-25 17:48:25,310 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-25 17:48:25,310 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2018-01-25 17:48:25,311 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2018-01-25 17:48:25,324 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2018-01-25 17:48:25,324 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2018-01-25 17:48:25,325 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2018-01-25 17:48:25,326 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-25 17:48:25,327 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2018-01-25 17:48:25,329 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-25 17:48:25,335 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2018-01-25 17:48:25,335 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2018-01-25 17:48:25,338 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2018-01-25 17:48:25,341 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2018-01-25 17:48:25,344 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2018-01-25 17:48:25,345 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2018-01-25 17:48:25,346 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2018-01-25 17:48:25,347 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2018-01-25 17:48:25,348 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at hadoop-master/192.168.28.129
************************************************************/
